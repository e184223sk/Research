{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "hello world\n",
      "transformer\n",
      "current dir: C:\\Users\\konolab\\Desktop\\Research\\deep_dialog_tutorial\n"
     ]
    }
   ],
   "source": [
    "# カレントディレクトリをリポジトリ直下にするおまじない\n",
    "import os\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "print(\"hello world\")\n",
    "print(os.getcwd().split('\\\\')[-1] )\n",
    "while os.getcwd().split('\\\\')[-1] != 'deep_dialog_tutorial': os.chdir('..')\n",
    "print('current dir:', os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konolab\\Desktop\\Research\\deep_dialog_tutorial\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import tensorflow as tf\n",
    "from deepdialog.transformer.transformer import Transformer\n",
    "from deepdialog.transformer.preprocess.batch_generator import BatchGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data\\\\natsume.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明治三十八年九月。\n"
     ]
    }
   ],
   "source": [
    "batch_generator = BatchGenerator()\n",
    "batch_generator.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = batch_generator.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konolab\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konolab\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    transformer = Transformer(\n",
    "        vocab_size=vocab_size,\n",
    "        hopping_num=4,\n",
    "        head_num=8,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        max_length=50,\n",
    "    )\n",
    "    transformer.build_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'tmp/learning/transformer/'\n",
    "log_dir = os.path.join(save_dir, 'log')\n",
    "ckpt_path = os.path.join(save_dir, 'checkpoints/model.ckpt')\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "    \n",
    "    learning_rate = tf.compat.v1.placeholder(dtype=tf.float32, name='learning_rate')\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=learning_rate,\n",
    "        beta2=0.98,\n",
    "    )\n",
    "    #TensorFlowには損失関数を最小限に抑えるために各変数をゆっくりと変更するオプティマイザが用意されている\n",
    "    optimize_op = optimizer.minimize(transformer.loss, global_step=global_step)\n",
    "# Tensor boardに出すためにデータをマージ\n",
    "    summary_op = tf.compat.v1.summary.merge([\n",
    "        tf.compat.v1.summary.scalar('train/loss', transformer.loss),\n",
    "        tf.compat.v1.summary.scalar('train/acc', transformer.acc),\n",
    "        tf.compat.v1.summary.scalar('train/learning_rate', learning_rate),\n",
    "    ], name='train_summary')\n",
    "    summary_writer = tf.compat.v1.summary.FileWriter(log_dir, graph)\n",
    "    saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 100000\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.0001\n",
    "warmup_step = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(step: int) -> float:\n",
    "    rate = min(step ** -0.5, step * warmup_step ** -1.5) / warmup_step ** -0.5\n",
    "    return max_learning_rate * rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    sess = tf.compat.v1.Session()\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss: 8.38064193725586,\t acc: 0.0\n",
      "100: loss: 8.005585670471191,\t acc: 0.08455361425876617\n",
      "200: loss: 7.597139358520508,\t acc: 0.095381960272789\n",
      "300: loss: 7.288633346557617,\t acc: 0.12671375274658203\n",
      "400: loss: 6.917326927185059,\t acc: 0.12110453844070435\n",
      "500: loss: 6.578369617462158,\t acc: 0.1424790471792221\n",
      "WARNING:tensorflow:From C:\\Users\\konolab\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "600: loss: 6.3707194328308105,\t acc: 0.14273612201213837\n",
      "700: loss: 6.2278361320495605,\t acc: 0.14492753148078918\n",
      "800: loss: 6.173699855804443,\t acc: 0.160411074757576\n",
      "900: loss: 6.009583473205566,\t acc: 0.17045961320400238\n",
      "1000: loss: 5.886408805847168,\t acc: 0.18925459682941437\n",
      "1100: loss: 5.909269332885742,\t acc: 0.18838591873645782\n",
      "1200: loss: 5.943912982940674,\t acc: 0.17588357627391815\n",
      "1300: loss: 5.891147136688232,\t acc: 0.18591319024562836\n",
      "1400: loss: 5.76690673828125,\t acc: 0.19243986904621124\n",
      "1500: loss: 5.68817138671875,\t acc: 0.19531914591789246\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    for batch in batch_generator.get_batch(batch_size=batch_size):\n",
    "        feed = {\n",
    "            **batch,\n",
    "            learning_rate: get_learning_rate(step + 1),\n",
    "        }\n",
    "        _, loss, acc, step, summary = sess.run([optimize_op, transformer.loss, transformer.acc, global_step, summary_op], feed_dict=feed)\n",
    "        summary_writer.add_summary(summary, step)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f'{step}: loss: {loss},\\t acc: {acc}')\n",
    "            saver.save(sess, ckpt_path, global_step=step)\n",
    "        if step == max_step:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
