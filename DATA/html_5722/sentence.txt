More than 1 year has passed since last update.【更新情報】ARCoreはデジタルと物理の世界をシームレスに融合させた新しい経験を形作ることができる、Googleが提供する新しいAR(拡張現実)プラットフォームです。
以下が実際に実装して、実行してみたものになります。
ARCoreはいわばTangoの一般向け汎用デバイスに向けたARプラットフォームにあたります。
Tangoはモーショントラッキングカメラや深度センサーなど追加のハードウェアを必要とするのに対し、ARCoreはそういった特別なハードウェアなしでTangoのようなものを開発することができるようにしたものです。※2018/3/1をもってTangoのサポートは終了しました。これからは、ARCoreの開発に注力します。
【参考】 Google、「Project Tango」の終了を正式発表　「ARCore」開発者プレビュー2公開ARCoreはARKitのAndroid版です。
ARKitでできることのほとんど同じことはARCoreでもできます。などこちらにARCoreを実行してみた様子のデモをいろいろ紹介してくれていますので参照してみてください。
ARCore Master Class | Augmented Startups【参考】一応、裏技でこれら以外の端末で動かすことはできますが、現状動作がかなり怪しいのでそのつもりで開発してください。
【参考】 ARCoreをPixelやS8以外の端末で動かす端末状況について詳しくはこちら【2018/2/25更新】
上記端末のほか、現在、Samsung, Huawei, LGE, Motorola, ASUS, Xiaomi, HMD/Nokia, ZTE, Sony Mobile, Vivoの端末メーカーの次の新機種にはARCoreを載せようとしていいます。そのため、これらのメーカーから販売される新機種の端末にはいずれもARCoreが搭載されている可能性が高いと思われます。【参考】 Unityです!!
実装には3Dの技術や知識が必要になります。
3Dについてのはじめの一歩としてこちらに紹介しています。
Android JavaのサンプルではOBJファイルを読みこんでいますが、それ以外のファイル(FBX等)を読みたい場合は自力で読み込むしかないです。(またはRajawaliをうまく使いこなすことができたら、もしかしたら...)
3Dの処理を自力で書くのは相当大変なのでUnityまたはUnreal Engine、(web)を使って開発することをおすすめします。(※webの場合、three.jsの練度や対応状況、端末依存などの影響を大きく受ける可能性があります。そのため安定した動作が期待できない可能性があります)【2018/5/22追記】
Sceneformが新しくリリースされました。これはAndroid Javaをメインに開発している人でも3Dの開発をしやすいようにしたエディタツール(Android Studio Plugin)です。つまりUnityやUE4のエディタ機能をAndroid Studioでも利用できるようにしたものになります。Sceneformを使って開発していけば、開発も捗ると思います。(Sceneformの使い方などについては本稿の趣旨と離れるので割愛します)【参考】公式ドキュメントはこちら。Getting Started with Android Studioこれで、ビルドされ、端末にサンプルがインストールされます。
※今回はhello_ar_javaのプロジェクトを開いて実行しましたがこれ以外のプロジェクトを開いた場合でも同様に▶ボタンを押すことでビルド、インストールすることができます。公式ドキュメントはこちら。Getting Started with Unity
Unityで動かすためには少し特殊な設定を行う必要があります。
※ARCore用の設定のままARCore以外のUnityプロジェクトをビルドすると正常に起動しないことがありますので気をつけてください
ARCoreではInstant Previewという、Unity Editor上でARCoreを実行している様子を表示することができる機能があります。通常のBuildの他に、この機能の使い方も一緒に紹介します。
4. 「Add Open Scenes」ボタンを押して現在のSceneを追加する。
5. Platformの中の「Android」を選択して、「Switch　Platform」ボタンを押す。
6. しばらくすると、AndroidでBuild可能な環境となります。ARCoreが実行可能な端末とPCと接続している状態で以下の手順を実行することでUnity Editor上で端末のカメラを使い、実行した様子を見ることができます。
1. ARCoreを実行可能な実機端末とUnityで開発しているマシンをつなげる
2. ▶のボタンを押す。これにより、実機端末の方でInstant Previewモードで実行され、実機端末でARカメラで撮影、実行されている様子が「Game」画面の中に表示されます。

また、この状態で「Hierarchy」内に3Dモデルなどを挿入すると実機端末内に挿入したものが出現します。
Instant Previewモードでの注意点として、このとき、起動するSceneでは以下の内容を記述しないと、実行中の間の実機でのタッチ判定を取得する事はできないので注意が必要です。(サンプルには記述されているので、主にversion upする場合の話になります。)詳しくはこちらをご覧ください2.　Other Settingsのタブを開き、以下の設定を行う
3. XR Settingsのタブを開き、 ARCore Supported のチェックをつける 

4. 再びFile-&gt;Build Settingsを選択して、BUild Settingsを開く
5. 「Build」ボタンを押してBuildする。ビルド結果を端末に直接インストールしたい場合は「Build And Run」ボタンを押して直接インストールする。
これでサンプルアプリを実機にBuildして動かすことができます。上記、XR Settingsタブの 「ARCore Supported」 のチェックはUnity 2018.2.1以降では以下のようにUnity Scriptでもからでも行うことができます
C#
PlayerSettings.Android.ARCoreEnabled = true;
すみません、試していません。しかし、公式ドキュメントはこちらにありますのでこちらをご参照ください。Getting Started with Unrealできません。開発するときは必ずPlatformを「Android」に指定して開発してください。

【2018/5/22追記】
ARCore1.2.0以降ではARCore内に一部、iOSでも使われる機能が内包されています。(実態はARKitの一部機能を用いています)そのため、ARCore内でもARKitの一部の機能を使うことができますが、本格的にARKitと共同で開発する場合はUnity-ARKit-Pluginを利用してください。また、ARKitとARCoreを共通のソースコードで開発する場合はこちらもご活用ください。
Unity で ARKit &amp; ARCore AR開発環境のマルチプラットーフォーム(iOS &amp; Android)対応【2018/8/20追記】
ARCore1.4.0では上記の機能はCloudAnchorを利用する場合にのみ使うことができるようになっていますので、それに合わせてiOSでARCoreをつかえるようにするかどうかの設定をすることができます。

上記で設定画面を開きます。

iOS Support Enabledにチェックを入れることでiOSでもARCoreが使えるようになります。【参考】
 * Welcome to the ARCore SDK for iOSひとまず、既存のSceneにあるExampleControllerの中のAndy Android Prefabを別のものに差し替えたら表示されるものが変わります。
検知した平面上にものを出現させる場合、Anchorと呼ばれるものを作成し、その子供に出現させる必要があります。Anchorを作る理由として、ARCoreでは時々、位置の調整を行なっており、Anchorの子供に出現させないとだんだん位置がずれていきます。(問い合わせてご回答いただけました。The camera often seems to teleport.)
具体的なやり方は以下のとおりです。でAnchor(クラス)を取得できます。
上記のPoseは出現させたいPosition(座標)とRotate(向き)を指定することで作成できます。また、TrackableとはTrackedPlane(検出できた面)やTrackedPoint(検出できた特徴点)の基底クラスとなります。3Dモデルを公開してくれているサービスはいくつもあるのでここらへんから3Dモデルを持ってくることをおすすめします。そのためのツールを作成しましたのでこちらを参考にしてください。
Unity 開発者があると便利だと思うツールを色々と作成したので公開以下記事が非常に参考になります。
ARCoreで検出した水平面にオブジェクトを落とす以下に該当のソースコードを記します。 そして、検出した面に当たり判定が適用されるようにします。
DetectedPlaneVisualizer.prefabにMeshColliderをつけることで、検出した面に当たり判定がつき、物を置くことができるようになります。
該当箇所を以上のように修正すると検出面にCollider(あたり判定を検出する膜)をつけることができます。
その後、物理演算をしたい3Dモデルに以下のようにRigidBodyという要素をつければ、物理演算をしてくれるようになります。

またこの時、Use Gravityにチェックを入れると、重力が有効になり、検出した平面に上に乗せることができます。サンプルの平面の検出にあたる部分の処理を以下に表示します。これで、新たに検出できた平面を取得し、これで検出できている平面全ての情報を取得することができます。
Session.GetTrackablesの第2引数は省略可能でTrackableQueryFilter.Allを使うので十分に事足ります。
この、DetectedPlaneが検出できた平面で、水平・垂直の両方の平面を共通して扱います。
このDetectedPlaneは検出面が広がることで各種値が更新されていきます。(以降の項目を参照)検出できた面はDetectedPlaneというstructとして取得することができます。
この、DetectedPlaneですが面の座標や広さの情報を保持しています。それぞれの座標系の情報以下の通りです。詳しく説明はこちらを参照。
GoogleARCore.DetectedPlaneFirst Person CameraがAR上のカメラにあたります。
アプリを起動した場所を原点として、移動、回転した分がこの値になります。
現在カメラに写っているかどうかで制御したい場合は以下のようにOnBecameVisibleまたはOnBecameInvisibleを使用することで判定できます。
※ただしこれらのCallbackはRenderer Classがついている場合のみ呼ばれます【参考】カメラに写っているかで処理を分岐するARCore 1.2.0以降では壁も検出できるようになりました。ARKitではVersion 1.5から壁を検出できます。(iOS 11.3以上にする必要があります)
実際に検出する方法は
この状態で、壁を検出すると、上記、DetectedPlaneについてと同様に、DetectedPlaneを取得することができます。(上記のようにPlaneTypeで取得できた値で判別することができます。)この他、ARCoreSessionConfig(今回の場合、DefaultSessionConfig)にてARCoreで利用できる機能のON/OFFの設定ができます。なお、独自に実装することも可能です。その場合はこちらを参考にしてください。
ARKitで任意の方向の平面を検出するAugmentedImageとは事前に画像の情報を指定し、その画像をARCoreのカメラにかざすと検出できるという機能です。(一般的にはマーカー画像と呼ばれます) Vuforiaで使われている機能と類似の機能になります。
なおARCore1.2.0ではARCore起動中に検出可能画像を追加することはUnityEditor上では可能ですが、実機ではできません。プログラム上で行う場合、以下のようにAugmentedImageDatabaseEntryを操作することで更新できます。以下のようにすることでマーカー画像を検出した情報を取得することができます。ここで取得できた、AugmentedImageは上記のTrackableでもあるので、AugmentedImageからCreateAnchorを呼び出すことでARCoreの空間に出現させることができます。CloudAnchorとは、複数の端末において共通の空間を共有する機能です。iOS(ARKit)で検出している空間とも共有することができます。
以下がデモの様子です。
CroudAnchorsを実際に利用できるようにするには、まずEditor→Project Settings→ARCoreを選択し、ダイアログを開きます。
以下のように「Cloud Server API Key」の項目にAndroid, iOSそれぞれに対応したAPIキーを入力します。(APIキーの取得については以下参照)
Google API Consoleを開き、ARCoreのCloud Anchorを使えるようにします。

Google API ConsoleからARCoreの検索します。

検索してでてきた、ARCoreの設定を「有効」にします。

Google API Consoleの中の「認証情報」を選択し、上記のようにARCoreが有効になっているプロジェクトのAPIキーの内容をUnityのAPIキーの項目にのところに入力します。この状態でAssets/GoogleARCore/Examples/CloudAnchor/Scenes/CloudAnchor.unityを開き、プロジェクトこのSceneをビルドすることで、CloudAnchorsについて、試してみることができます。
※UnityのExamplesでのCloudAnchorsは接続がかなりシビアになっており、なかなか端末と繋げることができません。UnityではなくAndroid NaitiveではNearByを利用しているためか、割と繋がりやすいです。また、上記でデモ動画で行われているアプリやソースコードは以下になりますので、実装の際にはこちらも参考にしてください。【その他参考記事】


