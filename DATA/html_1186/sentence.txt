WinRT で音声合成を試します。従来の API よりも扱える音声が増えたことを確認します。C# を使用します。この記事のコードは以下のリポジトリに掲載しています。他の言語での利用については以下の記事を参照してください。JavaScript との比較については以下の記事を参照してください。Windows 10 でサポートされる音声の一覧です。日本語以外の言語を使用する場合は追加します。今回はすべての言語を追加した状態でテストします。従来の API と WinRT とで結果が異なります。Windows 10 での新しい音声は OneCore という枠組みで扱われます。従来の API では OneCore の音声が扱えません。.NET Framework の System.Speech.Synthesis で音声一覧を取得します。一部の音声しか取得できません。SAPI ではレジストリを参照することで OneCore の音声を取得できますが、その方法は System.Speech.Synthesis では使えません。また、System.Speech.Synthesis は .NET Core 3.1 では動きません。WinRT に移行するようにということのようです。ほぼすべて（後述）の音声が取得できます。SAPI でレジストリを指定して取得した結果と比較すると、以下の2つの音声が取得できません。これらは音声の設定にも現れませんが、Chromium 版 Edge では使えます。隠れキャラなのでしょうか。音声を指定してしゃべらせます。再生が終了するまで待つようになっています。参考までにハマったポイントを書いておきます。当初、SpeechSynthesizer.SynthesizeTextToStreamAsync() から返される SpeechSynthesisStream が直接受け取れる MediaPlayer.SetStreamSource() を使おうとしましたが、obsolete でした。MediaPlayer.SetMediaSource may be altered or unavailable after Windows 10. Use MediaPlayer.Source instead.代替の MediaPlayer.Source は IMediaPlaybackSource を受け取るため変換が必要です。以下に変換方法についての質問がありますが、1番目の回答では引数が足りないため、2番目の回答から ContentType の部分を補う必要があります。今回は WinRT の MediaPlayer を使用しましたが、以下の記事では WPF の SoundPlayer を使用しています。こちらは Stream への変換が必要になります。再生は非同期で行われるため、再生が終わるまでプログラムが終了しないように待ちます。再生の終了は MediaEnded で通知されるので、TaskCompletionSource に値をセットして Task を終了させます。以下を参考にしました。TaskCompletionSource の使い方は JavaScript の Promise に近いと思いました。csproj ファイルでは以下のように WinRT を参照しています。以下を参考にしました。


