More than 1 year has passed since last update.最近の流行りのVtuberになれるアプリ作ってみました。このアプリは２つのアプリから成り立っていて
iPhone側でフェイスキャプチャー用が
PC側(Windows10)でLive2Dの制御用です。
動きよくなりましたね pic.twitter.com/NB5034WkeBUnity2019.2.15f1
Windows10
iPhoneXR 
ios13.3
Mac 10.15.1
Xcode 11.3
ARFoundatinは、Unity公式のGitHubからARFoundationの最新プロジェクトをクローンしてきます。
ARFoundatinリンク
Live2DモデルはCubism3.0桃瀬ひよりを使用しました。※ARFoundationに関しては自分も勉強途中なので間違っているところもあるかもしれません今回はARKitFaceBlendShapesのシーンをメインで使っていきます。iPhone側のアプリで参考にするのはARKitBlendShapeVisualizer.csになります。
今回はこれをもとに改造していきます。ARFaceコンポーネントを取得していて、これを軸に作成されています。
ARFaceは顔情報の更新が検知できるので、ここのupdatedに更新ごとの処理を登録していく形になります。基本的に参考にしているscript内のUpdateFaceFeaturesメソッドで実装されています。NativeArrayの中に構造体で格納されているので必要な部位のデータだけ
取得します。foreachを使って構造体ごとに取り出していきます。
部位の選択はstruct内の部位情報と自分の欲しい部位が一致しているかで行っています。
ARKitBlendShapeLocation(enum)で部位指定できます。switch文部分が追加したコードですデータ格納用クラスを作成し
格納クラス→JSON→byteと変換しPCに送信していきます
送信タイミングは顔データが更新されると送信としました。送信方法はUDPで実装しています。
PC側が受信、iPhone側で送信で実装していますよく使われるUDPの通信です。
すでに多くの資料が公開されているので通信部分は省略します。
(UDP C# 実装で検索)データが受信できたら復元しLive2Dに適用していきます
データを復元したタイミングでnullチェックしておくのがオススメですモデルへのデータ適用はLive2D公式のドキュメントのパラメーター更新と同じ方法です(ドキュメントリンク)PC側でWi-Fiの設定をプライベートに変更
あとはポートの設定も変えとく(windows10 ポート開放で検索)iPhone側でWi-Fi設定からプロキシ設定を手動
サーバに使用するIPアドレスを
ポートに使用するポート番号を入力して保存多分ルーターとかのセキュリティ問題　(学校の学科専用Wi-Fiでやったらできなかった)どうやらiPhoneで残り電池残量等のポップアップが出ると接続が切れるっぽいので再接続NativeArrayは指定したAllocatorのタイプごとに開放処理が必要です
今回は、Tempを指定したので1フレーム以内です!
詳しくは Unity NativeArrayで検索！
(UnityDOTSなどでも使われるので、これからは必須の知識になりそう)


