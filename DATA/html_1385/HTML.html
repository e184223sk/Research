<!DOCTYPE html><html><head><meta charset="utf-8" /><title>サイゼリヤの間違い探しをロバストな画像処理で解く - Qiita</title><meta content="width=device-width,initial-scale=1,shrink-to-fit=no,viewport-fit=cover" name="viewport" /><meta content="#55c500" name="theme-color" /><meta content="XWpkTG32-_C4joZoJ_UsmDUi-zaH-hcrjF6ZC_FoFbk" name="google-site-verification" /><meta content="telephone=no" name="format-detection" /><link rel="canonical" href="https://qiita.com/ika_kk/items/32c4986825c86ad92f36" /><link href="/manifest.json" rel="manifest" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link as="script" href="https://www.googletagservices.com/tag/js/gpt.js" rel="preload" /><link href="https://securepubads.g.doubleclick.net" rel="preconnect" /><script async="" src="https://www.googletagservices.com/tag/js/gpt.js"></script><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="2Paont6duC1k7CkvmM9ILdrmTbamwRYAjK1xInKeOcxLAlq4vJsH7eVvNaiyfcK3P9zbToU8n3KCF7KUNtb6Sg==" /><link rel="shortcut icon" type="image/x-icon" href="https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico" /><link rel="apple-touch-icon" type="image/png" href="https://cdn.qiita.com/assets/favicons/public/apple-touch-icon-ec5ba42a24ae923f16825592efdc356f.png" /><link rel="stylesheet" media="all" href="https://cdn.qiita.com/assets/public/article-2eaa7dbedc42a8ea65c722cda46d0ebb.min.css" /><script src="https://cdn.qiita.com/assets/public/v3-article-bundle-63de2d91fef827269d3f6b958db2335b.min.js" defer="defer"></script><meta name="twitter:card" content="summary_large_image"><meta content="@Qiita" name="twitter:site" /><meta content="@ika_kk" name="twitter:creator" /><meta property="og:type" content="article"><meta property="og:title" content="サイゼリヤの間違い探しをロバストな画像処理で解く - Qiita"><meta property="og:image" content="https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0&amp;w=1200&amp;mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND00NEsxNDRLazQ0Szg0NE9xNDRPazQ0R3U2WmFUNllHVjQ0R0U1bzZpNDRHWDQ0S1M0NE90NDRPUTQ0SzU0NE9JNDRHcTU1Uzc1WU9QNVllbTU1Q0c0NEduNktlajQ0R1AmdHh0LWNvbG9yPSUyMzMzMyZ0eHQtZm9udD1IaXJhZ2lubyUyMFNhbnMlMjBXNiZ0eHQtc2l6ZT01NCZ0eHQtY2xpcD1lbGxpcHNpcyZ0eHQtYWxpZ249Y2VudGVyJTJDbWlkZGxlJnM9MGVhMzU1NGUwOWU5YmViYWYwYzU2ZmYzM2Q5ZWRlNGU&amp;mark-align=center%2Cmiddle&amp;blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RR2xyWVY5cmF3JnR4dC1jb2xvcj0lMjMzMzMmdHh0LWZvbnQ9SGlyYWdpbm8lMjBTYW5zJTIwVzYmdHh0LXNpemU9NDUmdHh0LWFsaWduPXJpZ2h0JTJDYm90dG9tJnM9MWMzZDFlYWNlZTE3YzM4MGRmOGMxMzJmZmUwZmQ2ODg&amp;blend-align=center%2Cmiddle&amp;blend-mode=normal&amp;s=43c2d1c93b49fef774f2a65f68d918f8"><meta property="og:description" content="

はじめに

初投稿です。よろしくお願いします。

サイゼリヤの間違い探しを画像処理を用いて解くプログラムを作成しました。
基本的には画像の差分をとってなんやかんやして間違いを見つける、という手法ですが、それに加え今回はロバスト性に..."><meta content="https://qiita.com/ika_kk/items/32c4986825c86ad92f36" property="og:url" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><meta content="C#,画像処理,OpenCV,OpenCvSharp,間違い探し" name="keywords" /><script>!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};
if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];
s.parentNode.insertBefore(t,s)}(window, document,'script',
'https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '668972150489891');
fbq('track', 'PageView');</script><style data-emotion-css="17jxvjw 11t2ec1 1dvr2p8 18lkoru 1g4cku8 1iupg5d ijvq0v 15cocm3 12rp90f 115f4t 1b8uj5v 79elbk 16hhh7b fcbn8c 1gj7nt 154zy0m yikrym 1jqivyb 1ode1bp le4d8r 1hbd3g7 1nzh4zz 38fzdi helsa7 8qb8m4 2imjyh he5w1s 70qvj9 3ojehk 100alwu 1dtnjt5 10ougpm 1ay9vb9 m19uds cgzq40 1wa99t2 1l3zk9f 4czcte 1yzj1fm 1uv1qiv 109dbrr 5jpx49 mnxgyc 1vlpknv fsjkhv 1b17vb0 7i7f4d"}>.css-17jxvjw{display:grid;display:-ms-grid;grid-template-columns:80px minmax(0,1fr) 300px;-ms-grid-columns:80px minmax(0,1fr) 300px;grid-template-rows:minmax(270px,auto) 1fr;-ms-grid-rows:minmax(270px,auto) 1fr;max-width:1280px;margin-right:auto;margin-left:auto;padding-top:24px;padding-right:24px;padding-left:24px;}@media (max-width:1200px){.css-17jxvjw{padding-bottom:0;padding-left:0;padding-right:0;}}@media (max-width:992px){.css-17jxvjw{grid-template-columns:80px 452px 300px;-ms-grid-columns:80px 452px 300px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}@media (max-width:770px){.css-17jxvjw{display:block;}}@media (max-width:480px){.css-17jxvjw{padding-top:0;}}.css-11t2ec1{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;z-index:5;position:-webkit-sticky;position:sticky;top:calc(56px + 24px + 16px + 32px - 16px);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:16px;width:80px;}.css-11t2ec1:after{content:'';display:table;}.css-11t2ec1:before{content:'';display:table;}@media (max-width:770px){.css-11t2ec1{display:none;}}.css-1dvr2p8{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-18lkoru{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;background-color:#FFFFFF;}.css-1g4cku8{display:inline-block;vertical-align:middle;height:20px;width:20px;fill:#55C500;}.css-1iupg5d{color:#55C500;cursor:pointer;font-size:14px;font-weight:bold;}.css-ijvq0v{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-15cocm3{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:#FFFFFF;border:2px solid #6E6F70;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:2px 0px 0px;width:40px;}.css-12rp90f{display:inline-block;vertical-align:bottom;height:17.77777777777778px;width:16px;fill:#6E6F70;}.css-115f4t{color:#6E6F70;font-size:14px;font-weight:bold;}.css-1b8uj5v{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;margin-bottom:16px;padding:0;}.css-79elbk{position:relative;}.css-16hhh7b{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;padding:0;}.css-fcbn8c{display:none;bottom:initial;left:initial;right:initial;top:initial;left:100%;top:calc(-8px - (14px * 1.8) - 16px - 4px);}.css-1gj7nt{color:rgba(0,0,0,0.6);font-size:14px;font-weight:bold;line-height:1.8;padding:8px 16px;}.css-154zy0m{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.87);cursor:pointer;font-size:16px;font-weight:normal;line-height:1.8;padding:4px 16px;}.css-154zy0m:hover{-webkit-text-decoration:none;text-decoration:none;background-color:#F2F2F2;}.css-yikrym{width:20px;}.css-1jqivyb{color:rgba(0,0,0,0.6);font-size:13px;}.css-1ode1bp{background-color:rgba(0,0,0,0.12);height:1px;width:100%;margin:8px 0;}.css-le4d8r{display:inline-block;vertical-align:middle;height:13px;width:13px;fill:rgba(0,0,0,0.6);}.css-1hbd3g7{height:250px;}.css-1nzh4zz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:16px 32px;background-color:#FBE69E;color:rgba(0,0,0,0.87);line-height:1.5;font-weight:600;}@media (max-width:770px){.css-1nzh4zz{padding:16px;}}.css-38fzdi{color:#CA832A;margin-right:4px;}.css-helsa7{background-color:#FFFFFF;padding:32px;margin-bottom:24px;}@media (max-width:992px){.css-helsa7{margin:0 auto 40px;}}@media (max-width:480px){.css-helsa7{margin:0 0 40px;padding:32px 16px;}}.css-8qb8m4{margin-bottom:48px;}.css-2imjyh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-he5w1s{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:100%;}@media (max-width:770px){.css-he5w1s{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}}.css-70qvj9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.css-3ojehk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;margin-right:4px;}.css-100alwu{display:inline-block;border-radius:50%;line-height:1;overflow:hidden;vertical-align:middle;}.css-1dtnjt5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-10ougpm{color:rgba(0,0,0,0.87);font-size:14px;font-weight:600;line-height:1.8;margin-right:4px;text-wrap:break-word;word-break:break-all;}.css-1ay9vb9{margin-right:16px;}.css-m19uds{color:rgba(0,0,0,0.6);font-size:14px;line-height:1.8;}.css-cgzq40{color:rgba(0,0,0,0.87);font-size:32px;font-weight:bold;line-height:1.4;margin-top:8px;text-wrap:break-word;word-break:break-all;}.css-1wa99t2{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.6);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:8px;}.css-1l3zk9f{color:rgba(0,0,0,0.6);font-size:20px;margin-right:8px;}.css-4czcte{margin-right:4px;color:inherit;font-size:14px;line-height:1.8;}.css-4czcte:not(:last-child)::after{content:',';margin-right:4px;}.css-1yzj1fm{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:32px;}.css-1uv1qiv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-size:20px;height:32px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-right:16px;outline:none;padding:0;width:32px;}.css-109dbrr{background-color:#F9F9F9;border-top:1px solid rgba(0,0,0,0.12);bottom:0;box-shadow:0px 1px 4px rgba(0,0,0,0.14);display:none;height:calc(env(safe-area-inset-bottom,0px) + 56px);-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding-bottom:env(safe-area-inset-bottom);position:-webkit-sticky;position:sticky;width:100%;z-index:2000;}@media (max-width:770px){.css-109dbrr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}.css-5jpx49{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-evenly;-webkit-justify-content:space-evenly;-ms-flex-pack:space-evenly;justify-content:space-evenly;width:100%;}.css-mnxgyc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1vlpknv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;margin-right:4px;background-color:#FFFFFF;}.css-fsjkhv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1b17vb0{color:#6E6F70;font-size:14px;font-weight:bold;margin-left:4px;}.css-7i7f4d{display:none;bottom:initial;left:initial;right:initial;top:initial;bottom:32px;right:0;}</style></head><body><div class="allWrapper"><div><div id="GlobalHeader-react-component-ebfebb94-0a74-4e08-a78b-62da6d93a6b4"><div class="st-Header"><div class="st-Header_container"><div class="st-Header_start"><a href="/" class="st-Header_logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 426.57 130"><circle cx="167.08" cy="21.4" r="12.28"></circle><path d="M250.81 29.66h23.48v18.9h-23.48z"></path><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z"></path><circle cx="216.33" cy="21.4" r="12.28"></circle></svg></a><div class="st-Header_communitySelector" tabindex="0"><span class="fa fa-caret-down"></span></div><div class="st-Header_dropdown"><div class="st-Header_dropdownHeading">Qiita Teams that are logged in</div><div class="st-Header_dropdownItemNote">You are not logged in to any team</div><hr class="st-Header_dropdownDivider st-Header_dropdownDivider-shrink"/><a href="https://teams-center.qiita.com/find_team" class="st-Header_dropdownItem"><span class="fa fa-fw fa-sign-in st-Header_dropdownItemIcon"></span><div>Log in to Qiita Team</div></a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Community</div><a href="/organizations" class="st-Header_dropdownItem">Organization</a><a href="/official-events/open" class="st-Header_dropdownItem">Event</a><a href="/advent-calendar" class="st-Header_dropdownItem">Advent Calendar</a><a href="https://qiitadon.com/" class="st-Header_dropdownItem" target="_blank">Qiitadon (β)</a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Service</div><a href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Jobs</a><a href="https://zine.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Zine</a><a href="https://blog.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Blog</a></div><form class="st-Header_search" action="/search" method="get"><span class="fa fa-search st-Header_searchIcon"></span><input type="search" class="st-Header_searchInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form><form class="st-Header_searchModal" action="/search" method="get"><input type="text" class="st-Header_searchModalInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form></div><div class="st-Header_end"><div class="st-Header_searchButton"><span class="fa fa-search"></span></div><a class="st-Header_signupButton" href="/signup?redirect_to=%2Fika_kk%2Fitems%2F32c4986825c86ad92f36">Signup</a><a class="st-Header_loginLink" href="/login?redirect_to=%2Fika_kk%2Fitems%2F32c4986825c86ad92f36">Login</a></div><div class="st-Header_overlay"></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="GlobalHeader" data-dom-id="GlobalHeader-react-component-ebfebb94-0a74-4e08-a78b-62da6d93a6b4">{"unreadNotificationsCount":null,"realms":[{"humanName":"Qiita","isCurrentRealm":true,"isQiita":true,"isQiitaTeam":false,"loggedInUser":null,"teamId":null,"url":"https://qiita.com/"}],"teamFindUrl":"https://teams-center.qiita.com/find_team","isTeamOnlyUser":null,"currentUser":null}</script>
      
</div><div class="st-HeaderAlert st-HeaderAlert-warning"><div class="st-HeaderAlert_body"></div></div><script type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"/","name":"Qiita"}},{"@type":"ListItem","position":2,"item":{"@id":"/tags/csharp","name":"C#"}}]}</script><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","datePublished":"2020-05-16T19:03:35.000+09:00","dateModified":"2020-05-17T02:57:38.000+09:00","headline":"サイゼリヤの間違い探しをロバストな画像処理で解く","image":"https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0\u0026w=1200\u0026mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND00NEsxNDRLazQ0Szg0NE9xNDRPazQ0R3U2WmFUNllHVjQ0R0U1bzZpNDRHWDQ0S1M0NE90NDRPUTQ0SzU0NE9JNDRHcTU1Uzc1WU9QNVllbTU1Q0c0NEduNktlajQ0R1AmdHh0LWNvbG9yPSUyMzMzMyZ0eHQtZm9udD1IaXJhZ2lubyUyMFNhbnMlMjBXNiZ0eHQtc2l6ZT01NCZ0eHQtY2xpcD1lbGxpcHNpcyZ0eHQtYWxpZ249Y2VudGVyJTJDbWlkZGxlJnM9MGVhMzU1NGUwOWU5YmViYWYwYzU2ZmYzM2Q5ZWRlNGU\u0026mark-align=center%2Cmiddle\u0026blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RR2xyWVY5cmF3JnR4dC1jb2xvcj0lMjMzMzMmdHh0LWZvbnQ9SGlyYWdpbm8lMjBTYW5zJTIwVzYmdHh0LXNpemU9NDUmdHh0LWFsaWduPXJpZ2h0JTJDYm90dG9tJnM9MWMzZDFlYWNlZTE3YzM4MGRmOGMxMzJmZmUwZmQ2ODg\u0026blend-align=center%2Cmiddle\u0026blend-mode=normal\u0026s=43c2d1c93b49fef774f2a65f68d918f8","mainEntityOfPage":"https://qiita.com/ika_kk/items/32c4986825c86ad92f36","author":{"@type":"Person","address":"長野","email":null,"identifier":"ika_kk","name":"ika_kk","image":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fs3-ap-northeast-1.amazonaws.com%2Fqiita-image-store%2F0%2F524480%2F7978c641be05c0d99ba7883fc80e7d65e80fdf94%2Fx_large.png%3F1573476625?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=9875149c54a6053ee50a3abf69f116cd","url":"https://qiita.com/ika_kk","description":"C生まれのJava育ちです。仕事ではC#とC++やってる静的型付け信者ですが、最近Pythonを勉強しはじめました。主な担当業務は画像処理です。","memberOf":[]},"publisher":{"@type":"Organization","name":"Qiita","logo":{"@type":"ImageObject","url":"//cdn.qiita.com/assets/public/qiita-logo-c39ded593afa388e2e1ba435b110554e.png"}}}</script><style type="text/css">.wb-CampaignLink {
  background-color: #333333;
  width: 100%;
}

.wb-CampaignLink_container {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  max-width: 1100px;
  margin: 0 auto;
  font-size: 13px;
  padding: 0.8em;
}
.wb-CampaignLink_container > a {
  color: #fff;
}

.wb-CampaignLink_container > a:hover {
  text-decoration: underline;
}</style><div class="wb-CampaignLink"><div class="wb-CampaignLink_container"><a target="_blank" id="header_text_message_1" href="https://zine.qiita.com/interview/202104-ga-technologies/?utm_source=qiita&amp;utm_medium=header-banner">「不動産取引をワンクリックで完結する」世界観へ。GA technologiesの取り組み</a><a target="_blank" id="header_text_message_2" href="https://zine.qiita.com/interview/202104-ga-technologies/?utm_source=qiita&amp;utm_medium=header-banner">詳しくはこちら</a></div><script>td.trackEvent(
  'front_events',
  {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"ika_kk","type":"items","id":"32c4986825c86ad92f36"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Show","data":{"message":"「不動産取引をワンクリックで完結する」世界観へ。GA technologiesの取り組み","url":"https://zine.qiita.com/interview/202104-ga-technologies/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
)</script><script>document.getElementById('header_text_message_1').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"ika_kk","type":"items","id":"32c4986825c86ad92f36"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_1","message":"「不動産取引をワンクリックで完結する」世界観へ。GA technologiesの取り組み","url":"https://zine.qiita.com/interview/202104-ga-technologies/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
  )
})</script><script>document.getElementById('header_text_message_2').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"ika_kk","type":"items","id":"32c4986825c86ad92f36"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_2","message":"「不動産取引をワンクリックで完結する」世界観へ。GA technologiesの取り組み","url":"https://zine.qiita.com/interview/202104-ga-technologies/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
  )
})</script></div><script type="application/json" id="js-react-on-rails-context">{"railsEnv":"production","inMailer":false,"i18nLocale":"en","i18nDefaultLocale":"en","href":"https://qiita.com/ika_kk/items/32c4986825c86ad92f36","location":"/ika_kk/items/32c4986825c86ad92f36","scheme":"https","host":"qiita.com","port":null,"pathname":"/ika_kk/items/32c4986825c86ad92f36","search":null,"httpAcceptLanguage":null,"actionPath":"public/items#show","settings":{"analyticsTrackingId":"UA-24675221-12","assetsMap":{},"csrfToken":"tNZP+iqmmuBn5uERo0qt/nMIWODbqzeL6sqsphLkMKknIr3cSKAlIOZl/ZaJ+CdkljLOGPhWvvnkcG8QVqzzLw==","locale":"en"},"currentUser":null,"isLoggedIn":false,"recaptchaSiteKey":"6LfNkiQTAAAAAM3UGnSquBy2akTITGNMO_QDxMw6","serverSide":false}</script>
<div id="PersonalArticlePage-react-component-788c8891-a0ad-4121-a0fa-b397c490f364"><div class="p-items_wrapper"><div class=" css-17jxvjw"><div class="css-11t2ec1"><div class="css-1dvr2p8"><button class=" css-18lkoru"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/ika_kk/items/32c4986825c86ad92f36/likers" class="css-1iupg5d">436</a></div><div class="css-ijvq0v"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-115f4t">231</span></div><div class="css-1b8uj5v"><span class="fa fa-twitter"></span></div><div class="css-1b8uj5v"><span class="fa fa-facebook"></span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-fcbn8c"><div class="css-1gj7nt">Improve article</div><a href="/drafts/32c4986825c86ad92f36/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/ika_kk/items/32c4986825c86ad92f36/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/ika_kk/items/32c4986825c86ad92f36/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/ika_kk/items/32c4986825c86ad92f36/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/ika_kk/items/32c4986825c86ad92f36.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div><div class="p-items_options"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_toc"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_main"><div class="css-1nzh4zz"><span class="fa fa-fw fa-warning css-38fzdi"></span><p>More than 1 year has passed since last update.</p></div><div class="css-helsa7"><div class="css-8qb8m4"><div class="css-2imjyh"><div class="css-he5w1s"><div class="css-70qvj9"><div class="css-3ojehk"><a href="/ika_kk"><img class="css-100alwu eyfquo10" src="https://s3-ap-northeast-1.amazonaws.com/qiita-image-store/0/524480/7978c641be05c0d99ba7883fc80e7d65e80fdf94/x_large.png?1573476625" width="24" height="24" loading="lazy"/></a></div><div class="css-1dtnjt5"><a href="/ika_kk" class="css-10ougpm">@<!-- -->ika_kk</a><div class="css-1ay9vb9"><span><meta content="2020-05-16T10:03:35Z"/><time dateTime="2020-05-16T17:57:38Z" class="css-m19uds">updated at 2020-05-16</time></span></div></div></div></div></div><h1 class="css-cgzq40">サイゼリヤの間違い探しをロバストな画像処理で解く</h1><div class="css-1wa99t2"><span class="fa fa-tags mr-1of2 css-1l3zk9f" aria-hidden="true"></span><a href="/tags/csharp" class="css-4czcte">C#</a><a href="/tags/%e7%94%bb%e5%83%8f%e5%87%a6%e7%90%86" class="css-4czcte">画像処理</a><a href="/tags/opencv" class="css-4czcte">OpenCV</a><a href="/tags/opencvsharp" class="css-4czcte">OpenCvSharp</a><a href="/tags/%e9%96%93%e9%81%95%e3%81%84%e6%8e%a2%e3%81%97" class="css-4czcte">間違い探し</a></div></div><section class="it-MdContent"><div id="personal-public-article-body"><div>
<h1>
<span id="はじめに" class="fragment"></span><a href="#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB"><i class="fa fa-link"></i></a>はじめに</h1>

<p>初投稿です。よろしくお願いします。</p>

<p>サイゼリヤの間違い探しを画像処理を用いて解くプログラムを作成しました。<br>
基本的には<strong>画像の差分</strong>をとってなんやかんやして間違いを見つける、という手法ですが、それに加え今回は<strong>ロバスト性</strong>に着目しました。<br>
まずは実行結果をご覧ください。</p>

<p>※ロバスト性… 本義は外乱の影響の受けづらさ。差分で間違い箇所を抽出するときは全く同じ距離・角度から撮影した2枚の画像が必要となりますが(少しでもずれていると誤検出がめっちゃ増える)、少しずれた2枚の画像同士の間違いも検出できるという意味でロバスト性と言っています。</p>

<h2>
<span id="実行結果" class="fragment"></span><a href="#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C"><i class="fa fa-link"></i></a>実行結果</h2>

<p>通常、差分で間違いを探す手法では2枚の画像をきちんと位置合わせする必要があるのですが、斜めから見た画像同士からでも間違い箇所を検出できています。<br>
最終目標は、<strong>スマホのカメラでサイゼの間違い探しを撮影し、その写真をもとに間違いを見つけること</strong>です。<br>
<a href="https://camo.qiitausercontent.com/523c85e09e3e0a702cb6c4cced5d6bf9d6d14d24/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f33303639303535662d386238362d316632302d323636642d3038373131306333633637392e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F3069055f-8b86-1f20-266d-087110c3c679.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=8ee9e0c0b0edbb330a52bf2f2f0119f5" alt="0_01.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/3069055f-8b86-1f20-266d-087110c3c679.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F3069055f-8b86-1f20-266d-087110c3c679.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=687d65bc9de42ca33cf4288d7732c732 1x" loading="lazy"></a><br>
<a href="https://camo.qiitausercontent.com/011ea5d191a046e00fe9799d3a63374989c2e233/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f66313730623130652d376534322d303366312d656233612d6464666562643134383330352e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Ff170b10e-7e42-03f1-eb3a-ddfebd148305.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=83fb928a3e35d2eca90dc3c07ff169cd" alt="0_02.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/f170b10e-7e42-03f1-eb3a-ddfebd148305.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Ff170b10e-7e42-03f1-eb3a-ddfebd148305.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=08a1240b93d61796487885b844d14911 1x" loading="lazy"></a></p>

<h1>
<span id="アルゴリズムの概要" class="fragment"></span><a href="#%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E6%A6%82%E8%A6%81"><i class="fa fa-link"></i></a>アルゴリズムの概要</h1>

<p>以下、使用した技術等をつらつらと書いていきます。<br>
恥ずかしながら初めてGitHub使ったのでちゃんと見られるか不安ですが、一応ソース類をアップしたのでよかったらご覧ください。<br>
<a href="https://github.com/ika-kk/SaizeriyaPj" class="autolink" rel="nofollow noopener" target="_blank">https://github.com/ika-kk/SaizeriyaPj</a></p>

<h2>
<span id="実装と環境" class="fragment"></span><a href="#%E5%AE%9F%E8%A3%85%E3%81%A8%E7%92%B0%E5%A2%83"><i class="fa fa-link"></i></a>実装と環境</h2>

<p>C#<br>
.NET Framework 4.6.1<br>
OpenCvSharp4<br>
Windows 10 Home<br>
Intel Core i7-6700 @ 3.40GHz<br>
RAM 16.0GB<br>
グラボは非搭載</p>

<h2>
<span id="フローチャート" class="fragment"></span><a href="#%E3%83%95%E3%83%AD%E3%83%BC%E3%83%81%E3%83%A3%E3%83%BC%E3%83%88"><i class="fa fa-link"></i></a>フローチャート</h2>

<ol>
<li>画像を2枚読み込む(以下SrcとTargetと記載します)</li>
<li>OpenCVの特徴量マッチングでSrcとTargetの対応点を取得する</li>
<li>対応点の情報をもとにSrcに射影変換を適用し、Targetと座標を一致させる</li>
<li>SrcとTargetの差分画像を取得する</li>
<li>差分画像の重要箇所のみを目立たせ、マスクを作成する</li>
<li>マスクをSrcとTargetにかぶせ、間違い箇所を目立たせる</li>
</ol>

<h2>
<span id="1-画像を2枚読み込む" class="fragment"></span><a href="#1-%E7%94%BB%E5%83%8F%E3%82%922%E6%9E%9A%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%80"><i class="fa fa-link"></i></a>1. 画像を2枚読み込む</h2>

<p>まずはサイゼリヤの間違い探しの画像を読み込みます。<br>
今回は<a href="https://www.saizeriya.co.jp/entertainment/" rel="nofollow noopener" target="_blank">サイゼリヤのホームページ</a>から画像をいただきました。<br>
なお、<strong>実際にサイゼに行って間違い探しの写真を撮る</strong>という状況を想定し、Photoshopで歪みを加えた画像を作成しました。</p>

<p>また、間違い探し以外の余分な情報を極力削るために、マスク機能(手動)を追加してあります。<br>
これに関してはこちらのブログを参考にしました。<br>
<a href="http://skylinker.blog.fc2.com/blog-entry-57.html" rel="nofollow noopener" target="_blank">【C#】レイヤー機能を作る｜いえひのプログラミング部屋</a></p>

<p>あと最近のスマホの写真は解像度が大きめなので、処理時間が結構がかかります。<br>
そのため、次の処理に進む際に、画像サイズを<strong>800[px]*600[px]</strong>におさまるサイズに縮小するようにしました。<br>
このサイズに縮小しても分解能はだいたい0.4[mm/px]になるため、幅・高さともに1~2mm以上の間違い箇所であれば検出できるはずです。</p>

<h2>
<span id="2-opencvの特徴量マッチングでsrcとtargetの対応点を取得する" class="fragment"></span><a href="#2-opencv%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%83%9E%E3%83%83%E3%83%81%E3%83%B3%E3%82%B0%E3%81%A7src%E3%81%A8target%E3%81%AE%E5%AF%BE%E5%BF%9C%E7%82%B9%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B"><i class="fa fa-link"></i></a>2. OpenCVの特徴量マッチングでSrcとTargetの対応点を取得する</h2>

<p>画像同士のマッチングには、色々な種類があります。<br>
・<a href="http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html" rel="nofollow noopener" target="_blank">テンプレートマッチング</a> (画像の濃淡を主に用いたマッチング)<br>
・<a href="https://www.visco-tech.com/technical/guidance/patternmatch/" rel="nofollow noopener" target="_blank">幾何形状マッチング</a> (エッジ情報を用いたマッチング)<br>
・<a href="http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_feature2d/py_matcher/py_matcher.html" rel="nofollow noopener" target="_blank">特徴点マッチング</a> (局所的な特徴点を利用するマッチング)<br>
・その他</p>

<p>色々比較した結果、今回は<strong>特徴量マッチング</strong>を使うことにしました。</p>

<table>
<thead>
<tr>
<th style="text-align: left">方式</th>
<th style="text-align: center">OpenCV</th>
<th style="text-align: center">形状変化への強さ</th>
<th style="text-align: center">色味の変化への強さ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left">テンプレートマッチング</td>
<td style="text-align: center">対応</td>
<td style="text-align: center">×</td>
<td style="text-align: center">×</td>
</tr>
<tr>
<td style="text-align: left">幾何形状マッチング</td>
<td style="text-align: center">非対応</td>
<td style="text-align: center">×</td>
<td style="text-align: center">○</td>
</tr>
<tr>
<td style="text-align: left">特徴点マッチング</td>
<td style="text-align: center">対応</td>
<td style="text-align: center">○</td>
<td style="text-align: center">△</td>
</tr>
</tbody>
</table>

<p>幾何形状マッチングはOpenCVには非実装だったため、自動的に候補から除外されます。個人的にはかなり便利なマッチング方式だと思うので、実装してほしいんですけどね…。</p>

<p>次に、形状変化への強さは特徴点マッチングが優秀です。<br>
テンプレートマッチングと幾何形状マッチングは、マッチングの元画像と対象画像が拡大・縮小・回転を用いて一致するものしか対応できません。<br>
一方の特徴点マッチングは、拡大・縮小・回転に加え、せん断・歪みまで対応できます。冒頭にもあるように<strong>斜めから見た画像(=歪み変形した画像)</strong>同士を比較したいので、特徴点マッチングを採用しました。<br>
ちなみに、拡大・縮小・回転・せん断が可能で、更に移動を実現できる変形を<strong>アフィン変換(変形)</strong>、このアフィン変換に歪み変形を加えたものを<strong>射影変換(変形)</strong>と呼びます。<br>
<a href="https://camo.qiitausercontent.com/c8cd29df8bf0b4676339d609eb776acd353939a3/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f39316333343337382d336438312d303237622d386537632d3735393834636330633733642e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F91c34378-3d81-027b-8e7c-75984cc0c73d.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=ca87021b6af49877076f02005fbb2170" alt="変換.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/91c34378-3d81-027b-8e7c-75984cc0c73d.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F91c34378-3d81-027b-8e7c-75984cc0c73d.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=ac97ec699061d6b05192915cb694dbab 1x" loading="lazy"></a></p>

<p>画像の多くの箇所が同時に色味の変化を起こすことはないだろうと予想し、特徴点マッチングで問題ないと判断しました。<br>
ちなみに、色味が変わってもエッジさえ検出できればマッチングの精度に影響しないという意味で、幾何形状マッチングは優秀です。一方テンプレートマッチングは輝度情報がキモになるので、色が変わると検出できなくなったり、精度が悪くなったりします。</p>

<p>特徴点マッチングにはSIFT法やSURF法など色々な手法が存在しますが、OpenCVではAKAZEという方式が一般的だそうです。<br>
実装にあたってはこちらの記事を参考にさせていただきました。<br>
<a href="https://qiita.com/miwazawa/items/8609209b52e0aa223014" id="reference-ac98652f5a8637533935">OpenCvSharpでAKAZEを用いて特徴量を検出する - Qiita</a></p>

<p>最終的に、以下の画像のように特徴点同士を対応付けすることができました。<br>
対応する特徴点同士をつないだ線が<strong>おおむね平行</strong>になっているのがわかります。<br>
誤った特徴点が対応付けされている箇所もいくつかありますが、これは次に行う変換の際に<strong>外れ値として無視される</strong>ので、あんまり気にしなくてもいいです。<br>
ちなみに、今回使用した特徴点の数は、全体の<strong>10%</strong>です。つまり本来はこの10倍の特徴点が検出されているのですが、処理が重くなること、外れ値を多く含むため使用する意味がないことから、<strong>一致度上位10%</strong>のみを抽出しています。<br>
<a href="https://camo.qiitausercontent.com/94e3c128413df700c659fbef4aa2f150dd88aeff/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f32383139373263612d636430312d323036352d383939652d6131396564343432376265392e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F281972ca-cd01-2065-899e-a19ed4427be9.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=0995888d39ca9eaf2c75606a4ab8e1ca" alt="特徴点マッチング.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/281972ca-cd01-2065-899e-a19ed4427be9.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F281972ca-cd01-2065-899e-a19ed4427be9.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=3f3aac4f1f9d5d517b4a6098f8d0f335 1x" loading="lazy"></a></p>

<h2>
<span id="3-対応点の情報をもとにsrcに射影変換を適用してtargetと座標を合わせる" class="fragment"></span><a href="#3-%E5%AF%BE%E5%BF%9C%E7%82%B9%E3%81%AE%E6%83%85%E5%A0%B1%E3%82%92%E3%82%82%E3%81%A8%E3%81%ABsrc%E3%81%AB%E5%B0%84%E5%BD%B1%E5%A4%89%E6%8F%9B%E3%82%92%E9%81%A9%E7%94%A8%E3%81%97%E3%81%A6target%E3%81%A8%E5%BA%A7%E6%A8%99%E3%82%92%E5%90%88%E3%82%8F%E3%81%9B%E3%82%8B"><i class="fa fa-link"></i></a>3. 対応点の情報をもとにSrcに射影変換を適用してTargetと座標を合わせる</h2>

<p>拡大縮小回転とせん断であれば前述のようにアフィン変換で事足りますが、今回は歪みも想定しているため、射影変換を使用しました。<strong>SrcをTargetに合わせこむ</strong>ようなイメージです。処理の具体的なフローはこんな感じです。</p>

<ol>
<li>特徴点の対応をベクトルで表現する</li>
<li>ベクトルの始点と終点を一致させるような射影変換を実現したい</li>
<li>そうなるような変換行列を作成する</li>
<li>変換行列にもとづき、画像の変形を行う</li>
</ol>

<p>以下はイメージ画像です。簡単のために4隅のベクトルしか書いていませんが、実際は画像中の一致度上位10%の特徴点同士のベクトル全てを考慮し、かつ外れ値は無視しつつ変形が行われています。</p>

<p><a href="https://camo.qiitausercontent.com/73658ea155b446acc38a0a10eaaf9cb7925dfe84/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f62613931666133342d623731352d656530302d323737332d6439346461336134343230652e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fba91fa34-b715-ee00-2773-d94da3a4420e.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=75aff51f331ef5a73847f3bbf5546afe" alt="射影変換.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/ba91fa34-b715-ee00-2773-d94da3a4420e.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fba91fa34-b715-ee00-2773-d94da3a4420e.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=1341c999a226427a69a6cbb93fe07848 1x" loading="lazy"></a><br>
OpenCvSharpでの実装方法はこちらを参考にしました。<br>
<a href="https://qiita.com/ka10ryu1/items/bd05aed321a7a154d8a1" id="reference-0b7bacb269e767a3c2c3">画像から特徴量を抽出し、透視変換行列を導出して画像を変形する - Qiita</a><br>
<a href="http://sourcechord.hatenablog.com/entry/2017/02/20/233042" rel="nofollow noopener" target="_blank">OpenCvSharpで透視投影の補正 - SourceChord</a><br>
<details><summary>実装(折りたたみ)</summary><div>

<div class="code-frame" data-lang="c#">
<div class="code-lang"><span class="bold">射影変換の実装部</span></div>
<div class="highlight"><pre class="with-code"><code><span class="n">Mat</span> <span class="n">SrcMat</span><span class="p">,</span> <span class="n">TargetMat</span><span class="p">;</span> <span class="c1">// 素材画像</span>
<span class="k">public</span> <span class="n">Mat</span> <span class="n">WarpedSrcMat</span><span class="p">;</span> <span class="c1">// 射影変換後の画像</span>
<span class="n">KeyPoint</span><span class="p">[]</span> <span class="n">KeyPtsSrc</span><span class="p">,</span> <span class="n">KeyPtsTarget</span><span class="p">;</span> <span class="c1">// 特徴量</span>
<span class="n">IEnumerable</span><span class="p">&lt;</span><span class="n">DMatch</span><span class="p">&gt;</span> <span class="n">SelectedMatched</span><span class="p">;</span> <span class="c1">// マッチング結果</span>

<span class="k">public</span> <span class="k">void</span> <span class="nf">FitSrcToTarget</span><span class="p">()</span>
<span class="p">{</span>
    <span class="c1">// 使用する特徴点の量だけベクトル用意</span>
    <span class="kt">int</span> <span class="n">size</span> <span class="p">=</span> <span class="n">SelectedMatched</span><span class="p">.</span><span class="nf">Count</span><span class="p">();</span>
    <span class="kt">var</span> <span class="n">getPtsSrc</span> <span class="p">=</span> <span class="k">new</span> <span class="n">Vec2f</span><span class="p">[</span><span class="n">size</span><span class="p">];</span>
    <span class="kt">var</span> <span class="n">getPtsTarget</span> <span class="p">=</span> <span class="k">new</span> <span class="n">Vec2f</span><span class="p">[</span><span class="n">size</span><span class="p">];</span>

    <span class="c1">// SrcとTarget画像の対応する特徴点の座標を取得し、ベクトル配列に格納していく。</span>
    <span class="kt">int</span> <span class="n">count</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span>
    <span class="k">foreach</span> <span class="p">(</span><span class="kt">var</span> <span class="n">item</span> <span class="k">in</span> <span class="n">SelectedMatched</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="kt">var</span> <span class="n">ptSrc</span> <span class="p">=</span> <span class="n">KeyPtsSrc</span><span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="n">QueryIdx</span><span class="p">].</span><span class="n">Pt</span><span class="p">;</span>
        <span class="kt">var</span> <span class="n">ptTarget</span> <span class="p">=</span> <span class="n">KeyPtsTarget</span><span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="n">TrainIdx</span><span class="p">].</span><span class="n">Pt</span><span class="p">;</span>
        <span class="n">getPtsSrc</span><span class="p">[</span><span class="n">count</span><span class="p">][</span><span class="m">0</span><span class="p">]</span> <span class="p">=</span> <span class="n">ptSrc</span><span class="p">.</span><span class="n">X</span><span class="p">;</span>
        <span class="n">getPtsSrc</span><span class="p">[</span><span class="n">count</span><span class="p">][</span><span class="m">1</span><span class="p">]</span> <span class="p">=</span> <span class="n">ptSrc</span><span class="p">.</span><span class="n">Y</span><span class="p">;</span>
        <span class="n">getPtsTarget</span><span class="p">[</span><span class="n">count</span><span class="p">][</span><span class="m">0</span><span class="p">]</span> <span class="p">=</span> <span class="n">ptTarget</span><span class="p">.</span><span class="n">X</span><span class="p">;</span>
        <span class="n">getPtsTarget</span><span class="p">[</span><span class="n">count</span><span class="p">][</span><span class="m">1</span><span class="p">]</span> <span class="p">=</span> <span class="n">ptTarget</span><span class="p">.</span><span class="n">Y</span><span class="p">;</span>
        <span class="n">count</span><span class="p">++;</span>
    <span class="p">}</span>

    <span class="c1">// SrcをTargetにあわせこむ変換行列homを取得する。ロバスト推定法はRANZAC。</span>
    <span class="kt">var</span> <span class="n">hom</span> <span class="p">=</span> <span class="n">Cv2</span><span class="p">.</span><span class="nf">FindHomography</span><span class="p">(</span>
        <span class="n">InputArray</span><span class="p">.</span><span class="nf">Create</span><span class="p">(</span><span class="n">getPtsSrc</span><span class="p">),</span>
        <span class="n">InputArray</span><span class="p">.</span><span class="nf">Create</span><span class="p">(</span><span class="n">getPtsTarget</span><span class="p">),</span>
        <span class="n">HomographyMethods</span><span class="p">.</span><span class="n">Ransac</span><span class="p">);</span>

    <span class="c1">// 行列homを用いてSrcに射影変換を適用する。</span>
    <span class="n">WarpedSrcMat</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">Mat</span><span class="p">();</span>
    <span class="n">Cv2</span><span class="p">.</span><span class="nf">WarpPerspective</span><span class="p">(</span>
        <span class="n">SrcMat</span><span class="p">,</span> <span class="n">WarpedSrcMat</span><span class="p">,</span> <span class="n">hom</span><span class="p">,</span>
        <span class="k">new</span> <span class="n">OpenCvSharp</span><span class="p">.</span><span class="nf">Size</span><span class="p">(</span><span class="n">TargetMat</span><span class="p">.</span><span class="n">Width</span><span class="p">,</span> <span class="n">TargetMat</span><span class="p">.</span><span class="n">Height</span><span class="p">));</span>
<span class="p">}</span>
</code></pre></div>
</div>

<p></p>
</div></details></p>

<h2>
<span id="4-srcとtargetの差分画像を取得する" class="fragment"></span><a href="#4-src%E3%81%A8target%E3%81%AE%E5%B7%AE%E5%88%86%E7%94%BB%E5%83%8F%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B"><i class="fa fa-link"></i></a>4. SrcとTargetの差分画像を取得する</h2>

<p>ようやく2枚の画像を得ることができました。いよいよレガシーな画像処理の出番です。<br>
とりあえず射影変換後の画像をPhotoshopで比較してみました(レイヤースタイル：差の絶対値を使用)。なかなかいい感じです。<br>
<a href="https://camo.qiitausercontent.com/757687489587a92391a6b8ee77913f082c5e426d/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f30323337666531352d623961312d376263622d376465662d3432333338653662393939362e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F0237fe15-b9a1-7bcb-7def-42338e6b9996.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=df74692049369c0782c0bcb27d2a8de2" alt="差の絶対値.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/0237fe15-b9a1-7bcb-7def-42338e6b9996.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F0237fe15-b9a1-7bcb-7def-42338e6b9996.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=d0e44ff694755f0099727286a0189a63 1x" loading="lazy"></a><br>
更に、チャンネルを別個に使用すれば検出精度が上がると思ったため、RGBとHSVの各チャンネル同士の差分画像を作成しました。ただしH(色相)、S(彩度)の差分はノイズが多くて使い物になりませんでした。変形時の補完に原因があるような気がします。<br>
そのため、今回は<strong>RGB</strong>と<strong>V(輝度)</strong>の<strong>計4チャンネル</strong>のみを使用することにしました。これらの画像に対して処理を施し、間違い箇所のみを目立たせるマスクを作っていきます。<br>
<a href="https://camo.qiitausercontent.com/8e049331c32c1b0d1eabde179a15aa9d59c1c9b9/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f30336437663732622d376130392d663235352d383631372d3431636366386234383138652e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F03d7f72b-7a09-f255-8617-41ccf8b4818e.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=577871e8440b3d933c0cd21423700fe2" alt="差分画像.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/03d7f72b-7a09-f255-8617-41ccf8b4818e.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F03d7f72b-7a09-f255-8617-41ccf8b4818e.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=0906f7d5fcedf02d9aec4cdf356193b1 1x" loading="lazy"></a><br>
余談ですが、OpenCVには画素にアクセスするメソッドSet/GetPixelが用意されています。最初はそれを使って実装したのですが、クソ遅かったです(800px*600pxの差分画像を1枚作るのに5秒くらいかかった)。<br>
その後LockBitsを使ってメモリ領域を直接いじる方法を知って、ようやく6枚で1秒というギリ耐えられるかなって速度になりました。それでも遅いけど。<br>
更にプログラム完成後に知ったんですけどPythonだとこんな感じで差分画像取れるんですね……便利……。<del>C#やめよ。</del></p>

<div class="code-frame" data-lang="python">
<div class="code-lang"><span class="bold">Python</span></div>
<div class="highlight"><pre class="with-code"><code><span class="n">diff</span> <span class="o">=</span> <span class="n">src</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">-</span> <span class="n">target</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div>
</div>

<p><strong>2020/05/17追記</strong><br>
<a href="https://qiita.com/albireo">@albireo</a> 氏からコメントを頂き、OpenCVにも差分画像を取得する <a href="http://opencv.jp/opencv-2.1/cpp/operations_on_arrays.html#cv-absdiff" rel="nofollow noopener" target="_blank"><strong>cv::absdiff</strong></a> があることを知りました。当然 <a href="https://shimat.github.io/opencvsharp_docs/html/6c7cefd1-59bc-a595-fe2a-0c8a709f8d16.htm" rel="nofollow noopener" target="_blank">OpenCvSharpにも組み込まれている</a>ので、これを使用すれば処理時間の大幅な短縮が見込めそうです。情報ありがとうございました。<br>
まずは何事も調べるのは大事ですね。ごめんなC#。</p>

<h2>
<span id="5-差分画像の重要箇所のみを目立たせマスクを作成する" class="fragment"></span><a href="#5-%E5%B7%AE%E5%88%86%E7%94%BB%E5%83%8F%E3%81%AE%E9%87%8D%E8%A6%81%E7%AE%87%E6%89%80%E3%81%AE%E3%81%BF%E3%82%92%E7%9B%AE%E7%AB%8B%E3%81%9F%E3%81%9B%E3%83%9E%E3%82%B9%E3%82%AF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B"><i class="fa fa-link"></i></a>5. 差分画像の重要箇所のみを目立たせ、マスクを作成する</h2>

<p>得られたRGBとVの計4枚の差分画像を2値化しますが、このままだとノイズが結構あるので、<strong>メディアンフィルタ</strong>を適用してごま塩ノイズを取っています。<br>
<a href="https://imagingsolution.blog.fc2.com/blog-entry-92.html" rel="nofollow noopener" target="_blank">メディアンフィルタ　画像処理ソリューション</a></p>

<p>ノイズ除去の次は4枚の画像を<strong>BitwizeOr</strong>で統合します。すなわち、各画像の画素ごとにOR演算を行い、<strong>どれか1枚でも白の箇所があったらその画素は白とする</strong>ことで1枚の統合画像を作成します。この処理によって、検出モレを防ぐことができます。<br>
<a href="https://cvtech.cc/bitwise/" rel="nofollow noopener" target="_blank">ピクセル毎の論理演算 AND NOT OR XOR | OpenCV画像解析入門</a></p>

<p>次に<strong>ブロブ処理</strong>で<strong>一定の大きさより小さい差分検出領域を省いて、ノイズ除去</strong>を行います。メディアンフィルタと被っているように思えますが、メディアンフィルタとブロブの違いは形状に依存するか否かというところです。また、ブロブ処理は、これはある大きさのかたまりをカウントすることができる、という利点があります。今回は実装<del>できなかった</del>していませんが「○個の間違いを表示する」といったように指定することも応用次第でできると思います。<br>
<a href="https://www.visco-tech.com/technical/direction-presence/blob/" rel="nofollow noopener" target="_blank">ブロブ解析～ヴィスコの画像処理技術 | ヴィスコ・テクノロジーズ株式会社</a></p>

<p>最後に、膨張処理を適用します。膨張処理とは、<strong>ある画素が白だったらその近傍の画素も白にする</strong>という処理のことです。<br>
完成イメージとして、間違い箇所を囲むようなマスクを作りたかったので、差分検出領域を広げるためにこの処理をかませています。これで最終的なマスク調整を行います。<br>
<a href="https://imagingsolution.blog.fc2.com/blog-entry-101.html" rel="nofollow noopener" target="_blank">膨張・収縮・オープニング・クロージング　画像処理ソリューション</a></p>

<p>フローの概略図はこんな感じです(Vチャンネル描き忘れましたが、実際は前述のとおり4チャンネルの画像を使用しています)。<br>
<a href="https://camo.qiitausercontent.com/0700d61567064bb80f6f24f6c51b803c4fb19a73/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f37386235643138652d656135372d303435322d656334332d3938613064613265336136322e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78b5d18e-ea57-0452-ec43-98a0da2e3a62.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=e0b153c5a27d07ec03287a965cadb720" alt="下処理.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/78b5d18e-ea57-0452-ec43-98a0da2e3a62.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78b5d18e-ea57-0452-ec43-98a0da2e3a62.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=1ff75c02abb419410623bdc45908fcdc 1x" loading="lazy"></a></p>

<p>なお、メディアンフィルタのカーネルサイズは3px、2値化閾値は128、膨張は5px、ブロブ面積下限値は10pxとしました。この値でおおむね良さそうですが、実際には細かい調整をすることがあるため、こんな感じのGUIも一応作成しました。<br>
<a href="https://camo.qiitausercontent.com/3d3b4bf8d3fcf3e3b0afc4dfb958729f74565814/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f65346138396530612d376639302d623339642d626634312d3934373239656231313262342e676966" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/e4a89e0a-7f90-b39d-bf41-94729eb112b4.gif" alt="2.gif" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/e4a89e0a-7f90-b39d-bf41-94729eb112b4.gif" loading="lazy"></a></p>

<h2>
<span id="6-マスクをsrcとtargetにかぶせる" class="fragment"></span><a href="#6-%E3%83%9E%E3%82%B9%E3%82%AF%E3%82%92src%E3%81%A8target%E3%81%AB%E3%81%8B%E3%81%B6%E3%81%9B%E3%82%8B"><i class="fa fa-link"></i></a>6. マスクをSrcとTargetにかぶせる</h2>

<p>射影変換したSrcとTargetを並べて表示し、両方にマスクをかぶせます。<br>
今回のプログラムでは、差分検出領域は透明色、それ以外は低透明度の黒とすることで、間違い箇所を際立たせています。<br>
無事10個の間違いの周辺がハイライトされていますね。<br>
両脇もハイライトされているのは、ダウンロードできる間違い探しの画像サイズがそもそも一致しておらず、端の方が削れてしまっているからです。<br>
<a href="https://camo.qiitausercontent.com/db8276c1d8537117d6cc47c8d12e4e92ecf614eb/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f62386237323531322d323036612d656263352d383135382d6236393236646432336266662e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fb8b72512-206a-ebc5-8158-b6926dd23bff.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=621a751168ea44c544889dbb01100742" alt="0_02.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/b8b72512-206a-ebc5-8158-b6926dd23bff.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fb8b72512-206a-ebc5-8158-b6926dd23bff.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=328678168217167f05a720fed2af2e35 1x" loading="lazy"></a></p>

<h1>
<span id="机上評価結果" class="fragment"></span><a href="#%E6%9C%BA%E4%B8%8A%E8%A9%95%E4%BE%A1%E7%B5%90%E6%9E%9C"><i class="fa fa-link"></i></a>机上評価結果</h1>

<p>適当に3種類の間違い探しを選んでプログラム実行したところ、いずれも10個の間違いが取得できています！<br>
にしても本当に難しいですね。<strong>個人的にヤバいと思ったのは2つめの右下の焼き鳥の串の角度です。</strong>こいつはやばい。<br>
<a href="https://camo.qiitausercontent.com/9b93f1702307718522be2f563723bb33cb821521/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f61653338633164622d663462662d613364312d353763662d3462376230363433646434342e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fae38c1db-f4bf-a3d1-57cf-4b7b0643dd44.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=bd3763b20c5f12355512b5c5a7104ade" alt="2019.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/ae38c1db-f4bf-a3d1-57cf-4b7b0643dd44.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fae38c1db-f4bf-a3d1-57cf-4b7b0643dd44.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=d15e8ad1e230f91beba542e21ecd7103 1x" loading="lazy"></a><br>
<a href="https://camo.qiitausercontent.com/f26e0eabcf796f4acb63d9c778ea11ef9e0239e6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f34373065633862612d383136332d393535612d313362332d3665313435653564383538392e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F470ec8ba-8163-955a-13b3-6e145e5d8589.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=89bec44042196e16c7d89bccbc1fc456" alt="201912.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/470ec8ba-8163-955a-13b3-6e145e5d8589.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F470ec8ba-8163-955a-13b3-6e145e5d8589.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=5e2c9686dcc620305345fb99dcef3fb2 1x" loading="lazy"></a><br>
<a href="https://camo.qiitausercontent.com/2a09925c68d3ac2fd6286f87a5577d2db455dec9/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f32346330653537612d306335352d366337632d386633382d3735373535396464613032642e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F24c0e57a-0c55-6c7c-8f38-757559dda02d.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=585d70e75aa4af6bcd2335789e5dd886" alt="2020.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/24c0e57a-0c55-6c7c-8f38-757559dda02d.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F24c0e57a-0c55-6c7c-8f38-757559dda02d.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=785b55d62d08f671accd1883e48bec87 1x" loading="lazy"></a></p>

<h1>
<span id="そして現実へ" class="fragment"></span><a href="#%E3%81%9D%E3%81%97%E3%81%A6%E7%8F%BE%E5%AE%9F%E3%81%B8"><i class="fa fa-link"></i></a>そして現実へ…</h1>

<p>プログラムは完成した。抜かりはない、完璧だ。<br>
いざ実戦といこう。</p>

<h2>
<span id="実際にサイゼで写真を撮ってみた結果" class="fragment"></span><a href="#%E5%AE%9F%E9%9A%9B%E3%81%AB%E3%82%B5%E3%82%A4%E3%82%BC%E3%81%A7%E5%86%99%E7%9C%9F%E3%82%92%E6%92%AE%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E7%B5%90%E6%9E%9C"><i class="fa fa-link"></i></a>実際にサイゼで写真を撮ってみた結果</h2>

<p>くどいようですが、今回ロバスト性を重視したのは、<strong>サイゼに行って間違い探しの写真を撮ってその流れで答えを見つけるというリアルタイム感の実現</strong>を目指してのことです。<br>
そのため、実際にiPhone Xで写真を撮ってこのプログラムに突っ込んでみました。果たして結果やいかに。<br>
<a href="https://camo.qiitausercontent.com/7e54448809dd8981b684c57690f18dd95d2c30f6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f37383132366139382d386566342d626536312d316130622d6364366635313431363030312e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78126a98-8ef4-be61-1a0b-cd6f51416001.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=b06261cce3db8c29d6721dfd5026fbe7" alt="実写3.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/78126a98-8ef4-be61-1a0b-cd6f51416001.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78126a98-8ef4-be61-1a0b-cd6f51416001.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=a8d6afe4131cb9d8f0d9abf42187ee83 1x" loading="lazy"></a><br>
<strong>デンッ！！</strong><br>
<a href="https://camo.qiitausercontent.com/ca3989e6e24102a4ff149dbf12a256a26927823b/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f36633235356166322d323338382d663664632d623964632d6530323464323735616562312e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F6c255af2-2388-f6dc-b9dc-e024d275aeb1.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=b6a65fb489ae068f69d9491a70ecc641" alt="実写.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/6c255af2-2388-f6dc-b9dc-e024d275aeb1.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F6c255af2-2388-f6dc-b9dc-e024d275aeb1.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=965abdb292a9db31716d71172972c7c8 1x" loading="lazy"></a><br>
ダメだったよ。</p>

<h2>
<span id="失敗の原因" class="fragment"></span><a href="#%E5%A4%B1%E6%95%97%E3%81%AE%E5%8E%9F%E5%9B%A0"><i class="fa fa-link"></i></a>失敗の原因</h2>

<p>この失敗の原因は、実際の対象はJpgでもPngでもなく<strong>厚紙に印刷されている</strong>というところにあるようです。つまり、画像によって3次元的な<strong>反り</strong>の具合が異なってしまっており、その歪みが補正しきれていません。射影変換ではこのタイプの歪みに対応できないのです。<br>
その結果、端にいけばいくほど画像間のずれが大きくなり、結果として端の方で誤検出が増大しています。左端の女の子やおじさん、右端の羊なんかが顕著です。<br>
<a href="https://camo.qiitausercontent.com/d3b4cc314c72f3ec6845cc3a6404f3542633b027/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f30396130643332662d353966662d396334342d396532372d6665356635393464306438372e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F09a0d32f-59ff-9c44-9e27-fe5f594d0d87.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=9ea8ed4fdce4d373cfe4ef0c173d7bca" alt="反り.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/09a0d32f-59ff-9c44-9e27-fe5f594d0d87.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F09a0d32f-59ff-9c44-9e27-fe5f594d0d87.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=c99583cf3f63a3714420b4c78c3cf2c5 1x" loading="lazy"></a><br>
ただし、画像の中央付近はいい感じに検出できています。特に豆の違いが検出できているので個人的にはかなり達成感があります。この豆だけが自力(人力)で解けなかったんですよね……。<br>
<a href="https://camo.qiitausercontent.com/5d7ba575dd445a6cc83ed4c61c69ce81537fb948/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f62633739343832312d643766352d383732392d656530362d6462303433643335393163632e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fbc794821-d7f5-8729-ee06-db043d3591cc.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=1588931df25d91be7e9dda4a319774ec" alt="実写2.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/bc794821-d7f5-8729-ee06-db043d3591cc.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fbc794821-d7f5-8729-ee06-db043d3591cc.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=bc2ac4eb88b46c4c77c83f7e9ba15e2b 1x" loading="lazy"></a></p>

<h2>
<span id="対策" class="fragment"></span><a href="#%E5%AF%BE%E7%AD%96"><i class="fa fa-link"></i></a>対策</h2>

<p>単なる歪みであれば任意直線上の特徴点同士の距離の比は変わらないため射影変換で対応できますが、今回の場合は3次元的に反っているため、より高度な変形によって丹念にあわせ込む必要があります。<br>
色々調べたところ、九州大学の情報系の研究室の資料がヒットしました。<br>
<a href="http://human.ait.kyushu-u.ac.jp/publications/iee-presen.pdf" rel="nofollow noopener" target="_blank">【スライド】２次元ワープを用いた顔画像処理顔画像処理 - 内田誠一氏、他2名</a><br>
<a href="http://human.ait.kyushu-u.ac.jp/publications/miyazaki-0155.pdf" rel="nofollow noopener" target="_blank">【論文】粗密DPに基づく画像の弾性マッチングアルゴリズム - 宮崎洋光氏、他2名</a><br>
一応概要を書いておきます。</p>

<ul>
<li>射影変換よりもフレキシブルに変形できる<strong>弾性マッチング</strong>というアルゴリズムがある

<ul>
<li>対応する点同士を一致させるアルゴリズム。例えば、ある人の正面からの写真と斜めからの写真をマッチングして、斜めからの写真を正面からの写真に変換できる。</li>
<li>この原理で反りに対応できそう</li>
</ul>
</li>
<li>ただし計算量が<strong>$O(N^{2}9^{2N})$</strong>らしい。こいつはやばい。

<ul>
<li>指数オーダーのヤバさ → <a href="https://www.youtube.com/watch?v=Q4gTV4r0zRs" rel="nofollow noopener" target="_blank">【YouTube】フカシギの数え方</a>
</li>
</ul>
</li>
<li>それを緩和するために<strong>粗密DP</strong>という動的計画法を適用する

<ul>
<li>これにより計算量は<strong>$O(N^{4})$</strong>となり、ある程度現実的なアルゴリズムとなる</li>
<li>粗密DPを低解像度の画像に適用することが前提</li>
</ul>
</li>
</ul>

<p>なるほどわからん。ただ、本論文が執筆されたのは2004年とだいぶ前なので、技術自体は枯れてきているかもしれません。勉強していつか実装したいですね。</p>

<h2>
<span id="その他課題" class="fragment"></span><a href="#%E3%81%9D%E3%81%AE%E4%BB%96%E8%AA%B2%E9%A1%8C"><i class="fa fa-link"></i></a>その他課題</h2>

<h3>
<span id="極端に小さい間違いは検出できない" class="fragment"></span><a href="#%E6%A5%B5%E7%AB%AF%E3%81%AB%E5%B0%8F%E3%81%95%E3%81%84%E9%96%93%E9%81%95%E3%81%84%E3%81%AF%E6%A4%9C%E5%87%BA%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84"><i class="fa fa-link"></i></a>極端に小さい間違いは検出できない</h3>

<p>画像を合わせ込む段階で画像全体の特徴点を使っているため、当然ながら間違い箇所の特徴点も使用しています。現状、そういった箇所は閾値を設定して外れ値とすることで無視しています。<br>
ただし、<strong>2枚の画像両方に似たような特徴点があり、かつその2点の距離が比較的近い場合</strong>、その2点は同じであるとみなされ、<strong>射影変換の精度に影響する可能性</strong>があります。サイゼの間違い探しには対象がずれているだけ、という間違いも結構あるので、この影響は無視できません。<br>
実際、以下の画像の場合だと間違いの箇所がかなり細いため、プログラムを実行した結果ノイズとみなされてしまいました。<br>
<a href="https://www.saizeriya.co.jp/entertainment/rice.html" rel="nofollow noopener" target="_blank">2006年8月の間違い探し - 左下の時計の短針に注目</a></p>

<p>この解決策として、「マッチングの閾値を追い込む」「画像の一部分のみの特徴点を用いて射影変換する」といった方法が考えられます。<br>
ただし、前者は閾値を上回る間違い箇所の特徴点が無いことを証明できず、後者はその一部分に間違いがあった場合意味がない上に、一部分だけだと射影変換の精度が不安です。よって、これらの解決策は根本的なものではありません。<br>
あとは紙自体の反りを補正した上での話になりますが、間違い探しの<strong>冊子のエッジ</strong>を利用できるような気もします。要検討ですね。</p>

<h3>
<span id="サイゼで実行したい" class="fragment"></span><a href="#%E3%82%B5%E3%82%A4%E3%82%BC%E3%81%A7%E5%AE%9F%E8%A1%8C%E3%81%97%E3%81%9F%E3%81%84"><i class="fa fa-link"></i></a>サイゼで実行したい</h3>

<p><strong>「サイゼに行く→注文する→写真を撮る→実行する→料理が来るまでに間違いを全て見つける」</strong>というのが理想のフローです。<br>
でもスマホアプリ作ったことないので諦めました。Xamarin勉強します。<br>
また、スマホで動かすためにはもっと処理を軽くする必要がありますね。マシンパワーに頼らない実装……。</p>

<h1>
<span id="さいごに" class="fragment"></span><a href="#%E3%81%95%E3%81%84%E3%81%94%E3%81%AB"><i class="fa fa-link"></i></a>さいごに</h1>

<p>このたび初めてOpenCV（OpenCvSharp）をまともにいじりましたが、思いの外色々なことが実現できて楽しかったです。</p>

<p>また、今回使用した実写画像は、サイゼにテイクアウトを買いに行ったときに撮影しました。<br>
テイクアウトかなり良かったので是非みなさまもおうちでサイゼしましょう。<br>
<a href="https://www.saizeriya.co.jp/" rel="nofollow noopener" target="_blank">サイゼリヤトップページ｜サイゼリヤ</a><br>
<a href="https://camo.qiitausercontent.com/f36d660d46820a959767995fa91105d2056c5005/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f34646331333431632d336533612d303664632d373863352d3465363938626166643330352e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F4dc1341c-3e3a-06dc-78c5-4e698bafd305.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=4706cdcc0243f8983c2ba720c5f7ff6f" alt="takeout.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/4dc1341c-3e3a-06dc-78c5-4e698bafd305.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F4dc1341c-3e3a-06dc-78c5-4e698bafd305.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=fe4fc656eb81b845fc8c3ac75a9032a5 1x" loading="lazy"></a></p>
</div></div></section><div class="css-1yzj1fm"><div class="css-1uv1qiv"><span class="fa fa-twitter"></span></div><div class="css-1uv1qiv"><span class="fa fa-facebook"></span></div></div><div class="apm-Content"><div class="apm-Content_title">Why not register and get more from Qiita?</div><ol class="apm-Content_list"><li>We will deliver articles that match you<div class="description">By following users and tags, you can catch up information on technical fields that you are interested in as a whole</div></li><li>you can read useful information later efficiently<div class="description">By &quot;stocking&quot; the articles you like, you can search right away</div></li><div><a class="apm-Content_help" href="https://help.qiita.com/ja/articles/qiita-login-user" target="_blank"><i class="fa fa-fw fa-arrow-circle-right"></i>What you can do with signing up</a></div></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2Fika_kk%2Fitems%2F32c4986825c86ad92f36&amp;realm=qiita" class="apm-Content_button apm-Content_button-signup">Sign up</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2Fika_kk%2Fitems%2F32c4986825c86ad92f36&amp;realm=qiita" class="apm-Content_button apm-Content_button-signin">Login</a></div></div><div class="css-helsa7"></div></div></div></div><div class="css-109dbrr"><div class="css-5jpx49"><div class="css-mnxgyc"><button class=" css-1vlpknv"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/ika_kk/items/32c4986825c86ad92f36/likers" class="css-1iupg5d">436</a></div><div class="css-fsjkhv"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-1b17vb0">231</span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-7i7f4d"><div class="css-1gj7nt">Improve article</div><a href="/drafts/32c4986825c86ad92f36/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/ika_kk/items/32c4986825c86ad92f36/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/ika_kk/items/32c4986825c86ad92f36/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/ika_kk/items/32c4986825c86ad92f36/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/ika_kk/items/32c4986825c86ad92f36.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="PersonalArticlePage" data-dom-id="PersonalArticlePage-react-component-788c8891-a0ad-4121-a0fa-b397c490f364">{"authorAnalyticsTrackingId":null,"organizationAnalyticsTrackingId":null}</script>
      
<footer id="globalFooter" class="st-Footer"><div class="st-Footer_container"><div class="st-Footer_start"><div class="st-Footer_logo"><svg viewbox="0 0 426.57 130" xmlns="http://www.w3.org/2000/svg"><circle cx="167.08" cy="21.4" r="12.28" /><path d="M250.81 29.66h23.48v18.9h-23.48z" /><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z" /><circle cx="216.33" cy="21.4" r="12.28" /></svg></div><div class="st-Footer_catchcopy">How developers code is here.</div><div class="st-Footer_socials"><a class="fa fa-twitter" href="https://twitter.com/qiita"></a><a class="fa fa-facebook-square" href="https://www.facebook.com/qiita/"></a></div></div><div class="st-Footer_end"><div class="st-Footer_qiita"><div class="st-Footer_label">Qiita</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="/about">About</a><a href="/terms">Terms</a><a href="/privacy">Privacy</a><a target="_blank" href="http://help.qiita.com/ja/articles/qiita-community-guideline">Guideline</a><a target="_blank" href="https://help.qiita.com/ja/articles/others-brand-guideline">Design Guideline</a></div><div class="st-Footer_column"><a href="/release-notes">Release</a><a href="/api/v2/docs">API</a><a href="/feedback/new">ご意見</a><a href="https://help.qiita.com">Help</a><a target="_blank" href="https://qiita.com/ads?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Advertisement</a></div></div></div><div class="st-Footer_increments"><div class="st-Footer_label">Increments</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="https://increments.co.jp/company/">About</a><a href="https://increments.co.jp/jobs/">採用情報</a><a href="https://blog.qiita.com">Blog</a></div><div class="st-Footer_column"><a href="https://teams.qiita.com/">Qiita Team</a><a href="https://jobs.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Jobs</a><a href="https://zine.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Zine</a></div></div></div></div></div><div class="st-Footer_copyright">© 2011-2021 Increments Inc.</div></footer><div id="Snackbar-react-component-56a645f8-4f8e-484b-bc8f-b77dbe760917"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="Snackbar" data-dom-id="Snackbar-react-component-56a645f8-4f8e-484b-bc8f-b77dbe760917">{}</script>
      
<div id="LoginModal-react-component-ff137730-3d74-4153-b622-ae466dd27a62"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="LoginModal" data-dom-id="LoginModal-react-component-ff137730-3d74-4153-b622-ae466dd27a62">{}</script>
      
<div id="StockModal-react-component-08b514a7-ba10-4869-a27d-67e238d48d75"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="StockModal" data-dom-id="StockModal-react-component-08b514a7-ba10-4869-a27d-67e238d48d75">{}</script>
      
</div><div id="dataContainer" style="display: none;" data-config="{&quot;actionPath&quot;:&quot;public/items#show&quot;,&quot;settings&quot;:{&quot;analyticsTrackingId&quot;:&quot;UA-24675221-12&quot;,&quot;assetsMap&quot;:{},&quot;csrfToken&quot;:&quot;vI1Bg052qMCA1Tl9I2eEaVRLPLGI7yFD0lqyfF+6tZwvebOlLHAXAAFWJfoJ1Q7zsXGqSasSqDHc4HHKG/J2Gg==&quot;,&quot;locale&quot;:&quot;en&quot;},&quot;currentUser&quot;:null}" /></body></html><script type="application/json" data-js-react-on-rails-store="AppStoreWithReactOnRails">{"snackbar":{"type":"","body":"","isActive":false},"article":{"article":{"body":"\n\u003ch1\u003e\n\u003cspan id=\"はじめに\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eはじめに\u003c/h1\u003e\n\n\u003cp\u003e初投稿です。よろしくお願いします。\u003c/p\u003e\n\n\u003cp\u003eサイゼリヤの間違い探しを画像処理を用いて解くプログラムを作成しました。\u003cbr\u003e\n基本的には\u003cstrong\u003e画像の差分\u003c/strong\u003eをとってなんやかんやして間違いを見つける、という手法ですが、それに加え今回は\u003cstrong\u003eロバスト性\u003c/strong\u003eに着目しました。\u003cbr\u003e\nまずは実行結果をご覧ください。\u003c/p\u003e\n\n\u003cp\u003e※ロバスト性… 本義は外乱の影響の受けづらさ。差分で間違い箇所を抽出するときは全く同じ距離・角度から撮影した2枚の画像が必要となりますが(少しでもずれていると誤検出がめっちゃ増える)、少しずれた2枚の画像同士の間違いも検出できるという意味でロバスト性と言っています。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"実行結果\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実行結果\u003c/h2\u003e\n\n\u003cp\u003e通常、差分で間違いを探す手法では2枚の画像をきちんと位置合わせする必要があるのですが、斜めから見た画像同士からでも間違い箇所を検出できています。\u003cbr\u003e\n最終目標は、\u003cstrong\u003eスマホのカメラでサイゼの間違い探しを撮影し、その写真をもとに間違いを見つけること\u003c/strong\u003eです。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/523c85e09e3e0a702cb6c4cced5d6bf9d6d14d24/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f33303639303535662d386238362d316632302d323636642d3038373131306333633637392e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F3069055f-8b86-1f20-266d-087110c3c679.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=8ee9e0c0b0edbb330a52bf2f2f0119f5\" alt=\"0_01.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/3069055f-8b86-1f20-266d-087110c3c679.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F3069055f-8b86-1f20-266d-087110c3c679.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=687d65bc9de42ca33cf4288d7732c732 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/011ea5d191a046e00fe9799d3a63374989c2e233/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f66313730623130652d376534322d303366312d656233612d6464666562643134383330352e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Ff170b10e-7e42-03f1-eb3a-ddfebd148305.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=83fb928a3e35d2eca90dc3c07ff169cd\" alt=\"0_02.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/f170b10e-7e42-03f1-eb3a-ddfebd148305.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Ff170b10e-7e42-03f1-eb3a-ddfebd148305.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=08a1240b93d61796487885b844d14911 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"アルゴリズムの概要\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E6%A6%82%E8%A6%81\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eアルゴリズムの概要\u003c/h1\u003e\n\n\u003cp\u003e以下、使用した技術等をつらつらと書いていきます。\u003cbr\u003e\n恥ずかしながら初めてGitHub使ったのでちゃんと見られるか不安ですが、一応ソース類をアップしたのでよかったらご覧ください。\u003cbr\u003e\n\u003ca href=\"https://github.com/ika-kk/SaizeriyaPj\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttps://github.com/ika-kk/SaizeriyaPj\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"実装と環境\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E8%A3%85%E3%81%A8%E7%92%B0%E5%A2%83\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実装と環境\u003c/h2\u003e\n\n\u003cp\u003eC#\u003cbr\u003e\n.NET Framework 4.6.1\u003cbr\u003e\nOpenCvSharp4\u003cbr\u003e\nWindows 10 Home\u003cbr\u003e\nIntel Core i7-6700 @ 3.40GHz\u003cbr\u003e\nRAM 16.0GB\u003cbr\u003e\nグラボは非搭載\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"フローチャート\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%83%95%E3%83%AD%E3%83%BC%E3%83%81%E3%83%A3%E3%83%BC%E3%83%88\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eフローチャート\u003c/h2\u003e\n\n\u003col\u003e\n\u003cli\u003e画像を2枚読み込む(以下SrcとTargetと記載します)\u003c/li\u003e\n\u003cli\u003eOpenCVの特徴量マッチングでSrcとTargetの対応点を取得する\u003c/li\u003e\n\u003cli\u003e対応点の情報をもとにSrcに射影変換を適用し、Targetと座標を一致させる\u003c/li\u003e\n\u003cli\u003eSrcとTargetの差分画像を取得する\u003c/li\u003e\n\u003cli\u003e差分画像の重要箇所のみを目立たせ、マスクを作成する\u003c/li\u003e\n\u003cli\u003eマスクをSrcとTargetにかぶせ、間違い箇所を目立たせる\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"1-画像を2枚読み込む\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#1-%E7%94%BB%E5%83%8F%E3%82%922%E6%9E%9A%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%80\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e1. 画像を2枚読み込む\u003c/h2\u003e\n\n\u003cp\u003eまずはサイゼリヤの間違い探しの画像を読み込みます。\u003cbr\u003e\n今回は\u003ca href=\"https://www.saizeriya.co.jp/entertainment/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eサイゼリヤのホームページ\u003c/a\u003eから画像をいただきました。\u003cbr\u003e\nなお、\u003cstrong\u003e実際にサイゼに行って間違い探しの写真を撮る\u003c/strong\u003eという状況を想定し、Photoshopで歪みを加えた画像を作成しました。\u003c/p\u003e\n\n\u003cp\u003eまた、間違い探し以外の余分な情報を極力削るために、マスク機能(手動)を追加してあります。\u003cbr\u003e\nこれに関してはこちらのブログを参考にしました。\u003cbr\u003e\n\u003ca href=\"http://skylinker.blog.fc2.com/blog-entry-57.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003e【C#】レイヤー機能を作る｜いえひのプログラミング部屋\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eあと最近のスマホの写真は解像度が大きめなので、処理時間が結構がかかります。\u003cbr\u003e\nそのため、次の処理に進む際に、画像サイズを\u003cstrong\u003e800[px]*600[px]\u003c/strong\u003eにおさまるサイズに縮小するようにしました。\u003cbr\u003e\nこのサイズに縮小しても分解能はだいたい0.4[mm/px]になるため、幅・高さともに1~2mm以上の間違い箇所であれば検出できるはずです。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"2-opencvの特徴量マッチングでsrcとtargetの対応点を取得する\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#2-opencv%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%83%9E%E3%83%83%E3%83%81%E3%83%B3%E3%82%B0%E3%81%A7src%E3%81%A8target%E3%81%AE%E5%AF%BE%E5%BF%9C%E7%82%B9%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e2. OpenCVの特徴量マッチングでSrcとTargetの対応点を取得する\u003c/h2\u003e\n\n\u003cp\u003e画像同士のマッチングには、色々な種類があります。\u003cbr\u003e\n・\u003ca href=\"http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003eテンプレートマッチング\u003c/a\u003e (画像の濃淡を主に用いたマッチング)\u003cbr\u003e\n・\u003ca href=\"https://www.visco-tech.com/technical/guidance/patternmatch/\" rel=\"nofollow noopener\" target=\"_blank\"\u003e幾何形状マッチング\u003c/a\u003e (エッジ情報を用いたマッチング)\u003cbr\u003e\n・\u003ca href=\"http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_feature2d/py_matcher/py_matcher.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003e特徴点マッチング\u003c/a\u003e (局所的な特徴点を利用するマッチング)\u003cbr\u003e\n・その他\u003c/p\u003e\n\n\u003cp\u003e色々比較した結果、今回は\u003cstrong\u003e特徴量マッチング\u003c/strong\u003eを使うことにしました。\u003c/p\u003e\n\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align: left\"\u003e方式\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003eOpenCV\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003e形状変化への強さ\u003c/th\u003e\n\u003cth style=\"text-align: center\"\u003e色味の変化への強さ\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003eテンプレートマッチング\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e対応\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e×\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e×\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003e幾何形状マッチング\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e非対応\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e×\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e○\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align: left\"\u003e特徴点マッチング\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e対応\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e○\u003c/td\u003e\n\u003ctd style=\"text-align: center\"\u003e△\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\n\u003cp\u003e幾何形状マッチングはOpenCVには非実装だったため、自動的に候補から除外されます。個人的にはかなり便利なマッチング方式だと思うので、実装してほしいんですけどね…。\u003c/p\u003e\n\n\u003cp\u003e次に、形状変化への強さは特徴点マッチングが優秀です。\u003cbr\u003e\nテンプレートマッチングと幾何形状マッチングは、マッチングの元画像と対象画像が拡大・縮小・回転を用いて一致するものしか対応できません。\u003cbr\u003e\n一方の特徴点マッチングは、拡大・縮小・回転に加え、せん断・歪みまで対応できます。冒頭にもあるように\u003cstrong\u003e斜めから見た画像(=歪み変形した画像)\u003c/strong\u003e同士を比較したいので、特徴点マッチングを採用しました。\u003cbr\u003e\nちなみに、拡大・縮小・回転・せん断が可能で、更に移動を実現できる変形を\u003cstrong\u003eアフィン変換(変形)\u003c/strong\u003e、このアフィン変換に歪み変形を加えたものを\u003cstrong\u003e射影変換(変形)\u003c/strong\u003eと呼びます。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/c8cd29df8bf0b4676339d609eb776acd353939a3/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f39316333343337382d336438312d303237622d386537632d3735393834636330633733642e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F91c34378-3d81-027b-8e7c-75984cc0c73d.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=ca87021b6af49877076f02005fbb2170\" alt=\"変換.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/91c34378-3d81-027b-8e7c-75984cc0c73d.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F91c34378-3d81-027b-8e7c-75984cc0c73d.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=ac97ec699061d6b05192915cb694dbab 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e画像の多くの箇所が同時に色味の変化を起こすことはないだろうと予想し、特徴点マッチングで問題ないと判断しました。\u003cbr\u003e\nちなみに、色味が変わってもエッジさえ検出できればマッチングの精度に影響しないという意味で、幾何形状マッチングは優秀です。一方テンプレートマッチングは輝度情報がキモになるので、色が変わると検出できなくなったり、精度が悪くなったりします。\u003c/p\u003e\n\n\u003cp\u003e特徴点マッチングにはSIFT法やSURF法など色々な手法が存在しますが、OpenCVではAKAZEという方式が一般的だそうです。\u003cbr\u003e\n実装にあたってはこちらの記事を参考にさせていただきました。\u003cbr\u003e\n\u003ca href=\"https://qiita.com/miwazawa/items/8609209b52e0aa223014\" id=\"reference-ac98652f5a8637533935\"\u003eOpenCvSharpでAKAZEを用いて特徴量を検出する - Qiita\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e最終的に、以下の画像のように特徴点同士を対応付けすることができました。\u003cbr\u003e\n対応する特徴点同士をつないだ線が\u003cstrong\u003eおおむね平行\u003c/strong\u003eになっているのがわかります。\u003cbr\u003e\n誤った特徴点が対応付けされている箇所もいくつかありますが、これは次に行う変換の際に\u003cstrong\u003e外れ値として無視される\u003c/strong\u003eので、あんまり気にしなくてもいいです。\u003cbr\u003e\nちなみに、今回使用した特徴点の数は、全体の\u003cstrong\u003e10%\u003c/strong\u003eです。つまり本来はこの10倍の特徴点が検出されているのですが、処理が重くなること、外れ値を多く含むため使用する意味がないことから、\u003cstrong\u003e一致度上位10%\u003c/strong\u003eのみを抽出しています。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/94e3c128413df700c659fbef4aa2f150dd88aeff/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f32383139373263612d636430312d323036352d383939652d6131396564343432376265392e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F281972ca-cd01-2065-899e-a19ed4427be9.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=0995888d39ca9eaf2c75606a4ab8e1ca\" alt=\"特徴点マッチング.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/281972ca-cd01-2065-899e-a19ed4427be9.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F281972ca-cd01-2065-899e-a19ed4427be9.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=3f3aac4f1f9d5d517b4a6098f8d0f335 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"3-対応点の情報をもとにsrcに射影変換を適用してtargetと座標を合わせる\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#3-%E5%AF%BE%E5%BF%9C%E7%82%B9%E3%81%AE%E6%83%85%E5%A0%B1%E3%82%92%E3%82%82%E3%81%A8%E3%81%ABsrc%E3%81%AB%E5%B0%84%E5%BD%B1%E5%A4%89%E6%8F%9B%E3%82%92%E9%81%A9%E7%94%A8%E3%81%97%E3%81%A6target%E3%81%A8%E5%BA%A7%E6%A8%99%E3%82%92%E5%90%88%E3%82%8F%E3%81%9B%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e3. 対応点の情報をもとにSrcに射影変換を適用してTargetと座標を合わせる\u003c/h2\u003e\n\n\u003cp\u003e拡大縮小回転とせん断であれば前述のようにアフィン変換で事足りますが、今回は歪みも想定しているため、射影変換を使用しました。\u003cstrong\u003eSrcをTargetに合わせこむ\u003c/strong\u003eようなイメージです。処理の具体的なフローはこんな感じです。\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e特徴点の対応をベクトルで表現する\u003c/li\u003e\n\u003cli\u003eベクトルの始点と終点を一致させるような射影変換を実現したい\u003c/li\u003e\n\u003cli\u003eそうなるような変換行列を作成する\u003c/li\u003e\n\u003cli\u003e変換行列にもとづき、画像の変形を行う\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e以下はイメージ画像です。簡単のために4隅のベクトルしか書いていませんが、実際は画像中の一致度上位10%の特徴点同士のベクトル全てを考慮し、かつ外れ値は無視しつつ変形が行われています。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://camo.qiitausercontent.com/73658ea155b446acc38a0a10eaaf9cb7925dfe84/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f62613931666133342d623731352d656530302d323737332d6439346461336134343230652e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fba91fa34-b715-ee00-2773-d94da3a4420e.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=75aff51f331ef5a73847f3bbf5546afe\" alt=\"射影変換.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/ba91fa34-b715-ee00-2773-d94da3a4420e.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fba91fa34-b715-ee00-2773-d94da3a4420e.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=1341c999a226427a69a6cbb93fe07848 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\nOpenCvSharpでの実装方法はこちらを参考にしました。\u003cbr\u003e\n\u003ca href=\"https://qiita.com/ka10ryu1/items/bd05aed321a7a154d8a1\" id=\"reference-0b7bacb269e767a3c2c3\"\u003e画像から特徴量を抽出し、透視変換行列を導出して画像を変形する - Qiita\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"http://sourcechord.hatenablog.com/entry/2017/02/20/233042\" rel=\"nofollow noopener\" target=\"_blank\"\u003eOpenCvSharpで透視投影の補正 - SourceChord\u003c/a\u003e\u003cbr\u003e\n\u003cdetails\u003e\u003csummary\u003e実装(折りたたみ)\u003c/summary\u003e\u003cdiv\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"c#\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003e射影変換の実装部\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003eMat\u003c/span\u003e \u003cspan class=\"n\"\u003eSrcMat\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eTargetMat\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 素材画像\u003c/span\u003e\n\u003cspan class=\"k\"\u003epublic\u003c/span\u003e \u003cspan class=\"n\"\u003eMat\u003c/span\u003e \u003cspan class=\"n\"\u003eWarpedSrcMat\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 射影変換後の画像\u003c/span\u003e\n\u003cspan class=\"n\"\u003eKeyPoint\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"n\"\u003eKeyPtsSrc\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eKeyPtsTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 特徴量\u003c/span\u003e\n\u003cspan class=\"n\"\u003eIEnumerable\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eDMatch\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eSelectedMatched\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// マッチング結果\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003epublic\u003c/span\u003e \u003cspan class=\"k\"\u003evoid\u003c/span\u003e \u003cspan class=\"nf\"\u003eFitSrcToTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// 使用する特徴点の量だけベクトル用意\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eSelectedMatched\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eCount\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003egetPtsSrc\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eVec2f\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003egetPtsTarget\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eVec2f\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e];\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// SrcとTarget画像の対応する特徴点の座標を取得し、ベクトル配列に格納していく。\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003ecount\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eforeach\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"k\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003eSelectedMatched\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003eptSrc\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eKeyPtsSrc\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eQueryIdx\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ePt\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003eptTarget\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eKeyPtsTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTrainIdx\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003ePt\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"n\"\u003egetPtsSrc\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eptSrc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"n\"\u003egetPtsSrc\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eptSrc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"n\"\u003egetPtsTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eptTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"n\"\u003egetPtsTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eptTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eY\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"p\"\u003e++;\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// SrcをTargetにあわせこむ変換行列homを取得する。ロバスト推定法はRANZAC。\u003c/span\u003e\n    \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003ehom\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eCv2\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eFindHomography\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eInputArray\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eCreate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003egetPtsSrc\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eInputArray\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eCreate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003egetPtsTarget\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eHomographyMethods\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRansac\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n    \u003cspan class=\"c1\"\u003e// 行列homを用いてSrcに射影変換を適用する。\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eWarpedSrcMat\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eMat\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eCv2\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eWarpPerspective\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eSrcMat\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eWarpedSrcMat\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehom\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eOpenCvSharp\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eSize\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eTargetMat\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eWidth\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eTargetMat\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eHeight\u003c/span\u003e\u003cspan class=\"p\"\u003e));\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003e\u003c/p\u003e\n\u003c/div\u003e\u003c/details\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"4-srcとtargetの差分画像を取得する\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#4-src%E3%81%A8target%E3%81%AE%E5%B7%AE%E5%88%86%E7%94%BB%E5%83%8F%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e4. SrcとTargetの差分画像を取得する\u003c/h2\u003e\n\n\u003cp\u003eようやく2枚の画像を得ることができました。いよいよレガシーな画像処理の出番です。\u003cbr\u003e\nとりあえず射影変換後の画像をPhotoshopで比較してみました(レイヤースタイル：差の絶対値を使用)。なかなかいい感じです。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/757687489587a92391a6b8ee77913f082c5e426d/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f30323337666531352d623961312d376263622d376465662d3432333338653662393939362e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F0237fe15-b9a1-7bcb-7def-42338e6b9996.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=df74692049369c0782c0bcb27d2a8de2\" alt=\"差の絶対値.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/0237fe15-b9a1-7bcb-7def-42338e6b9996.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F0237fe15-b9a1-7bcb-7def-42338e6b9996.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=d0e44ff694755f0099727286a0189a63 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\n更に、チャンネルを別個に使用すれば検出精度が上がると思ったため、RGBとHSVの各チャンネル同士の差分画像を作成しました。ただしH(色相)、S(彩度)の差分はノイズが多くて使い物になりませんでした。変形時の補完に原因があるような気がします。\u003cbr\u003e\nそのため、今回は\u003cstrong\u003eRGB\u003c/strong\u003eと\u003cstrong\u003eV(輝度)\u003c/strong\u003eの\u003cstrong\u003e計4チャンネル\u003c/strong\u003eのみを使用することにしました。これらの画像に対して処理を施し、間違い箇所のみを目立たせるマスクを作っていきます。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/8e049331c32c1b0d1eabde179a15aa9d59c1c9b9/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f30336437663732622d376130392d663235352d383631372d3431636366386234383138652e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F03d7f72b-7a09-f255-8617-41ccf8b4818e.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=577871e8440b3d933c0cd21423700fe2\" alt=\"差分画像.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/03d7f72b-7a09-f255-8617-41ccf8b4818e.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F03d7f72b-7a09-f255-8617-41ccf8b4818e.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=0906f7d5fcedf02d9aec4cdf356193b1 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\n余談ですが、OpenCVには画素にアクセスするメソッドSet/GetPixelが用意されています。最初はそれを使って実装したのですが、クソ遅かったです(800px*600pxの差分画像を1枚作るのに5秒くらいかかった)。\u003cbr\u003e\nその後LockBitsを使ってメモリ領域を直接いじる方法を知って、ようやく6枚で1秒というギリ耐えられるかなって速度になりました。それでも遅いけど。\u003cbr\u003e\n更にプログラム完成後に知ったんですけどPythonだとこんな感じで差分画像取れるんですね……便利……。\u003cdel\u003eC#やめよ。\u003c/del\u003e\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"python\"\u003e\n\u003cdiv class=\"code-lang\"\u003e\u003cspan class=\"bold\"\u003ePython\u003c/span\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003ediff\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esrc\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eastype\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003etarget\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eastype\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003cp\u003e\u003cstrong\u003e2020/05/17追記\u003c/strong\u003e\u003cbr\u003e\n\u003ca href=\"https://qiita.com/albireo\"\u003e@albireo\u003c/a\u003e 氏からコメントを頂き、OpenCVにも差分画像を取得する \u003ca href=\"http://opencv.jp/opencv-2.1/cpp/operations_on_arrays.html#cv-absdiff\" rel=\"nofollow noopener\" target=\"_blank\"\u003e\u003cstrong\u003ecv::absdiff\u003c/strong\u003e\u003c/a\u003e があることを知りました。当然 \u003ca href=\"https://shimat.github.io/opencvsharp_docs/html/6c7cefd1-59bc-a595-fe2a-0c8a709f8d16.htm\" rel=\"nofollow noopener\" target=\"_blank\"\u003eOpenCvSharpにも組み込まれている\u003c/a\u003eので、これを使用すれば処理時間の大幅な短縮が見込めそうです。情報ありがとうございました。\u003cbr\u003e\nまずは何事も調べるのは大事ですね。ごめんなC#。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"5-差分画像の重要箇所のみを目立たせマスクを作成する\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#5-%E5%B7%AE%E5%88%86%E7%94%BB%E5%83%8F%E3%81%AE%E9%87%8D%E8%A6%81%E7%AE%87%E6%89%80%E3%81%AE%E3%81%BF%E3%82%92%E7%9B%AE%E7%AB%8B%E3%81%9F%E3%81%9B%E3%83%9E%E3%82%B9%E3%82%AF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e5. 差分画像の重要箇所のみを目立たせ、マスクを作成する\u003c/h2\u003e\n\n\u003cp\u003e得られたRGBとVの計4枚の差分画像を2値化しますが、このままだとノイズが結構あるので、\u003cstrong\u003eメディアンフィルタ\u003c/strong\u003eを適用してごま塩ノイズを取っています。\u003cbr\u003e\n\u003ca href=\"https://imagingsolution.blog.fc2.com/blog-entry-92.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003eメディアンフィルタ　画像処理ソリューション\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eノイズ除去の次は4枚の画像を\u003cstrong\u003eBitwizeOr\u003c/strong\u003eで統合します。すなわち、各画像の画素ごとにOR演算を行い、\u003cstrong\u003eどれか1枚でも白の箇所があったらその画素は白とする\u003c/strong\u003eことで1枚の統合画像を作成します。この処理によって、検出モレを防ぐことができます。\u003cbr\u003e\n\u003ca href=\"https://cvtech.cc/bitwise/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eピクセル毎の論理演算 AND NOT OR XOR | OpenCV画像解析入門\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e次に\u003cstrong\u003eブロブ処理\u003c/strong\u003eで\u003cstrong\u003e一定の大きさより小さい差分検出領域を省いて、ノイズ除去\u003c/strong\u003eを行います。メディアンフィルタと被っているように思えますが、メディアンフィルタとブロブの違いは形状に依存するか否かというところです。また、ブロブ処理は、これはある大きさのかたまりをカウントすることができる、という利点があります。今回は実装\u003cdel\u003eできなかった\u003c/del\u003eしていませんが「○個の間違いを表示する」といったように指定することも応用次第でできると思います。\u003cbr\u003e\n\u003ca href=\"https://www.visco-tech.com/technical/direction-presence/blob/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eブロブ解析～ヴィスコの画像処理技術 | ヴィスコ・テクノロジーズ株式会社\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e最後に、膨張処理を適用します。膨張処理とは、\u003cstrong\u003eある画素が白だったらその近傍の画素も白にする\u003c/strong\u003eという処理のことです。\u003cbr\u003e\n完成イメージとして、間違い箇所を囲むようなマスクを作りたかったので、差分検出領域を広げるためにこの処理をかませています。これで最終的なマスク調整を行います。\u003cbr\u003e\n\u003ca href=\"https://imagingsolution.blog.fc2.com/blog-entry-101.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003e膨張・収縮・オープニング・クロージング　画像処理ソリューション\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eフローの概略図はこんな感じです(Vチャンネル描き忘れましたが、実際は前述のとおり4チャンネルの画像を使用しています)。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/0700d61567064bb80f6f24f6c51b803c4fb19a73/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f37386235643138652d656135372d303435322d656334332d3938613064613265336136322e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78b5d18e-ea57-0452-ec43-98a0da2e3a62.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=e0b153c5a27d07ec03287a965cadb720\" alt=\"下処理.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/78b5d18e-ea57-0452-ec43-98a0da2e3a62.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78b5d18e-ea57-0452-ec43-98a0da2e3a62.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=1ff75c02abb419410623bdc45908fcdc 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eなお、メディアンフィルタのカーネルサイズは3px、2値化閾値は128、膨張は5px、ブロブ面積下限値は10pxとしました。この値でおおむね良さそうですが、実際には細かい調整をすることがあるため、こんな感じのGUIも一応作成しました。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/3d3b4bf8d3fcf3e3b0afc4dfb958729f74565814/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f65346138396530612d376639302d623339642d626634312d3934373239656231313262342e676966\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/e4a89e0a-7f90-b39d-bf41-94729eb112b4.gif\" alt=\"2.gif\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/e4a89e0a-7f90-b39d-bf41-94729eb112b4.gif\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"6-マスクをsrcとtargetにかぶせる\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#6-%E3%83%9E%E3%82%B9%E3%82%AF%E3%82%92src%E3%81%A8target%E3%81%AB%E3%81%8B%E3%81%B6%E3%81%9B%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e6. マスクをSrcとTargetにかぶせる\u003c/h2\u003e\n\n\u003cp\u003e射影変換したSrcとTargetを並べて表示し、両方にマスクをかぶせます。\u003cbr\u003e\n今回のプログラムでは、差分検出領域は透明色、それ以外は低透明度の黒とすることで、間違い箇所を際立たせています。\u003cbr\u003e\n無事10個の間違いの周辺がハイライトされていますね。\u003cbr\u003e\n両脇もハイライトされているのは、ダウンロードできる間違い探しの画像サイズがそもそも一致しておらず、端の方が削れてしまっているからです。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/db8276c1d8537117d6cc47c8d12e4e92ecf614eb/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f62386237323531322d323036612d656263352d383135382d6236393236646432336266662e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fb8b72512-206a-ebc5-8158-b6926dd23bff.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=621a751168ea44c544889dbb01100742\" alt=\"0_02.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/b8b72512-206a-ebc5-8158-b6926dd23bff.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fb8b72512-206a-ebc5-8158-b6926dd23bff.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=328678168217167f05a720fed2af2e35 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"机上評価結果\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%9C%BA%E4%B8%8A%E8%A9%95%E4%BE%A1%E7%B5%90%E6%9E%9C\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e机上評価結果\u003c/h1\u003e\n\n\u003cp\u003e適当に3種類の間違い探しを選んでプログラム実行したところ、いずれも10個の間違いが取得できています！\u003cbr\u003e\nにしても本当に難しいですね。\u003cstrong\u003e個人的にヤバいと思ったのは2つめの右下の焼き鳥の串の角度です。\u003c/strong\u003eこいつはやばい。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/9b93f1702307718522be2f563723bb33cb821521/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f61653338633164622d663462662d613364312d353763662d3462376230363433646434342e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fae38c1db-f4bf-a3d1-57cf-4b7b0643dd44.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=bd3763b20c5f12355512b5c5a7104ade\" alt=\"2019.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/ae38c1db-f4bf-a3d1-57cf-4b7b0643dd44.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fae38c1db-f4bf-a3d1-57cf-4b7b0643dd44.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=d15e8ad1e230f91beba542e21ecd7103 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/f26e0eabcf796f4acb63d9c778ea11ef9e0239e6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f34373065633862612d383136332d393535612d313362332d3665313435653564383538392e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F470ec8ba-8163-955a-13b3-6e145e5d8589.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=89bec44042196e16c7d89bccbc1fc456\" alt=\"201912.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/470ec8ba-8163-955a-13b3-6e145e5d8589.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F470ec8ba-8163-955a-13b3-6e145e5d8589.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=5e2c9686dcc620305345fb99dcef3fb2 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/2a09925c68d3ac2fd6286f87a5577d2db455dec9/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f32346330653537612d306335352d366337632d386633382d3735373535396464613032642e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F24c0e57a-0c55-6c7c-8f38-757559dda02d.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=585d70e75aa4af6bcd2335789e5dd886\" alt=\"2020.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/24c0e57a-0c55-6c7c-8f38-757559dda02d.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F24c0e57a-0c55-6c7c-8f38-757559dda02d.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=785b55d62d08f671accd1883e48bec87 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"そして現実へ\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%9D%E3%81%97%E3%81%A6%E7%8F%BE%E5%AE%9F%E3%81%B8\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eそして現実へ…\u003c/h1\u003e\n\n\u003cp\u003eプログラムは完成した。抜かりはない、完璧だ。\u003cbr\u003e\nいざ実戦といこう。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"実際にサイゼで写真を撮ってみた結果\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E9%9A%9B%E3%81%AB%E3%82%B5%E3%82%A4%E3%82%BC%E3%81%A7%E5%86%99%E7%9C%9F%E3%82%92%E6%92%AE%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E7%B5%90%E6%9E%9C\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実際にサイゼで写真を撮ってみた結果\u003c/h2\u003e\n\n\u003cp\u003eくどいようですが、今回ロバスト性を重視したのは、\u003cstrong\u003eサイゼに行って間違い探しの写真を撮ってその流れで答えを見つけるというリアルタイム感の実現\u003c/strong\u003eを目指してのことです。\u003cbr\u003e\nそのため、実際にiPhone Xで写真を撮ってこのプログラムに突っ込んでみました。果たして結果やいかに。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/7e54448809dd8981b684c57690f18dd95d2c30f6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f37383132366139382d386566342d626536312d316130622d6364366635313431363030312e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78126a98-8ef4-be61-1a0b-cd6f51416001.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=b06261cce3db8c29d6721dfd5026fbe7\" alt=\"実写3.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/78126a98-8ef4-be61-1a0b-cd6f51416001.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F78126a98-8ef4-be61-1a0b-cd6f51416001.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=a8d6afe4131cb9d8f0d9abf42187ee83 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003cstrong\u003eデンッ！！\u003c/strong\u003e\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/ca3989e6e24102a4ff149dbf12a256a26927823b/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f36633235356166322d323338382d663664632d623964632d6530323464323735616562312e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F6c255af2-2388-f6dc-b9dc-e024d275aeb1.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=b6a65fb489ae068f69d9491a70ecc641\" alt=\"実写.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/6c255af2-2388-f6dc-b9dc-e024d275aeb1.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F6c255af2-2388-f6dc-b9dc-e024d275aeb1.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=965abdb292a9db31716d71172972c7c8 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\nダメだったよ。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"失敗の原因\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%A4%B1%E6%95%97%E3%81%AE%E5%8E%9F%E5%9B%A0\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e失敗の原因\u003c/h2\u003e\n\n\u003cp\u003eこの失敗の原因は、実際の対象はJpgでもPngでもなく\u003cstrong\u003e厚紙に印刷されている\u003c/strong\u003eというところにあるようです。つまり、画像によって3次元的な\u003cstrong\u003e反り\u003c/strong\u003eの具合が異なってしまっており、その歪みが補正しきれていません。射影変換ではこのタイプの歪みに対応できないのです。\u003cbr\u003e\nその結果、端にいけばいくほど画像間のずれが大きくなり、結果として端の方で誤検出が増大しています。左端の女の子やおじさん、右端の羊なんかが顕著です。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/d3b4cc314c72f3ec6845cc3a6404f3542633b027/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f30396130643332662d353966662d396334342d396532372d6665356635393464306438372e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F09a0d32f-59ff-9c44-9e27-fe5f594d0d87.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=9ea8ed4fdce4d373cfe4ef0c173d7bca\" alt=\"反り.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/09a0d32f-59ff-9c44-9e27-fe5f594d0d87.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F09a0d32f-59ff-9c44-9e27-fe5f594d0d87.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=c99583cf3f63a3714420b4c78c3cf2c5 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003cbr\u003e\nただし、画像の中央付近はいい感じに検出できています。特に豆の違いが検出できているので個人的にはかなり達成感があります。この豆だけが自力(人力)で解けなかったんですよね……。\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/5d7ba575dd445a6cc83ed4c61c69ce81537fb948/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f62633739343832312d643766352d383732392d656530362d6462303433643335393163632e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fbc794821-d7f5-8729-ee06-db043d3591cc.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=1588931df25d91be7e9dda4a319774ec\" alt=\"実写2.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/bc794821-d7f5-8729-ee06-db043d3591cc.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2Fbc794821-d7f5-8729-ee06-db043d3591cc.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=bc2ac4eb88b46c4c77c83f7e9ba15e2b 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"対策\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AF%BE%E7%AD%96\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e対策\u003c/h2\u003e\n\n\u003cp\u003e単なる歪みであれば任意直線上の特徴点同士の距離の比は変わらないため射影変換で対応できますが、今回の場合は3次元的に反っているため、より高度な変形によって丹念にあわせ込む必要があります。\u003cbr\u003e\n色々調べたところ、九州大学の情報系の研究室の資料がヒットしました。\u003cbr\u003e\n\u003ca href=\"http://human.ait.kyushu-u.ac.jp/publications/iee-presen.pdf\" rel=\"nofollow noopener\" target=\"_blank\"\u003e【スライド】２次元ワープを用いた顔画像処理顔画像処理 - 内田誠一氏、他2名\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"http://human.ait.kyushu-u.ac.jp/publications/miyazaki-0155.pdf\" rel=\"nofollow noopener\" target=\"_blank\"\u003e【論文】粗密DPに基づく画像の弾性マッチングアルゴリズム - 宮崎洋光氏、他2名\u003c/a\u003e\u003cbr\u003e\n一応概要を書いておきます。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e射影変換よりもフレキシブルに変形できる\u003cstrong\u003e弾性マッチング\u003c/strong\u003eというアルゴリズムがある\n\n\u003cul\u003e\n\u003cli\u003e対応する点同士を一致させるアルゴリズム。例えば、ある人の正面からの写真と斜めからの写真をマッチングして、斜めからの写真を正面からの写真に変換できる。\u003c/li\u003e\n\u003cli\u003eこの原理で反りに対応できそう\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eただし計算量が\u003cstrong\u003e$O(N^{2}9^{2N})$\u003c/strong\u003eらしい。こいつはやばい。\n\n\u003cul\u003e\n\u003cli\u003e指数オーダーのヤバさ → \u003ca href=\"https://www.youtube.com/watch?v=Q4gTV4r0zRs\" rel=\"nofollow noopener\" target=\"_blank\"\u003e【YouTube】フカシギの数え方\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eそれを緩和するために\u003cstrong\u003e粗密DP\u003c/strong\u003eという動的計画法を適用する\n\n\u003cul\u003e\n\u003cli\u003eこれにより計算量は\u003cstrong\u003e$O(N^{4})$\u003c/strong\u003eとなり、ある程度現実的なアルゴリズムとなる\u003c/li\u003e\n\u003cli\u003e粗密DPを低解像度の画像に適用することが前提\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eなるほどわからん。ただ、本論文が執筆されたのは2004年とだいぶ前なので、技術自体は枯れてきているかもしれません。勉強していつか実装したいですね。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"その他課題\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%9D%E3%81%AE%E4%BB%96%E8%AA%B2%E9%A1%8C\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eその他課題\u003c/h2\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"極端に小さい間違いは検出できない\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%A5%B5%E7%AB%AF%E3%81%AB%E5%B0%8F%E3%81%95%E3%81%84%E9%96%93%E9%81%95%E3%81%84%E3%81%AF%E6%A4%9C%E5%87%BA%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e極端に小さい間違いは検出できない\u003c/h3\u003e\n\n\u003cp\u003e画像を合わせ込む段階で画像全体の特徴点を使っているため、当然ながら間違い箇所の特徴点も使用しています。現状、そういった箇所は閾値を設定して外れ値とすることで無視しています。\u003cbr\u003e\nただし、\u003cstrong\u003e2枚の画像両方に似たような特徴点があり、かつその2点の距離が比較的近い場合\u003c/strong\u003e、その2点は同じであるとみなされ、\u003cstrong\u003e射影変換の精度に影響する可能性\u003c/strong\u003eがあります。サイゼの間違い探しには対象がずれているだけ、という間違いも結構あるので、この影響は無視できません。\u003cbr\u003e\n実際、以下の画像の場合だと間違いの箇所がかなり細いため、プログラムを実行した結果ノイズとみなされてしまいました。\u003cbr\u003e\n\u003ca href=\"https://www.saizeriya.co.jp/entertainment/rice.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003e2006年8月の間違い探し - 左下の時計の短針に注目\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eこの解決策として、「マッチングの閾値を追い込む」「画像の一部分のみの特徴点を用いて射影変換する」といった方法が考えられます。\u003cbr\u003e\nただし、前者は閾値を上回る間違い箇所の特徴点が無いことを証明できず、後者はその一部分に間違いがあった場合意味がない上に、一部分だけだと射影変換の精度が不安です。よって、これらの解決策は根本的なものではありません。\u003cbr\u003e\nあとは紙自体の反りを補正した上での話になりますが、間違い探しの\u003cstrong\u003e冊子のエッジ\u003c/strong\u003eを利用できるような気もします。要検討ですね。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"サイゼで実行したい\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%B5%E3%82%A4%E3%82%BC%E3%81%A7%E5%AE%9F%E8%A1%8C%E3%81%97%E3%81%9F%E3%81%84\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eサイゼで実行したい\u003c/h3\u003e\n\n\u003cp\u003e\u003cstrong\u003e「サイゼに行く→注文する→写真を撮る→実行する→料理が来るまでに間違いを全て見つける」\u003c/strong\u003eというのが理想のフローです。\u003cbr\u003e\nでもスマホアプリ作ったことないので諦めました。Xamarin勉強します。\u003cbr\u003e\nまた、スマホで動かすためにはもっと処理を軽くする必要がありますね。マシンパワーに頼らない実装……。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"さいごに\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%95%E3%81%84%E3%81%94%E3%81%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eさいごに\u003c/h1\u003e\n\n\u003cp\u003eこのたび初めてOpenCV（OpenCvSharp）をまともにいじりましたが、思いの外色々なことが実現できて楽しかったです。\u003c/p\u003e\n\n\u003cp\u003eまた、今回使用した実写画像は、サイゼにテイクアウトを買いに行ったときに撮影しました。\u003cbr\u003e\nテイクアウトかなり良かったので是非みなさまもおうちでサイゼしましょう。\u003cbr\u003e\n\u003ca href=\"https://www.saizeriya.co.jp/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eサイゼリヤトップページ｜サイゼリヤ\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/f36d660d46820a959767995fa91105d2056c5005/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3532343438302f34646331333431632d336533612d303664632d373863352d3465363938626166643330352e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F4dc1341c-3e3a-06dc-78c5-4e698bafd305.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=4706cdcc0243f8983c2ba720c5f7ff6f\" alt=\"takeout.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/524480/4dc1341c-3e3a-06dc-78c5-4e698bafd305.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F524480%2F4dc1341c-3e3a-06dc-78c5-4e698bafd305.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=fe4fc656eb81b845fc8c3ac75a9032a5 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n","createdAt":"2020-05-16T10:03:35Z","elapsedYearsFromLastModifiedAt":1,"encryptedId":"sugRwsuum7IQQfR/5m0Yg0nuPxewkIJXKQ==--NiFDMfgpXbpZIArA--4nEvY3/OQs5sy2i8JOOA8g==","isBanned":false,"isDeprecated":true,"isDestroyableByViewer":false,"isEditRequestReadableByViewer":true,"isEditRequestSendableByViewer":true,"isLikableByViewer":true,"isLikedByViewer":false,"isPublic":true,"isSlide":false,"isStockableByViewer":true,"isStockedByViewer":false,"isSubscribableByViewer":false,"isSubscribedByViewer":false,"isUpdatableByViewer":false,"isUpdated":true,"lastModifiedAt":"2020-05-16T17:57:38Z","likesCount":436,"linkUrl":"https://qiita.com/ika_kk/items/32c4986825c86ad92f36","organization":null,"originalId":1224537,"stockedCount":231,"title":"サイゼリヤの間違い探しをロバストな画像処理で解く","toc":"\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\"\u003eはじめに\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C\"\u003e実行結果\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E6%A6%82%E8%A6%81\"\u003eアルゴリズムの概要\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E8%A3%85%E3%81%A8%E7%92%B0%E5%A2%83\"\u003e実装と環境\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%83%95%E3%83%AD%E3%83%BC%E3%83%81%E3%83%A3%E3%83%BC%E3%83%88\"\u003eフローチャート\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#1-%E7%94%BB%E5%83%8F%E3%82%922%E6%9E%9A%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%80\"\u003e1. 画像を2枚読み込む\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#2-opencv%E3%81%AE%E7%89%B9%E5%BE%B4%E9%87%8F%E3%83%9E%E3%83%83%E3%83%81%E3%83%B3%E3%82%B0%E3%81%A7src%E3%81%A8target%E3%81%AE%E5%AF%BE%E5%BF%9C%E7%82%B9%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B\"\u003e2. OpenCVの特徴量マッチングでSrcとTargetの対応点を取得する\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#3-%E5%AF%BE%E5%BF%9C%E7%82%B9%E3%81%AE%E6%83%85%E5%A0%B1%E3%82%92%E3%82%82%E3%81%A8%E3%81%ABsrc%E3%81%AB%E5%B0%84%E5%BD%B1%E5%A4%89%E6%8F%9B%E3%82%92%E9%81%A9%E7%94%A8%E3%81%97%E3%81%A6target%E3%81%A8%E5%BA%A7%E6%A8%99%E3%82%92%E5%90%88%E3%82%8F%E3%81%9B%E3%82%8B\"\u003e3. 対応点の情報をもとにSrcに射影変換を適用してTargetと座標を合わせる\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#4-src%E3%81%A8target%E3%81%AE%E5%B7%AE%E5%88%86%E7%94%BB%E5%83%8F%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B\"\u003e4. SrcとTargetの差分画像を取得する\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#5-%E5%B7%AE%E5%88%86%E7%94%BB%E5%83%8F%E3%81%AE%E9%87%8D%E8%A6%81%E7%AE%87%E6%89%80%E3%81%AE%E3%81%BF%E3%82%92%E7%9B%AE%E7%AB%8B%E3%81%9F%E3%81%9B%E3%83%9E%E3%82%B9%E3%82%AF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B\"\u003e5. 差分画像の重要箇所のみを目立たせ、マスクを作成する\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#6-%E3%83%9E%E3%82%B9%E3%82%AF%E3%82%92src%E3%81%A8target%E3%81%AB%E3%81%8B%E3%81%B6%E3%81%9B%E3%82%8B\"\u003e6. マスクをSrcとTargetにかぶせる\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%9C%BA%E4%B8%8A%E8%A9%95%E4%BE%A1%E7%B5%90%E6%9E%9C\"\u003e机上評価結果\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%9D%E3%81%97%E3%81%A6%E7%8F%BE%E5%AE%9F%E3%81%B8\"\u003eそして現実へ…\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E9%9A%9B%E3%81%AB%E3%82%B5%E3%82%A4%E3%82%BC%E3%81%A7%E5%86%99%E7%9C%9F%E3%82%92%E6%92%AE%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E7%B5%90%E6%9E%9C\"\u003e実際にサイゼで写真を撮ってみた結果\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%A4%B1%E6%95%97%E3%81%AE%E5%8E%9F%E5%9B%A0\"\u003e失敗の原因\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AF%BE%E7%AD%96\"\u003e対策\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%9D%E3%81%AE%E4%BB%96%E8%AA%B2%E9%A1%8C\"\u003eその他課題\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%A5%B5%E7%AB%AF%E3%81%AB%E5%B0%8F%E3%81%95%E3%81%84%E9%96%93%E9%81%95%E3%81%84%E3%81%AF%E6%A4%9C%E5%87%BA%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84\"\u003e極端に小さい間違いは検出できない\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%B5%E3%82%A4%E3%82%BC%E3%81%A7%E5%AE%9F%E8%A1%8C%E3%81%97%E3%81%9F%E3%81%84\"\u003eサイゼで実行したい\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%95%E3%81%84%E3%81%94%E3%81%AB\"\u003eさいごに\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","totalPv":18245,"uuid":"32c4986825c86ad92f36","banReason":null,"adventCalendarItem":null,"author":{"encryptedId":"bVUGX10BsvoLxHjqfRhZMn2gF3G1--hjm2aVmh9iD98DVb--Gl5/F3QM8jfOJ0+c5tlKfw==","originalId":524480,"description":"C生まれのJava育ちです。仕事ではC#とC++やってる静的型付け信者ですが、最近Pythonを勉強しはじめました。主な担当業務は画像処理です。","facebookUrl":null,"githubUrl":null,"isBlockingViewer":false,"isFollowableByViewer":true,"isFollowedByViewer":false,"isTweetWebNotificationReceivable":true,"linkedinUrl":null,"name":"","profileImageUrl":"https://s3-ap-northeast-1.amazonaws.com/qiita-image-store/0/524480/7978c641be05c0d99ba7883fc80e7d65e80fdf94/x_large.png?1573476625","profileImageUrlW48":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fs3-ap-northeast-1.amazonaws.com%2Fqiita-image-store%2F0%2F524480%2F7978c641be05c0d99ba7883fc80e7d65e80fdf94%2Fx_large.png%3F1573476625?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=b675eee74632003c0e39c0cbf38ffbca","profileImageUrlW75":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fs3-ap-northeast-1.amazonaws.com%2Fqiita-image-store%2F0%2F524480%2F7978c641be05c0d99ba7883fc80e7d65e80fdf94%2Fx_large.png%3F1573476625?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=9875149c54a6053ee50a3abf69f116cd","urlName":"ika_kk","websiteUrl":"","twitterUrl":"https://twitter.com/ika_kk","twitterUrlName":"ika_kk","revealedOrganizations":{"edges":[]}},"tags":[{"name":"C#","urlName":"csharp"},{"name":"画像処理","urlName":"%e7%94%bb%e5%83%8f%e5%87%a6%e7%90%86"},{"name":"OpenCV","urlName":"opencv"},{"name":"OpenCvSharp","urlName":"opencvsharp"},{"name":"間違い探し","urlName":"%e9%96%93%e9%81%95%e3%81%84%e6%8e%a2%e3%81%97"}],"followingLikers":{"edges":[]},"comments":{"totalCount":8}},"comments":[],"client":null,"ads_event_emitter":null}}</script>
