More than 1 year has passed since last update.Google VRという、iOSおよびAndroid用にGoogleが開発しているVRのSDKです。最近、MirageSoloで開発することが多かったので忘れないようにメモしときます。ほとんどが英語のドキュメントからの情報で、英語力うんちっちの私がまとめますので
間違っていた際は教えてくださると助かります。GVRにはこんな感じ↑のコントローラーでのプレイを想定した機能が用意されています。このコントローラーにGvrPointerPhysicsRaycasterをAdd Componentすることで
Rayが出るようになり、レーザーポインターのようにして使うことができます。HelloVRというデモシーンが用意されているので中身を覗いてみます。
ポインターが多面体にEnter、Exitでマテリアルが変わるようになってます。
タッチパッドをクリックしたら別の多面体が出現します。多面体側にEvent TriggerがAdd Componentされており、
ここで処理が行われているようです。
仕組みは極めて単純になっており、
・PointerがEnter
・PonterがExit
・Pointerが当たった状態でタッチパッドを押す
等のそれぞれ用意されたイベントハンドラにイベントを登録することができます。他にもイベントはたくさん用意されてましたが、よく使いそうなものだけメモしときます。しかし、これだとポインターが特定のオブジェクトに衝突したら...という処理は実装できますが、
単純にボタンを押したら...という処理はできません。
また、オブジェクトに毎回つけるの正直めんどくさいです。なので、別の方法を調べました。・RayがHitしたら...
・指定したボタンを押したら...を調べればEvent Triggerと同様のことも再現できるはずです。unityにすでにRayの機能はあるのでそれでいいかな～と思ってたのですが、
反応があまりよくありませんでした。
なのでGvrPointerPhysicsRaycasterを使います。ついでに、なぜ普通のRayだと反応が悪いのか気になるので調べてみました。まず、比較しやすいように
Laserの設定からDirectを選んで、コントローラーの正面からまっすぐGVR用のRayが出るようにしました。
そして、RayをDebug.DrawRayで表示。
赤線がUnityのRay、青線がGVRのRayです。GVR用のRayには若干角度がついていました。結局なぜこんなことになってるのかよくわかりませんでしたが、
ポインターもあった方がわかり易いので、
やはりGvrPointerPhysicsRaycasterを使ったほうがよさそうです。上記コードで通常のRayと同様、Tagで特定のゲームオブジェクトにのみRayの衝突判定を行えます。ボタンの入力はGvrControllerInputDeviceからbool値を引っ張ってきます。Homeボタンの入力も用意されていますが、
中心にトラッキングし直したり、文字通りHome画面を表示したりするボタンなので使うことはないと思います。以上の入力で戻ってきたbool値を下記のように使います。GetDeviceの引数はGvrControllerHand.DominantでOKです。Rayの衝突かつボタンの入力 ＝　Event TriggerのPonter Clickせっかくタッチパッドがあるので、スワイプとかも調べてまとめたいと思ってます。関連記事：GVRのコントローラーに操作説明を表示する


