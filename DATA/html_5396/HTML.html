<!DOCTYPE html><html><head><meta charset="utf-8" /><title>C#でGoogle Cloud Vision APIを利用して、簡易OCRアプリケーションを作成する - Qiita</title><meta content="width=device-width,initial-scale=1,shrink-to-fit=no,viewport-fit=cover" name="viewport" /><meta content="#55c500" name="theme-color" /><meta content="XWpkTG32-_C4joZoJ_UsmDUi-zaH-hcrjF6ZC_FoFbk" name="google-site-verification" /><meta content="telephone=no" name="format-detection" /><link rel="canonical" href="https://qiita.com/nyagato_00/items/4a764260ec76e8504cf4" /><link href="/manifest.json" rel="manifest" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link as="script" href="https://www.googletagservices.com/tag/js/gpt.js" rel="preload" /><link href="https://securepubads.g.doubleclick.net" rel="preconnect" /><script async="" src="https://www.googletagservices.com/tag/js/gpt.js"></script><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="Q7H+vm9CMy1508gHgWLgB/tSn8TzCPLJvVTvaGtboTC8J27D+GUIYIpblYJBBBYrWoPPjgXvwmtLK8l7GcnMyQ==" /><link rel="shortcut icon" type="image/x-icon" href="https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico" /><link rel="apple-touch-icon" type="image/png" href="https://cdn.qiita.com/assets/favicons/public/apple-touch-icon-ec5ba42a24ae923f16825592efdc356f.png" /><link rel="stylesheet" media="all" href="https://cdn.qiita.com/assets/public/article-2eaa7dbedc42a8ea65c722cda46d0ebb.min.css" /><script src="https://cdn.qiita.com/assets/public/v3-article-bundle-63de2d91fef827269d3f6b958db2335b.min.js" defer="defer"></script><meta name="twitter:card" content="summary_large_image"><meta content="@Qiita" name="twitter:site" /><meta content="@TakashiMiyahara" name="twitter:creator" /><meta property="og:type" content="article"><meta property="og:title" content="C#でGoogle Cloud Vision APIを利用して、簡易OCRアプリケーションを作成する - Qiita"><meta property="og:image" content="https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0&amp;w=1200&amp;mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND1ReVBqZ2FkSGIyOW5iR1VnUTJ4dmRXUWdWbWx6YVc5dUlFRlFTZU9Da3VXSXFlZVVxT09CbC1PQnB1T0FnZWV3b2VhWWswOURVdU9Db3VPRGwtT0RxdU9Dc2VPRHZPT0N0LU9EcC1PRHMtT0NrdVM5bk9hSWtPT0JtZU9DaXcmdHh0LWNvbG9yPSUyMzMzMyZ0eHQtZm9udD1IaXJhZ2lubyUyMFNhbnMlMjBXNiZ0eHQtc2l6ZT01NCZ0eHQtY2xpcD1lbGxpcHNpcyZ0eHQtYWxpZ249Y2VudGVyJTJDbWlkZGxlJnM9NGQ0OTIwMWZmZDQ3ZTY1NjAyMzdiNGY5MjM4ZWNlMTM&amp;mark-align=center%2Cmiddle&amp;blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RRzU1WVdkaGRHOWZNREEmdHh0LWNvbG9yPSUyMzMzMyZ0eHQtZm9udD1IaXJhZ2lubyUyMFNhbnMlMjBXNiZ0eHQtc2l6ZT00NSZ0eHQtYWxpZ249cmlnaHQlMkNib3R0b20mcz03NjVkMjhmZDA4ZGU1MTYwMTM5MWM3Njg1YjM1MTQzZg&amp;blend-align=center%2Cmiddle&amp;blend-mode=normal&amp;s=a46f71c5ade6871e1f8bfcb349f35415"><meta property="og:description" content="

はじめに

こんばんは、miyaharaです。最近、OCRを利用した業務アプリケーションを作ったりしています。
有名所のOCRライブラリを幾つか試してみたのと、クラウドベースの画像処理APIが使いやすくて、正直ビビりましたので、備..."><meta content="https://qiita.com/nyagato_00/items/4a764260ec76e8504cf4" property="og:url" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><meta content="C#,GoogleCloudPlatform,VisionAPI" name="keywords" /><script>!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};
if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];
s.parentNode.insertBefore(t,s)}(window, document,'script',
'https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '668972150489891');
fbq('track', 'PageView');</script><style data-emotion-css="17jxvjw 11t2ec1 1dvr2p8 18lkoru 1g4cku8 1iupg5d ijvq0v 15cocm3 12rp90f 115f4t 1b8uj5v 79elbk 16hhh7b fcbn8c 1gj7nt 154zy0m yikrym 1jqivyb 1ode1bp le4d8r 1hbd3g7 1nzh4zz 38fzdi helsa7 8qb8m4 2imjyh he5w1s 70qvj9 3ojehk 100alwu 1dtnjt5 10ougpm 1ay9vb9 m19uds cgzq40 1wa99t2 1l3zk9f 4czcte 1yzj1fm 1uv1qiv 109dbrr 5jpx49 mnxgyc 1vlpknv fsjkhv 1b17vb0 7i7f4d"}>.css-17jxvjw{display:grid;display:-ms-grid;grid-template-columns:80px minmax(0,1fr) 300px;-ms-grid-columns:80px minmax(0,1fr) 300px;grid-template-rows:minmax(270px,auto) 1fr;-ms-grid-rows:minmax(270px,auto) 1fr;max-width:1280px;margin-right:auto;margin-left:auto;padding-top:24px;padding-right:24px;padding-left:24px;}@media (max-width:1200px){.css-17jxvjw{padding-bottom:0;padding-left:0;padding-right:0;}}@media (max-width:992px){.css-17jxvjw{grid-template-columns:80px 452px 300px;-ms-grid-columns:80px 452px 300px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}@media (max-width:770px){.css-17jxvjw{display:block;}}@media (max-width:480px){.css-17jxvjw{padding-top:0;}}.css-11t2ec1{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;z-index:5;position:-webkit-sticky;position:sticky;top:calc(56px + 24px + 16px + 32px - 16px);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:16px;width:80px;}.css-11t2ec1:after{content:'';display:table;}.css-11t2ec1:before{content:'';display:table;}@media (max-width:770px){.css-11t2ec1{display:none;}}.css-1dvr2p8{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-18lkoru{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;background-color:#FFFFFF;}.css-1g4cku8{display:inline-block;vertical-align:middle;height:20px;width:20px;fill:#55C500;}.css-1iupg5d{color:#55C500;cursor:pointer;font-size:14px;font-weight:bold;}.css-ijvq0v{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-15cocm3{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:#FFFFFF;border:2px solid #6E6F70;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:2px 0px 0px;width:40px;}.css-12rp90f{display:inline-block;vertical-align:bottom;height:17.77777777777778px;width:16px;fill:#6E6F70;}.css-115f4t{color:#6E6F70;font-size:14px;font-weight:bold;}.css-1b8uj5v{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;margin-bottom:16px;padding:0;}.css-79elbk{position:relative;}.css-16hhh7b{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;padding:0;}.css-fcbn8c{display:none;bottom:initial;left:initial;right:initial;top:initial;left:100%;top:calc(-8px - (14px * 1.8) - 16px - 4px);}.css-1gj7nt{color:rgba(0,0,0,0.6);font-size:14px;font-weight:bold;line-height:1.8;padding:8px 16px;}.css-154zy0m{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.87);cursor:pointer;font-size:16px;font-weight:normal;line-height:1.8;padding:4px 16px;}.css-154zy0m:hover{-webkit-text-decoration:none;text-decoration:none;background-color:#F2F2F2;}.css-yikrym{width:20px;}.css-1jqivyb{color:rgba(0,0,0,0.6);font-size:13px;}.css-1ode1bp{background-color:rgba(0,0,0,0.12);height:1px;width:100%;margin:8px 0;}.css-le4d8r{display:inline-block;vertical-align:middle;height:13px;width:13px;fill:rgba(0,0,0,0.6);}.css-1hbd3g7{height:250px;}.css-1nzh4zz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:16px 32px;background-color:#FBE69E;color:rgba(0,0,0,0.87);line-height:1.5;font-weight:600;}@media (max-width:770px){.css-1nzh4zz{padding:16px;}}.css-38fzdi{color:#CA832A;margin-right:4px;}.css-helsa7{background-color:#FFFFFF;padding:32px;margin-bottom:24px;}@media (max-width:992px){.css-helsa7{margin:0 auto 40px;}}@media (max-width:480px){.css-helsa7{margin:0 0 40px;padding:32px 16px;}}.css-8qb8m4{margin-bottom:48px;}.css-2imjyh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-he5w1s{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:100%;}@media (max-width:770px){.css-he5w1s{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}}.css-70qvj9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.css-3ojehk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;margin-right:4px;}.css-100alwu{display:inline-block;border-radius:50%;line-height:1;overflow:hidden;vertical-align:middle;}.css-1dtnjt5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-10ougpm{color:rgba(0,0,0,0.87);font-size:14px;font-weight:600;line-height:1.8;margin-right:4px;text-wrap:break-word;word-break:break-all;}.css-1ay9vb9{margin-right:16px;}.css-m19uds{color:rgba(0,0,0,0.6);font-size:14px;line-height:1.8;}.css-cgzq40{color:rgba(0,0,0,0.87);font-size:32px;font-weight:bold;line-height:1.4;margin-top:8px;text-wrap:break-word;word-break:break-all;}.css-1wa99t2{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.6);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:8px;}.css-1l3zk9f{color:rgba(0,0,0,0.6);font-size:20px;margin-right:8px;}.css-4czcte{margin-right:4px;color:inherit;font-size:14px;line-height:1.8;}.css-4czcte:not(:last-child)::after{content:',';margin-right:4px;}.css-1yzj1fm{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:32px;}.css-1uv1qiv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-size:20px;height:32px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-right:16px;outline:none;padding:0;width:32px;}.css-109dbrr{background-color:#F9F9F9;border-top:1px solid rgba(0,0,0,0.12);bottom:0;box-shadow:0px 1px 4px rgba(0,0,0,0.14);display:none;height:calc(env(safe-area-inset-bottom,0px) + 56px);-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding-bottom:env(safe-area-inset-bottom);position:-webkit-sticky;position:sticky;width:100%;z-index:2000;}@media (max-width:770px){.css-109dbrr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}.css-5jpx49{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-evenly;-webkit-justify-content:space-evenly;-ms-flex-pack:space-evenly;justify-content:space-evenly;width:100%;}.css-mnxgyc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1vlpknv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;margin-right:4px;background-color:#FFFFFF;}.css-fsjkhv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1b17vb0{color:#6E6F70;font-size:14px;font-weight:bold;margin-left:4px;}.css-7i7f4d{display:none;bottom:initial;left:initial;right:initial;top:initial;bottom:32px;right:0;}</style></head><body><div class="allWrapper"><div><div id="GlobalHeader-react-component-e35dd10b-7b50-4ca3-a29a-f9f8aecadb76"><div class="st-Header"><div class="st-Header_container"><div class="st-Header_start"><a href="/" class="st-Header_logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 426.57 130"><circle cx="167.08" cy="21.4" r="12.28"></circle><path d="M250.81 29.66h23.48v18.9h-23.48z"></path><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z"></path><circle cx="216.33" cy="21.4" r="12.28"></circle></svg></a><div class="st-Header_communitySelector" tabindex="0"><span class="fa fa-caret-down"></span></div><div class="st-Header_dropdown"><div class="st-Header_dropdownHeading">Qiita Teams that are logged in</div><div class="st-Header_dropdownItemNote">You are not logged in to any team</div><hr class="st-Header_dropdownDivider st-Header_dropdownDivider-shrink"/><a href="https://teams-center.qiita.com/find_team" class="st-Header_dropdownItem"><span class="fa fa-fw fa-sign-in st-Header_dropdownItemIcon"></span><div>Log in to Qiita Team</div></a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Community</div><a href="/organizations" class="st-Header_dropdownItem">Organization</a><a href="/official-events/open" class="st-Header_dropdownItem">Event</a><a href="/advent-calendar" class="st-Header_dropdownItem">Advent Calendar</a><a href="https://qiitadon.com/" class="st-Header_dropdownItem" target="_blank">Qiitadon (β)</a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Service</div><a href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Jobs</a><a href="https://zine.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Zine</a><a href="https://blog.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Blog</a></div><form class="st-Header_search" action="/search" method="get"><span class="fa fa-search st-Header_searchIcon"></span><input type="search" class="st-Header_searchInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form><form class="st-Header_searchModal" action="/search" method="get"><input type="text" class="st-Header_searchModalInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form></div><div class="st-Header_end"><div class="st-Header_searchButton"><span class="fa fa-search"></span></div><a class="st-Header_signupButton" href="/signup?redirect_to=%2Fnyagato_00%2Fitems%2F4a764260ec76e8504cf4">Signup</a><a class="st-Header_loginLink" href="/login?redirect_to=%2Fnyagato_00%2Fitems%2F4a764260ec76e8504cf4">Login</a></div><div class="st-Header_overlay"></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="GlobalHeader" data-dom-id="GlobalHeader-react-component-e35dd10b-7b50-4ca3-a29a-f9f8aecadb76">{"unreadNotificationsCount":null,"realms":[{"humanName":"Qiita","isCurrentRealm":true,"isQiita":true,"isQiitaTeam":false,"loggedInUser":null,"teamId":null,"url":"https://qiita.com/"}],"teamFindUrl":"https://teams-center.qiita.com/find_team","isTeamOnlyUser":null,"currentUser":null}</script>
      
</div><div class="st-HeaderAlert st-HeaderAlert-warning"><div class="st-HeaderAlert_body"></div></div><script type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"/","name":"Qiita"}},{"@type":"ListItem","position":2,"item":{"@id":"/tags/csharp","name":"C#"}}]}</script><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","datePublished":"2018-03-12T22:24:45.000+09:00","dateModified":"2018-03-13T10:55:45.000+09:00","headline":"C#でGoogle Cloud Vision APIを利用して、簡易OCRアプリケーションを作成する","image":"https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0\u0026w=1200\u0026mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND1ReVBqZ2FkSGIyOW5iR1VnUTJ4dmRXUWdWbWx6YVc5dUlFRlFTZU9Da3VXSXFlZVVxT09CbC1PQnB1T0FnZWV3b2VhWWswOURVdU9Db3VPRGwtT0RxdU9Dc2VPRHZPT0N0LU9EcC1PRHMtT0NrdVM5bk9hSWtPT0JtZU9DaXcmdHh0LWNvbG9yPSUyMzMzMyZ0eHQtZm9udD1IaXJhZ2lubyUyMFNhbnMlMjBXNiZ0eHQtc2l6ZT01NCZ0eHQtY2xpcD1lbGxpcHNpcyZ0eHQtYWxpZ249Y2VudGVyJTJDbWlkZGxlJnM9NGQ0OTIwMWZmZDQ3ZTY1NjAyMzdiNGY5MjM4ZWNlMTM\u0026mark-align=center%2Cmiddle\u0026blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RRzU1WVdkaGRHOWZNREEmdHh0LWNvbG9yPSUyMzMzMyZ0eHQtZm9udD1IaXJhZ2lubyUyMFNhbnMlMjBXNiZ0eHQtc2l6ZT00NSZ0eHQtYWxpZ249cmlnaHQlMkNib3R0b20mcz03NjVkMjhmZDA4ZGU1MTYwMTM5MWM3Njg1YjM1MTQzZg\u0026blend-align=center%2Cmiddle\u0026blend-mode=normal\u0026s=a46f71c5ade6871e1f8bfcb349f35415","mainEntityOfPage":"https://qiita.com/nyagato_00/items/4a764260ec76e8504cf4","author":{"@type":"Person","address":"東京都","email":null,"identifier":"nyagato_00","name":"nyagato_00","image":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F50627%2Fprofile-images%2F1598706015?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=6e3c62d2e3e371ca855baca308e15bef","url":"https://qiita.com/nyagato_00","description":"Twitterのnyagato_00です.\r\nQiitaの方のアカウントを作りました.主には画像処理・センサ信号処理を大学時代の研究で行っていました。今は組み込みエンジニアからRailsエンジニアにジョブチェンジしました。\r\n","memberOf":[{"@type":"Organization","address":"岩手県滝沢市","legalName":"岩手県立大学","image":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/3c6cb4671531fd0b42343dfbc160d4ad8442dd42/original.jpg?1511144968","logo":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/bb5cc699d3a95ccb8d00624f5d69b73615e21eb8/original.jpg?1511144968","identifier":"iwate-pu","description":"岩手県滝沢市にある公立大学です。Qiitaではソフトウェア情報学部生や出身の人が多いです。"}]},"publisher":{"@type":"Organization","name":"Qiita","logo":{"@type":"ImageObject","url":"//cdn.qiita.com/assets/public/qiita-logo-c39ded593afa388e2e1ba435b110554e.png"}}}</script><style type="text/css">.wb-CampaignLink {
  background-color: #333333;
  width: 100%;
}

.wb-CampaignLink_container {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  max-width: 1100px;
  margin: 0 auto;
  font-size: 13px;
  padding: 0.8em;
}
.wb-CampaignLink_container > a {
  color: #fff;
}

.wb-CampaignLink_container > a:hover {
  text-decoration: underline;
}</style><div class="wb-CampaignLink"><div class="wb-CampaignLink_container"><a target="_blank" id="header_text_message_1" href="https://zine.qiita.com/interview/202107-hitachi/?utm_source=qiita&amp;utm_medium=header-banner">クラウド型AI-OCRの技術者が語る、研究開発寄りのプロダクト開発のやりがい</a><a target="_blank" id="header_text_message_2" href="https://zine.qiita.com/interview/202107-hitachi/?utm_source=qiita&amp;utm_medium=header-banner">詳しくはこちら</a></div><script>td.trackEvent(
  'front_events',
  {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"nyagato_00","type":"items","id":"4a764260ec76e8504cf4"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Show","data":{"message":"クラウド型AI-OCRの技術者が語る、研究開発寄りのプロダクト開発のやりがい","url":"https://zine.qiita.com/interview/202107-hitachi/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
)</script><script>document.getElementById('header_text_message_1').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"nyagato_00","type":"items","id":"4a764260ec76e8504cf4"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_1","message":"クラウド型AI-OCRの技術者が語る、研究開発寄りのプロダクト開発のやりがい","url":"https://zine.qiita.com/interview/202107-hitachi/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
  )
})</script><script>document.getElementById('header_text_message_2').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"nyagato_00","type":"items","id":"4a764260ec76e8504cf4"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_2","message":"クラウド型AI-OCRの技術者が語る、研究開発寄りのプロダクト開発のやりがい","url":"https://zine.qiita.com/interview/202107-hitachi/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
  )
})</script></div><script type="application/json" id="js-react-on-rails-context">{"railsEnv":"production","inMailer":false,"i18nLocale":"en","i18nDefaultLocale":"en","href":"https://qiita.com/nyagato_00/items/4a764260ec76e8504cf4","location":"/nyagato_00/items/4a764260ec76e8504cf4","scheme":"https","host":"qiita.com","port":null,"pathname":"/nyagato_00/items/4a764260ec76e8504cf4","search":null,"httpAcceptLanguage":null,"actionPath":"public/items#show","settings":{"analyticsTrackingId":"UA-24675221-12","assetsMap":{},"csrfToken":"3tur5t2lxyqugStEfswDDO9d8xjxjpOnMOg3/gTStT8hTTubSoL8Z10JdsG+qvUgToyjUgdpowXGlxHtdkDYxg==","locale":"en"},"currentUser":null,"isLoggedIn":false,"recaptchaSiteKey":"6LfNkiQTAAAAAM3UGnSquBy2akTITGNMO_QDxMw6","serverSide":false}</script>
<div id="PersonalArticlePage-react-component-52621f32-6f85-4ce7-86d4-a8b499ae827a"><div class="p-items_wrapper"><div class=" css-17jxvjw"><div class="css-11t2ec1"><div class="css-1dvr2p8"><button class=" css-18lkoru"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/nyagato_00/items/4a764260ec76e8504cf4/likers" class="css-1iupg5d">17</a></div><div class="css-ijvq0v"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-115f4t">23</span></div><div class="css-1b8uj5v"><span class="fa fa-twitter"></span></div><div class="css-1b8uj5v"><span class="fa fa-facebook"></span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-fcbn8c"><div class="css-1gj7nt">Improve article</div><a href="/drafts/4a764260ec76e8504cf4/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/nyagato_00/items/4a764260ec76e8504cf4/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/nyagato_00/items/4a764260ec76e8504cf4/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/nyagato_00/items/4a764260ec76e8504cf4/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/nyagato_00/items/4a764260ec76e8504cf4.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div><div class="p-items_options"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_toc"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_main"><div class="css-1nzh4zz"><span class="fa fa-fw fa-warning css-38fzdi"></span><p>More than 3 years have passed since last update.</p></div><div class="css-helsa7"><div class="css-8qb8m4"><div class="css-2imjyh"><div class="css-he5w1s"><div class="css-70qvj9"><div class="css-3ojehk"><a href="/nyagato_00"><img class="css-100alwu eyfquo10" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/50627/profile-images/1598706015" width="24" height="24" loading="lazy"/></a></div><div class="css-1dtnjt5"><a href="/nyagato_00" class="css-10ougpm">@<!-- -->nyagato_00</a><div class="css-1ay9vb9"><span><meta content="2018-03-12T13:24:45Z"/><time dateTime="2018-03-13T01:55:45Z" class="css-m19uds">updated at 2018-03-13</time></span></div></div></div></div></div><h1 class="css-cgzq40">C#でGoogle Cloud Vision APIを利用して、簡易OCRアプリケーションを作成する</h1><div class="css-1wa99t2"><span class="fa fa-tags mr-1of2 css-1l3zk9f" aria-hidden="true"></span><a href="/tags/csharp" class="css-4czcte">C#</a><a href="/tags/googlecloudplatform" class="css-4czcte">GoogleCloudPlatform</a><a href="/tags/visionapi" class="css-4czcte">VisionAPI</a></div></div><section class="it-MdContent"><div id="personal-public-article-body"><div>
<h1>
<span id="はじめに" class="fragment"></span><a href="#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB"><i class="fa fa-link"></i></a>はじめに</h1>

<p>こんばんは、miyaharaです。最近、OCRを利用した業務アプリケーションを作ったりしています。<br>
有名所のOCRライブラリを幾つか試してみたのと、クラウドベースの画像処理APIが使いやすくて、正直ビビりましたので、備忘録も兼ねて記して置きたいと思います。</p>

<h1>
<span id="使ってみたocrライブラリapi" class="fragment"></span><a href="#%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9Focr%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AAapi"><i class="fa fa-link"></i></a>使ってみたOCRライブラリ・API</h1>

<ul>
<li>tesseract-ocr</li>
<li>Microsoft Azure Computer Vision API</li>
<li>Google Cloud Vision API</li>
</ul>

<p>OpenCV3系から、利用しやすくなった「tesseract-ocr」からはじめ、その後AzureとGCPのAPIを試しました。<br>
今回作成するアプリケーションの制約が、「C#を使うこと」と「WindowsPCで動作するアプリケーションにすること」の２つでしたので、これらに落ち着きました。<br>
(ですので、基本的にNuGetを利用してライブラリが導入できるものを選択しています)</p>

<p>有償のOCRライブラリ等は、試せなかったのですが、どの程度の精度でOCR出来るのかが気になりました。お試して試せる方法等、ご存知の方は教えて頂けたら幸いです。</p>

<h1>
<span id="それぞれのocrライブラリの精度雑感" class="fragment"></span><a href="#%E3%81%9D%E3%82%8C%E3%81%9E%E3%82%8C%E3%81%AEocr%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E7%B2%BE%E5%BA%A6%E9%9B%91%E6%84%9F"><i class="fa fa-link"></i></a>それぞれのOCRライブラリの精度（雑感）</h1>

<h2>
<span id="tesseract-ocr" class="fragment"></span><a href="#tesseract-ocr"><i class="fa fa-link"></i></a>tesseract-ocr</h2>

<p>バイナリー(.exe)形式で導入できるのもとしては、Ver.3.5.1とVer.4.0.0があります。<br>
前者は安定番で、後者がα板のようです。欧米諸国の言語に対しては、α板を使うことで飛躍的に良くなるということはありませんでしたが、日中韓の３カ国の言語は、α板のほうが断然精度が高いです。<br>
Ver.3.5.1には、Ver.3.5.1用の言語の学習データを、Ver.4.0.0には、Ver.4.0.0用の学習データをそれぞれダウンロードする必要があるため、単純に認識精度を高めたい場合は、Ver.4.0.0を使うことをオススメします。<br>
しかし、バイナリーファイルはサードパーティ製になるので、この点のみご注意ください。<br>
GitHubからソースコードをダウンロードし、ビルドする分には、問題ないかと思います。<br>
(ビルドは結構たいへんでした)</p>

<h2>
<span id="microsoft-azure-computer-vision-api" class="fragment"></span><a href="#microsoft-azure-computer-vision-api"><i class="fa fa-link"></i></a>Microsoft Azure Computer Vision API</h2>

<p>Microsoft Azureにて提供されている「Microsoft Cognitive Services」から利用できる“Vision API”。<br>
Microsoft社謹製ということも有り、C#での開発にはドキュメント類も整備されており、悩むことなく試すことが出来るかと思います。テキスト認識では、与えた画像中の文字の特徴から、言語を判定してもっとも有力な言語の候補を返してくれます。<br>
また、日本語、中国語、韓国語に関しても高い精度でOCR出来ていました。</p>

<h2>
<span id="google-cloud-vision-api" class="fragment"></span><a href="#google-cloud-vision-api"><i class="fa fa-link"></i></a>Google Cloud Vision API</h2>

<p>Cloud Vision APIは、公式リファレンスにて解説されている言語の種類が、最も多いです。<br>
Go言語はもとより、Python、RubyにC#などなど、Webアプリケーションを作り慣れた方でも、Windowsアプリケーションを作り慣れてた方でも利用しやすい、印象を受けました。<br>
OCRの精度については、利用した３つうち最も良い結果を出しました。Azureの方は、なんとかして文字で表現しようと試みている感じがしましたが、Googleの方は信頼度が高い文字のみ結果に反映させているような印象でした。</p>

<p>３つのライブラリに言えることなのですが、０とOを完全にOCR出来たものはありませんでした。非常によく似ている文字ですし、フォントによってはほとんど差のない文字でもあります。これに関しては、使い手側で間違えることを前提にアプリケーションを作成したほうが良いでしょう。</p>

<h1>
<span id="インストール" class="fragment"></span><a href="#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>インストール</h1>

<p>NuGetを使って、ライブラリをインストールします。<br>
Visual Studioはこのあたりが、非常に便利なので助かります。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre class="with-code"><code>PM&gt; Install-Package Google.Apis.Vision.v1 -Version 1.32.2.1159
</code></pre></div></div>

<h1>
<span id="実装" class="fragment"></span><a href="#%E5%AE%9F%E8%A3%85"><i class="fa fa-link"></i></a>実装</h1>

<h3>
<span id="認証処理" class="fragment"></span><a href="#%E8%AA%8D%E8%A8%BC%E5%87%A6%E7%90%86"><i class="fa fa-link"></i></a>認証処理</h3>

<p>Vision APIを用いて画像の解析を行う前に、すでに取得済みの認証情報を使用して、サービスを認証する必要があります。認証情報に幾つか種類がありますが、今回はサービスアカウントキーを利用します。GCPのコンソールツールから、サービスアカウントキーを発行し、このキーを使用するPCの環境変数へ設定します。<br>
ここで、アプリケーションのデフォルト認証情報(ADC)を使用します。デフォルトでは、先程の環境変数を「GOOGLE_APPLICATION_CREDENTIALS」の名前で登録してあります。</p>

<p>認証情報が正しく有効化されれば、Vision APIの機能を使うことができるようになります。しかし、これは認証情報が有効なのは、特定のスコープの中に限られます。</p>

<div class="code-frame" data-lang="c#"><div class="highlight"><pre class="with-code"><code><span class="k">private</span> <span class="n">VisionService</span> <span class="nf">CreateAuthorizedClient</span><span class="p">()</span>
<span class="p">{</span>
<span class="err">　</span><span class="n">GoogleCredential</span> <span class="n">credential</span> <span class="p">=</span>
<span class="err">　　　</span><span class="n">GoogleCredential</span><span class="p">.</span><span class="nf">GetApplicationDefaultAsync</span><span class="p">().</span><span class="n">Result</span><span class="p">;</span>

<span class="err">　</span><span class="c1">// Inject the Cloud Vision scopes</span>
<span class="err">　</span><span class="k">if</span> <span class="p">(</span><span class="n">credential</span><span class="p">.</span><span class="n">IsCreateScopedRequired</span><span class="p">)</span>
<span class="err">　</span><span class="p">{</span>
<span class="err">　　　</span><span class="n">credential</span> <span class="p">=</span> <span class="n">credential</span><span class="p">.</span><span class="nf">CreateScoped</span><span class="p">(</span><span class="k">new</span><span class="p">[]</span>
<span class="err">　　　</span><span class="p">{</span>
<span class="err">　　　　　</span><span class="n">VisionService</span><span class="p">.</span><span class="n">Scope</span><span class="p">.</span><span class="n">CloudPlatform</span>
     <span class="p">});</span>
  <span class="p">}</span>

<span class="err">　</span><span class="k">return</span> <span class="k">new</span> <span class="nf">VisionService</span><span class="p">(</span><span class="k">new</span> <span class="n">BaseClientService</span><span class="p">.</span><span class="n">Initializer</span>
  <span class="p">{</span>
  <span class="err">　　</span><span class="n">HttpClientInitializer</span> <span class="p">=</span> <span class="n">credential</span><span class="p">,</span>
     <span class="n">GZipEnabled</span> <span class="p">=</span> <span class="k">false</span>
  <span class="p">});</span>
<span class="p">}</span>
</code></pre></div></div>

<h3>
<span id="リクエストを構築" class="fragment"></span><a href="#%E3%83%AA%E3%82%AF%E3%82%A8%E3%82%B9%E3%83%88%E3%82%92%E6%A7%8B%E7%AF%89"><i class="fa fa-link"></i></a>リクエストを構築</h3>

<p>さて、Vision APIを利用する準備が整いましたので、サービスへリクエストを行います。Cloud Vision APIに対するリクエストは、JSONオブジェクトとして作成し、送信する必要があります。</p>

<p>今回は、まず読み込んだ画像をByte型へ変換して関数へ渡します。<br>
次に。画像に対してBase64エンコードを行います。<br>
OCRを行うため、「TEXT_DETECTION」をペイロードします。<br>
JSONをimage:annotate URLへのPOSTリクエストとして送信します。<br>
この時、ラッパー関数 image().annotate()を利用して、HTTP POSTリクエストを作成します。</p>

<p>その後、Vision APIからのレスポンスが届きます。<br>
これを解析して、欲しい情報を取得します。<br>
OCR結果の全文は、「responses.Responses[0].TextAnnotations[0].Description」に格納されて言います。<br>
また、それぞれの単語は、[1]以降の配列に順に格納されております。</p>

<div class="code-frame" data-lang="c#"><div class="highlight"><pre class="with-code"><code><span class="k">private</span> <span class="kt">int</span> <span class="nf">DetectTextWord</span><span class="p">(</span><span class="n">VisionService</span> <span class="n">vision</span><span class="p">,</span> <span class="kt">byte</span><span class="p">[]</span> <span class="n">getImage</span><span class="p">,</span> <span class="k">ref</span> <span class="kt">string</span> <span class="n">FullText</span><span class="p">)</span>
        <span class="p">{</span>
            <span class="kt">int</span> <span class="n">result</span> <span class="p">=</span> <span class="m">1</span><span class="p">;</span>
            <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"Detecting image to texts..."</span><span class="p">);</span>
            <span class="c1">// Convert image to Base64 encoded for JSON ASCII text based request</span>
            <span class="kt">string</span> <span class="n">imageContent</span> <span class="p">=</span> <span class="n">Convert</span><span class="p">.</span><span class="nf">ToBase64String</span><span class="p">(</span><span class="n">getImage</span><span class="p">);</span>

            <span class="k">try</span>
            <span class="p">{</span>
                <span class="c1">// Post text detection request to the Vision API</span>
                <span class="kt">var</span> <span class="n">responses</span> <span class="p">=</span> <span class="n">vision</span><span class="p">.</span><span class="n">Images</span><span class="p">.</span><span class="nf">Annotate</span><span class="p">(</span>
                    <span class="k">new</span> <span class="nf">BatchAnnotateImagesRequest</span><span class="p">()</span>
                    <span class="p">{</span>
                        <span class="n">Requests</span> <span class="p">=</span> <span class="k">new</span><span class="p">[]</span> 
                        <span class="p">{</span>
                          <span class="k">new</span> <span class="nf">AnnotateImageRequest</span><span class="p">()</span> 
                          <span class="p">{</span>
                            <span class="n">Features</span> <span class="p">=</span> <span class="k">new</span> <span class="p">[]</span> 
                            <span class="p">{</span> <span class="k">new</span> <span class="nf">Feature</span><span class="p">()</span>
                              <span class="p">{</span>
                                <span class="n">Type</span> <span class="p">=</span> <span class="s">"TEXT_DETECTION"</span>
                              <span class="p">}</span>
                            <span class="p">},</span>
                            <span class="n">Image</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">Image</span><span class="p">()</span> 
                            <span class="p">{</span> 
                              <span class="n">Content</span> <span class="p">=</span> <span class="n">imageContent</span> 
                            <span class="p">}</span>
                          <span class="p">}</span>
                        <span class="p">}</span>
                      <span class="p">}).</span><span class="nf">Execute</span><span class="p">();</span>

                <span class="k">if</span> <span class="p">(</span><span class="n">responses</span><span class="p">.</span><span class="n">Responses</span> <span class="p">!=</span> <span class="k">null</span><span class="p">)</span>
                <span class="p">{</span>
                    <span class="n">FullText</span> <span class="p">=</span> <span class="n">responses</span><span class="p">.</span><span class="n">Responses</span><span class="p">[</span><span class="m">0</span><span class="p">].</span><span class="n">TextAnnotations</span><span class="p">[</span><span class="m">0</span><span class="p">].</span><span class="n">Description</span><span class="p">;</span>

                    <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"SUCCESS：Cloud Vision API Access."</span><span class="p">);</span>
                    <span class="n">result</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span>
                <span class="p">}</span>
                <span class="k">else</span>
                <span class="p">{</span>
                    <span class="n">FullText</span> <span class="p">=</span> <span class="s">""</span><span class="p">;</span>
                    <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"ERROR : No text found."</span><span class="p">);</span>
                    <span class="n">result</span> <span class="p">=</span> <span class="p">-</span><span class="m">1</span><span class="p">;</span>
                <span class="p">}</span>
            <span class="p">}</span>
            <span class="k">catch</span>
            <span class="p">{</span>
                <span class="n">FullText</span> <span class="p">=</span> <span class="s">""</span><span class="p">;</span>
                <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"ERROR : Not Access Cloud Vision API."</span><span class="p">);</span>
                <span class="n">result</span> <span class="p">=</span> <span class="p">-</span><span class="m">1</span><span class="p">;</span>
            <span class="p">}</span>

            <span class="k">return</span> <span class="n">result</span><span class="p">;</span>
        <span class="p">}</span>
</code></pre></div></div>

<h3>
<span id="結果を返す関数" class="fragment"></span><a href="#%E7%B5%90%E6%9E%9C%E3%82%92%E8%BF%94%E3%81%99%E9%96%A2%E6%95%B0"><i class="fa fa-link"></i></a>結果を返す関数</h3>

<div class="code-frame" data-lang="c#"><div class="highlight"><pre class="with-code"><code><span class="k">public</span> <span class="kt">int</span> <span class="nf">getTextAndRoi</span><span class="p">(</span><span class="kt">byte</span><span class="p">[]</span> <span class="n">getImage</span><span class="p">,</span> <span class="k">ref</span> <span class="kt">string</span> <span class="n">FullText</span><span class="p">)</span>
<span class="p">{</span>
   <span class="kt">int</span> <span class="n">result</span> <span class="p">=</span> <span class="m">1</span><span class="p">;</span>
   <span class="n">GCPVisonAPI</span> <span class="n">sample</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">GCPVisonAPI</span><span class="p">();</span>

   <span class="c1">// Create a new Cloud Vision clieuthorint azed via Application</span>
   <span class="c1">// Default Credentials</span>
   <span class="n">VisionService</span> <span class="n">vision</span> <span class="p">=</span> <span class="n">sample</span><span class="p">.</span><span class="nf">CreateAuthorizedClient</span><span class="p">();</span>

   <span class="c1">// Use the client to get label annotations for the given image</span>
   <span class="kt">string</span> <span class="n">getFullText</span> <span class="p">=</span> <span class="s">""</span><span class="p">;</span>
   <span class="n">result</span> <span class="p">=</span> <span class="n">sample</span><span class="p">.</span><span class="nf">DetectTextWord</span><span class="p">(</span><span class="n">vision</span><span class="p">,</span> <span class="n">getImage</span><span class="p">,</span> <span class="k">ref</span> <span class="n">getFullText</span><span class="p">);</span>
   <span class="n">FullText</span> <span class="p">=</span> <span class="n">getFullText</span><span class="p">;</span>

   <span class="k">return</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h1>
<span id="アプリケーション" class="fragment"></span><a href="#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3"><i class="fa fa-link"></i></a>アプリケーション</h1>

<p><a href="https://camo.qiitausercontent.com/391f62f3cd4a817595d29e271994e990bfcd96a5/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f35303632372f30623236396165322d663466392d346132622d396631332d6237626264336439333939652e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50627%2F0b269ae2-f4f9-4a2b-9f13-b7bbd3d9399e.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=b360d6cbd031585077897b34ecf8feb4" alt="runImage.png" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/50627/0b269ae2-f4f9-4a2b-9f13-b7bbd3d9399e.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50627%2F0b269ae2-f4f9-4a2b-9f13-b7bbd3d9399e.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=ded4a59dfb810389095ce738702de928 1x" loading="lazy"></a></p>

<p>今回作成したデモアプリケーションです。<br>
とってもWindowsなUIになっていますね。Materialデザインを適応出来るそうなので、見た目はもう少し綺麗にしたいと思います。</p>

<p>左上のボタン押下で、画像ファイルを読み込み、直下のイメージビューに表示します。<br>
中央のOCRボタンを押下すると、画像がポストされ結果が帰ってくるまで待ちます。<br>
受信したレスポンスから、OCR結果の全文を取得しテキストビューに設定します。</p>

<h1>
<span id="おわりに" class="fragment"></span><a href="#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB"><i class="fa fa-link"></i></a>おわりに</h1>

<p>　Google Cloud Vision APIを利用して、任意の画像に対するOCRを行うWindowsアプリケーションを作成することが出来ました。私は、画像処理や組み込み畑出身なので、Web界隈の知識はあまりないのですが、公式のドキュメントも非常によく整備されていて躓くことなく実装することが出来ました。<br>
　はじめに試した「tesseract-ocr」にて、今回使用するフォントの学習データを作ったり、OpenCVで前処理をしたりと地道な処理をセコセコ書いていました。しかしながら、Microsoft Cognitive ServicesのVision API、Google Cloud PlatformのCloud Vision API双方とも、グレースケール化程度の前処理のみで良好な結果を出してしまいました。<br>
　やはり、単なる画像処理の限界を改めて痛感させられました。今回は、Microsoft、Googleと外部の企業のサービスを利用したのですが、自社内で将来的には内製化する必要があるなと感じました。<br>
　そして、私人身も機械学習について本格的に学ぶ必要が有るなと思った次第です。機械学習を用いてOCRを行うAPIをこれから作っていこうと思います。</p>

<p>また、今回のコードを私のGitHubに上げました。<br>
とてもツッコミどころ満載のコードだと思いますので、ツッコミいただければと思います。<br>
<a href="https://github.com/takashi-miyahara/SimpleOCRApp_for_GoogleCloudVisionAPI" class="autolink" rel="nofollow noopener" target="_blank">https://github.com/takashi-miyahara/SimpleOCRApp_for_GoogleCloudVisionAPI</a></p>

<h1>
<span id="参考" class="fragment"></span><a href="#%E5%8F%82%E8%80%83"><i class="fa fa-link"></i></a>参考</h1>

<p><a href="https://cloud.google.com/vision/docs/label-tutorial?hl=ja" class="autolink" rel="nofollow noopener" target="_blank">https://cloud.google.com/vision/docs/label-tutorial?hl=ja</a><br>
<a href="https://github.com/msm2020/OCR-google-APIs" class="autolink" rel="nofollow noopener" target="_blank">https://github.com/msm2020/OCR-google-APIs</a></p>
</div></div></section><div class="css-1yzj1fm"><div class="css-1uv1qiv"><span class="fa fa-twitter"></span></div><div class="css-1uv1qiv"><span class="fa fa-facebook"></span></div></div><div class="apm-Content"><div class="apm-Content_title">Why not register and get more from Qiita?</div><ol class="apm-Content_list"><li>We will deliver articles that match you<div class="description">By following users and tags, you can catch up information on technical fields that you are interested in as a whole</div></li><li>you can read useful information later efficiently<div class="description">By &quot;stocking&quot; the articles you like, you can search right away</div></li><div><a class="apm-Content_help" href="https://help.qiita.com/ja/articles/qiita-login-user" target="_blank"><i class="fa fa-fw fa-arrow-circle-right"></i>What you can do with signing up</a></div></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2Fnyagato_00%2Fitems%2F4a764260ec76e8504cf4&amp;realm=qiita" class="apm-Content_button apm-Content_button-signup">Sign up</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2Fnyagato_00%2Fitems%2F4a764260ec76e8504cf4&amp;realm=qiita" class="apm-Content_button apm-Content_button-signin">Login</a></div></div><div class="css-helsa7"></div></div></div></div><div class="css-109dbrr"><div class="css-5jpx49"><div class="css-mnxgyc"><button class=" css-1vlpknv"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/nyagato_00/items/4a764260ec76e8504cf4/likers" class="css-1iupg5d">17</a></div><div class="css-fsjkhv"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-1b17vb0">23</span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-7i7f4d"><div class="css-1gj7nt">Improve article</div><a href="/drafts/4a764260ec76e8504cf4/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/nyagato_00/items/4a764260ec76e8504cf4/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/nyagato_00/items/4a764260ec76e8504cf4/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/nyagato_00/items/4a764260ec76e8504cf4/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/nyagato_00/items/4a764260ec76e8504cf4.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="PersonalArticlePage" data-dom-id="PersonalArticlePage-react-component-52621f32-6f85-4ce7-86d4-a8b499ae827a">{"authorAnalyticsTrackingId":null,"organizationAnalyticsTrackingId":null}</script>
      
<footer id="globalFooter" class="st-Footer"><div class="st-Footer_container"><div class="st-Footer_start"><div class="st-Footer_logo"><svg viewbox="0 0 426.57 130" xmlns="http://www.w3.org/2000/svg"><circle cx="167.08" cy="21.4" r="12.28" /><path d="M250.81 29.66h23.48v18.9h-23.48z" /><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z" /><circle cx="216.33" cy="21.4" r="12.28" /></svg></div><div class="st-Footer_catchcopy">How developers code is here.</div><div class="st-Footer_socials"><a class="fa fa-twitter" href="https://twitter.com/qiita"></a><a class="fa fa-facebook-square" href="https://www.facebook.com/qiita/"></a></div></div><div class="st-Footer_end"><div class="st-Footer_qiita"><div class="st-Footer_label">Qiita</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="/about">About</a><a href="/terms">Terms</a><a href="/privacy">Privacy</a><a target="_blank" href="http://help.qiita.com/ja/articles/qiita-community-guideline">Guideline</a><a target="_blank" href="https://help.qiita.com/ja/articles/others-brand-guideline">Design Guideline</a></div><div class="st-Footer_column"><a href="/release-notes">Release</a><a href="/api/v2/docs">API</a><a href="/feedback/new">ご意見</a><a href="https://help.qiita.com">Help</a><a target="_blank" href="https://qiita.com/ads?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Advertisement</a></div></div></div><div class="st-Footer_increments"><div class="st-Footer_label">Increments</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="https://increments.co.jp/company/">About</a><a href="https://increments.co.jp/jobs/">採用情報</a><a href="https://blog.qiita.com">Blog</a></div><div class="st-Footer_column"><a href="https://teams.qiita.com/">Qiita Team</a><a href="https://jobs.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Jobs</a><a href="https://zine.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Zine</a></div></div></div></div></div><div class="st-Footer_copyright">© 2011-2021 Increments Inc.</div></footer><div id="Snackbar-react-component-fcce6c24-b6bf-4c70-a1cd-e23a84efac46"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="Snackbar" data-dom-id="Snackbar-react-component-fcce6c24-b6bf-4c70-a1cd-e23a84efac46">{}</script>
      
<div id="LoginModal-react-component-abd926b9-b88b-43f8-a5a4-6e8f66e2318b"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="LoginModal" data-dom-id="LoginModal-react-component-abd926b9-b88b-43f8-a5a4-6e8f66e2318b">{}</script>
      
<div id="StockModal-react-component-97b1ab95-1d53-4421-8923-e2bc6b22a313"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="StockModal" data-dom-id="StockModal-react-component-97b1ab95-1d53-4421-8923-e2bc6b22a313">{}</script>
      
</div><div id="dataContainer" style="display: none;" data-config="{&quot;actionPath&quot;:&quot;public/items#show&quot;,&quot;settings&quot;:{&quot;analyticsTrackingId&quot;:&quot;UA-24675221-12&quot;,&quot;assetsMap&quot;:{},&quot;csrfToken&quot;:&quot;D7UC5idQF+AXxogE5pLsxiI7GSBTotRH0afdv27gImvwI5KbsHcsreRO1YEm9Brqg+pJaqVF5OUn2PusHHJPkg==&quot;,&quot;locale&quot;:&quot;en&quot;},&quot;currentUser&quot;:null}" /></body></html><script type="application/json" data-js-react-on-rails-store="AppStoreWithReactOnRails">{"snackbar":{"type":"","body":"","isActive":false},"article":{"article":{"body":"\n\u003ch1\u003e\n\u003cspan id=\"はじめに\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eはじめに\u003c/h1\u003e\n\n\u003cp\u003eこんばんは、miyaharaです。最近、OCRを利用した業務アプリケーションを作ったりしています。\u003cbr\u003e\n有名所のOCRライブラリを幾つか試してみたのと、クラウドベースの画像処理APIが使いやすくて、正直ビビりましたので、備忘録も兼ねて記して置きたいと思います。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"使ってみたocrライブラリapi\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9Focr%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AAapi\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e使ってみたOCRライブラリ・API\u003c/h1\u003e\n\n\u003cul\u003e\n\u003cli\u003etesseract-ocr\u003c/li\u003e\n\u003cli\u003eMicrosoft Azure Computer Vision API\u003c/li\u003e\n\u003cli\u003eGoogle Cloud Vision API\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eOpenCV3系から、利用しやすくなった「tesseract-ocr」からはじめ、その後AzureとGCPのAPIを試しました。\u003cbr\u003e\n今回作成するアプリケーションの制約が、「C#を使うこと」と「WindowsPCで動作するアプリケーションにすること」の２つでしたので、これらに落ち着きました。\u003cbr\u003e\n(ですので、基本的にNuGetを利用してライブラリが導入できるものを選択しています)\u003c/p\u003e\n\n\u003cp\u003e有償のOCRライブラリ等は、試せなかったのですが、どの程度の精度でOCR出来るのかが気になりました。お試して試せる方法等、ご存知の方は教えて頂けたら幸いです。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"それぞれのocrライブラリの精度雑感\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%9D%E3%82%8C%E3%81%9E%E3%82%8C%E3%81%AEocr%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E7%B2%BE%E5%BA%A6%E9%9B%91%E6%84%9F\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eそれぞれのOCRライブラリの精度（雑感）\u003c/h1\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"tesseract-ocr\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#tesseract-ocr\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003etesseract-ocr\u003c/h2\u003e\n\n\u003cp\u003eバイナリー(.exe)形式で導入できるのもとしては、Ver.3.5.1とVer.4.0.0があります。\u003cbr\u003e\n前者は安定番で、後者がα板のようです。欧米諸国の言語に対しては、α板を使うことで飛躍的に良くなるということはありませんでしたが、日中韓の３カ国の言語は、α板のほうが断然精度が高いです。\u003cbr\u003e\nVer.3.5.1には、Ver.3.5.1用の言語の学習データを、Ver.4.0.0には、Ver.4.0.0用の学習データをそれぞれダウンロードする必要があるため、単純に認識精度を高めたい場合は、Ver.4.0.0を使うことをオススメします。\u003cbr\u003e\nしかし、バイナリーファイルはサードパーティ製になるので、この点のみご注意ください。\u003cbr\u003e\nGitHubからソースコードをダウンロードし、ビルドする分には、問題ないかと思います。\u003cbr\u003e\n(ビルドは結構たいへんでした)\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"microsoft-azure-computer-vision-api\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#microsoft-azure-computer-vision-api\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eMicrosoft Azure Computer Vision API\u003c/h2\u003e\n\n\u003cp\u003eMicrosoft Azureにて提供されている「Microsoft Cognitive Services」から利用できる“Vision API”。\u003cbr\u003e\nMicrosoft社謹製ということも有り、C#での開発にはドキュメント類も整備されており、悩むことなく試すことが出来るかと思います。テキスト認識では、与えた画像中の文字の特徴から、言語を判定してもっとも有力な言語の候補を返してくれます。\u003cbr\u003e\nまた、日本語、中国語、韓国語に関しても高い精度でOCR出来ていました。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"google-cloud-vision-api\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#google-cloud-vision-api\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eGoogle Cloud Vision API\u003c/h2\u003e\n\n\u003cp\u003eCloud Vision APIは、公式リファレンスにて解説されている言語の種類が、最も多いです。\u003cbr\u003e\nGo言語はもとより、Python、RubyにC#などなど、Webアプリケーションを作り慣れた方でも、Windowsアプリケーションを作り慣れてた方でも利用しやすい、印象を受けました。\u003cbr\u003e\nOCRの精度については、利用した３つうち最も良い結果を出しました。Azureの方は、なんとかして文字で表現しようと試みている感じがしましたが、Googleの方は信頼度が高い文字のみ結果に反映させているような印象でした。\u003c/p\u003e\n\n\u003cp\u003e３つのライブラリに言えることなのですが、０とOを完全にOCR出来たものはありませんでした。非常によく似ている文字ですし、フォントによってはほとんど差のない文字でもあります。これに関しては、使い手側で間違えることを前提にアプリケーションを作成したほうが良いでしょう。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"インストール\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eインストール\u003c/h1\u003e\n\n\u003cp\u003eNuGetを使って、ライブラリをインストールします。\u003cbr\u003e\nVisual Studioはこのあたりが、非常に便利なので助かります。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"text\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003ePM\u0026gt; Install-Package Google.Apis.Vision.v1 -Version 1.32.2.1159\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"実装\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E8%A3%85\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実装\u003c/h1\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"認証処理\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E8%AA%8D%E8%A8%BC%E5%87%A6%E7%90%86\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e認証処理\u003c/h3\u003e\n\n\u003cp\u003eVision APIを用いて画像の解析を行う前に、すでに取得済みの認証情報を使用して、サービスを認証する必要があります。認証情報に幾つか種類がありますが、今回はサービスアカウントキーを利用します。GCPのコンソールツールから、サービスアカウントキーを発行し、このキーを使用するPCの環境変数へ設定します。\u003cbr\u003e\nここで、アプリケーションのデフォルト認証情報(ADC)を使用します。デフォルトでは、先程の環境変数を「GOOGLE_APPLICATION_CREDENTIALS」の名前で登録してあります。\u003c/p\u003e\n\n\u003cp\u003e認証情報が正しく有効化されれば、Vision APIの機能を使うことができるようになります。しかし、これは認証情報が有効なのは、特定のスコープの中に限られます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"c#\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"n\"\u003eVisionService\u003c/span\u003e \u003cspan class=\"nf\"\u003eCreateAuthorizedClient\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003cspan class=\"err\"\u003e　\u003c/span\u003e\u003cspan class=\"n\"\u003eGoogleCredential\u003c/span\u003e \u003cspan class=\"n\"\u003ecredential\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n\u003cspan class=\"err\"\u003e　　　\u003c/span\u003e\u003cspan class=\"n\"\u003eGoogleCredential\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eGetApplicationDefaultAsync\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"n\"\u003eResult\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n\u003cspan class=\"err\"\u003e　\u003c/span\u003e\u003cspan class=\"c1\"\u003e// Inject the Cloud Vision scopes\u003c/span\u003e\n\u003cspan class=\"err\"\u003e　\u003c/span\u003e\u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecredential\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eIsCreateScopedRequired\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"err\"\u003e　\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003cspan class=\"err\"\u003e　　　\u003c/span\u003e\u003cspan class=\"n\"\u003ecredential\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecredential\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eCreateScoped\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n\u003cspan class=\"err\"\u003e　　　\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003cspan class=\"err\"\u003e　　　　　\u003c/span\u003e\u003cspan class=\"n\"\u003eVisionService\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eScope\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCloudPlatform\u003c/span\u003e\n     \u003cspan class=\"p\"\u003e});\u003c/span\u003e\n  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"err\"\u003e　\u003c/span\u003e\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eVisionService\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"n\"\u003eBaseClientService\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eInitializer\u003c/span\u003e\n  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"err\"\u003e　　\u003c/span\u003e\u003cspan class=\"n\"\u003eHttpClientInitializer\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecredential\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n     \u003cspan class=\"n\"\u003eGZipEnabled\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003efalse\u003c/span\u003e\n  \u003cspan class=\"p\"\u003e});\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"リクエストを構築\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%83%AA%E3%82%AF%E3%82%A8%E3%82%B9%E3%83%88%E3%82%92%E6%A7%8B%E7%AF%89\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eリクエストを構築\u003c/h3\u003e\n\n\u003cp\u003eさて、Vision APIを利用する準備が整いましたので、サービスへリクエストを行います。Cloud Vision APIに対するリクエストは、JSONオブジェクトとして作成し、送信する必要があります。\u003c/p\u003e\n\n\u003cp\u003e今回は、まず読み込んだ画像をByte型へ変換して関数へ渡します。\u003cbr\u003e\n次に。画像に対してBase64エンコードを行います。\u003cbr\u003e\nOCRを行うため、「TEXT_DETECTION」をペイロードします。\u003cbr\u003e\nJSONをimage:annotate URLへのPOSTリクエストとして送信します。\u003cbr\u003e\nこの時、ラッパー関数 image().annotate()を利用して、HTTP POSTリクエストを作成します。\u003c/p\u003e\n\n\u003cp\u003eその後、Vision APIからのレスポンスが届きます。\u003cbr\u003e\nこれを解析して、欲しい情報を取得します。\u003cbr\u003e\nOCR結果の全文は、「responses.Responses[0].TextAnnotations[0].Description」に格納されて言います。\u003cbr\u003e\nまた、それぞれの単語は、[1]以降の配列に順に格納されております。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"c#\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003eDetectTextWord\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eVisionService\u003c/span\u003e \u003cspan class=\"n\"\u003evision\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003ebyte\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"n\"\u003egetImage\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eref\u003c/span\u003e \u003cspan class=\"kt\"\u003estring\u003c/span\u003e \u003cspan class=\"n\"\u003eFullText\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Detecting image to texts...\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n            \u003cspan class=\"c1\"\u003e// Convert image to Base64 encoded for JSON ASCII text based request\u003c/span\u003e\n            \u003cspan class=\"kt\"\u003estring\u003c/span\u003e \u003cspan class=\"n\"\u003eimageContent\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eConvert\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eToBase64String\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003egetImage\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n            \u003cspan class=\"k\"\u003etry\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                \u003cspan class=\"c1\"\u003e// Post text detection request to the Vision API\u003c/span\u003e\n                \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003eresponses\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003evision\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eImages\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAnnotate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n                    \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eBatchAnnotateImagesRequest\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n                    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                        \u003cspan class=\"n\"\u003eRequests\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \n                        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                          \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eAnnotateImageRequest\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \n                          \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                            \u003cspan class=\"n\"\u003eFeatures\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e \n                            \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eFeature\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n                              \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                                \u003cspan class=\"n\"\u003eType\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"TEXT_DETECTION\"\u003c/span\u003e\n                              \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n                            \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n                            \u003cspan class=\"n\"\u003eImage\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eImage\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \n                            \u003cspan class=\"p\"\u003e{\u003c/span\u003e \n                              \u003cspan class=\"n\"\u003eContent\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eimageContent\u003c/span\u003e \n                            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n                          \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n                        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n                      \u003cspan class=\"p\"\u003e}).\u003c/span\u003e\u003cspan class=\"nf\"\u003eExecute\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\n                \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponses\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eResponses\u003c/span\u003e \u003cspan class=\"p\"\u003e!=\u003c/span\u003e \u003cspan class=\"k\"\u003enull\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                    \u003cspan class=\"n\"\u003eFullText\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eresponses\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eResponses\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eTextAnnotations\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e].\u003c/span\u003e\u003cspan class=\"n\"\u003eDescription\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n                    \u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"SUCCESS：Cloud Vision API Access.\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n                    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n                \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                    \u003cspan class=\"n\"\u003eFullText\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n                    \u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"ERROR : No text found.\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n                    \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n            \u003cspan class=\"k\"\u003ecatch\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eFullText\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"ERROR : Not Access Cloud Vision API.\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e\u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"結果を返す関数\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%B5%90%E6%9E%9C%E3%82%92%E8%BF%94%E3%81%99%E9%96%A2%E6%95%B0\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e結果を返す関数\u003c/h3\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"c#\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003epublic\u003c/span\u003e \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"nf\"\u003egetTextAndRoi\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003ebyte\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"n\"\u003egetImage\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eref\u003c/span\u003e \u003cspan class=\"kt\"\u003estring\u003c/span\u003e \u003cspan class=\"n\"\u003eFullText\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n   \u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"m\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eGCPVisonAPI\u003c/span\u003e \u003cspan class=\"n\"\u003esample\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eGCPVisonAPI\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\n   \u003cspan class=\"c1\"\u003e// Create a new Cloud Vision clieuthorint azed via Application\u003c/span\u003e\n   \u003cspan class=\"c1\"\u003e// Default Credentials\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eVisionService\u003c/span\u003e \u003cspan class=\"n\"\u003evision\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eCreateAuthorizedClient\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\n   \u003cspan class=\"c1\"\u003e// Use the client to get label annotations for the given image\u003c/span\u003e\n   \u003cspan class=\"kt\"\u003estring\u003c/span\u003e \u003cspan class=\"n\"\u003egetFullText\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003esample\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eDetectTextWord\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003evision\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003egetImage\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eref\u003c/span\u003e \u003cspan class=\"n\"\u003egetFullText\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eFullText\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003egetFullText\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\n   \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"アプリケーション\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eアプリケーション\u003c/h1\u003e\n\n\u003cp\u003e\u003ca href=\"https://camo.qiitausercontent.com/391f62f3cd4a817595d29e271994e990bfcd96a5/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f35303632372f30623236396165322d663466392d346132622d396631332d6237626264336439333939652e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50627%2F0b269ae2-f4f9-4a2b-9f13-b7bbd3d9399e.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=b360d6cbd031585077897b34ecf8feb4\" alt=\"runImage.png\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/50627/0b269ae2-f4f9-4a2b-9f13-b7bbd3d9399e.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F50627%2F0b269ae2-f4f9-4a2b-9f13-b7bbd3d9399e.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=ded4a59dfb810389095ce738702de928 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e今回作成したデモアプリケーションです。\u003cbr\u003e\nとってもWindowsなUIになっていますね。Materialデザインを適応出来るそうなので、見た目はもう少し綺麗にしたいと思います。\u003c/p\u003e\n\n\u003cp\u003e左上のボタン押下で、画像ファイルを読み込み、直下のイメージビューに表示します。\u003cbr\u003e\n中央のOCRボタンを押下すると、画像がポストされ結果が帰ってくるまで待ちます。\u003cbr\u003e\n受信したレスポンスから、OCR結果の全文を取得しテキストビューに設定します。\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"おわりに\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eおわりに\u003c/h1\u003e\n\n\u003cp\u003e　Google Cloud Vision APIを利用して、任意の画像に対するOCRを行うWindowsアプリケーションを作成することが出来ました。私は、画像処理や組み込み畑出身なので、Web界隈の知識はあまりないのですが、公式のドキュメントも非常によく整備されていて躓くことなく実装することが出来ました。\u003cbr\u003e\n　はじめに試した「tesseract-ocr」にて、今回使用するフォントの学習データを作ったり、OpenCVで前処理をしたりと地道な処理をセコセコ書いていました。しかしながら、Microsoft Cognitive ServicesのVision API、Google Cloud PlatformのCloud Vision API双方とも、グレースケール化程度の前処理のみで良好な結果を出してしまいました。\u003cbr\u003e\n　やはり、単なる画像処理の限界を改めて痛感させられました。今回は、Microsoft、Googleと外部の企業のサービスを利用したのですが、自社内で将来的には内製化する必要があるなと感じました。\u003cbr\u003e\n　そして、私人身も機械学習について本格的に学ぶ必要が有るなと思った次第です。機械学習を用いてOCRを行うAPIをこれから作っていこうと思います。\u003c/p\u003e\n\n\u003cp\u003eまた、今回のコードを私のGitHubに上げました。\u003cbr\u003e\nとてもツッコミどころ満載のコードだと思いますので、ツッコミいただければと思います。\u003cbr\u003e\n\u003ca href=\"https://github.com/takashi-miyahara/SimpleOCRApp_for_GoogleCloudVisionAPI\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttps://github.com/takashi-miyahara/SimpleOCRApp_for_GoogleCloudVisionAPI\u003c/a\u003e\u003c/p\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"参考\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e参考\u003c/h1\u003e\n\n\u003cp\u003e\u003ca href=\"https://cloud.google.com/vision/docs/label-tutorial?hl=ja\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttps://cloud.google.com/vision/docs/label-tutorial?hl=ja\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://github.com/msm2020/OCR-google-APIs\" class=\"autolink\" rel=\"nofollow noopener\" target=\"_blank\"\u003ehttps://github.com/msm2020/OCR-google-APIs\u003c/a\u003e\u003c/p\u003e\n","createdAt":"2018-03-12T13:24:45Z","elapsedYearsFromLastModifiedAt":3,"encryptedId":"FtKAp4EBswbMQhwl/q6ZEMxbFqf1DdD0--8w6LjqZ9gDYItXvP--7G5mUdeq8j39BwThS+psbQ==","isBanned":false,"isDeprecated":true,"isDestroyableByViewer":false,"isEditRequestReadableByViewer":true,"isEditRequestSendableByViewer":true,"isLikableByViewer":true,"isLikedByViewer":false,"isPublic":true,"isSlide":false,"isStockableByViewer":true,"isStockedByViewer":false,"isSubscribableByViewer":false,"isSubscribedByViewer":false,"isUpdatableByViewer":false,"isUpdated":true,"lastModifiedAt":"2018-03-13T01:55:45Z","likesCount":17,"linkUrl":"https://qiita.com/nyagato_00/items/4a764260ec76e8504cf4","organization":null,"originalId":618546,"stockedCount":23,"title":"C#でGoogle Cloud Vision APIを利用して、簡易OCRアプリケーションを作成する","toc":"\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\"\u003eはじめに\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9Focr%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AAapi\"\u003e使ってみたOCRライブラリ・API\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%9D%E3%82%8C%E3%81%9E%E3%82%8C%E3%81%AEocr%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E7%B2%BE%E5%BA%A6%E9%9B%91%E6%84%9F\"\u003eそれぞれのOCRライブラリの精度（雑感）\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#tesseract-ocr\"\u003etesseract-ocr\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#microsoft-azure-computer-vision-api\"\u003eMicrosoft Azure Computer Vision API\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#google-cloud-vision-api\"\u003eGoogle Cloud Vision API\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\"\u003eインストール\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E8%A3%85\"\u003e実装\u003c/a\u003e\n\u003cul\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E8%AA%8D%E8%A8%BC%E5%87%A6%E7%90%86\"\u003e認証処理\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%83%AA%E3%82%AF%E3%82%A8%E3%82%B9%E3%83%88%E3%82%92%E6%A7%8B%E7%AF%89\"\u003eリクエストを構築\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%B5%90%E6%9E%9C%E3%82%92%E8%BF%94%E3%81%99%E9%96%A2%E6%95%B0\"\u003e結果を返す関数\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cli\u003e\n\u003ca href=\"#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3\"\u003eアプリケーション\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB\"\u003eおわりに\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e参考\u003c/a\u003e\n\u003c/li\u003e\n\n","totalPv":9891,"uuid":"4a764260ec76e8504cf4","banReason":null,"adventCalendarItem":null,"author":{"encryptedId":"b2DUld0HFjnJhXWI5UHevLVmdiw=--0guD2Nm+70UiNPa4--D120C5yVoErYTpsRl6aBOA==","originalId":50627,"description":"Twitterのnyagato_00です.\r\nQiitaの方のアカウントを作りました.主には画像処理・センサ信号処理を大学時代の研究で行っていました。今は組み込みエンジニアからRailsエンジニアにジョブチェンジしました。\r\n","facebookUrl":null,"githubUrl":null,"isBlockingViewer":false,"isFollowableByViewer":true,"isFollowedByViewer":false,"isTweetWebNotificationReceivable":true,"linkedinUrl":null,"name":"","profileImageUrl":"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/50627/profile-images/1598706015","profileImageUrlW48":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F50627%2Fprofile-images%2F1598706015?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=0c233a5f702b8537389ff2893e6f3e95","profileImageUrlW75":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F50627%2Fprofile-images%2F1598706015?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=6e3c62d2e3e371ca855baca308e15bef","urlName":"nyagato_00","websiteUrl":"","twitterUrl":"https://twitter.com/TakashiMiyahara","twitterUrlName":"TakashiMiyahara","revealedOrganizations":{"edges":[{"node":{"encryptedId":"jugJwO6Fe4aju5Zk5V34hVyA6z8N5TWZgUU=--sHezKnF0d8wxR9zE--fxP+OOFbWbznwXm2Jl9+vw==","isBetaReleaseEnabled":false,"isFollowableByViewer":false,"isFollowedByViewer":false,"name":"岩手県立大学","logoUrl":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/bb5cc699d3a95ccb8d00624f5d69b73615e21eb8/original.jpg?1511144968","urlName":"iwate-pu","description":"岩手県滝沢市にある公立大学です。Qiitaではソフトウェア情報学部生や出身の人が多いです。","url":"https://www.iwate-pu.ac.jp/"}}]}},"tags":[{"name":"C#","urlName":"csharp"},{"name":"GoogleCloudPlatform","urlName":"googlecloudplatform"},{"name":"VisionAPI","urlName":"visionapi"}],"followingLikers":{"edges":[]},"comments":{"totalCount":0}},"comments":[],"client":null,"ads_event_emitter":null}}</script>
