More than 3 years have passed since last update.この記事はAndroidの画面をPCにミラーリングするソフトを作る１の続きです。
Androidの画面をミラーリングする機能の作り方は、そちらで解説しています。マウスでAndroid端末を操作できるようにします。
AndroidとPC間のコネクションは１本にしたいところですが、プログラムが複雑になりそうだったので妥協しました。FFmpegから流れてくるデータを表示します。
また、マウス操作をスクリーンのタッチ操作に変換して端末側に投げます。前回同様、画面の内容をエンコードし、PC側に流します。
また、PC側からタッチイベントを受取り、それをシステムに介入させます。このセクションでは、Android端末がどのようにタッチやキー操作を扱っているかについての説明をします。
知らなくてもリアルタイムタッチの実装はできますので、興味がなければ「いざ、実装」まで飛ばしてください。PCからAndroidを操作するにはどうすればいいのでしょうか？
簡単な例から見てみます。AndroidはLinuxベースのOSです。ですから、機能限定版であるものの、Linuxのターミナルを使用できます。とすることで対話に入ることができます。
そして、タッチ操作やキー操作などを送るinputというコマンドが用意されているのでそれを使用します。
以下に例を出します。これらを実行することで手軽に端末にイベントを送ることができます。
しかし実行してみると、イベントが発行されるまで時間がかかります。
これではリアルタイムな操作に向きません。
また、タップやスワイプ以外の複雑な操作をしたい場合はどうすればよいのでしょうか。geteventコマンドは端末のタッチパネルや物理キーから送られてくるデータを出力してくれるコマンドです。
以下のコマンドを実行してからタッチパネルを操作してみてください。すると以下の画像のように数値がズラッと表示されると思います。

これはタッチパネルから送られてくるデータです。
OSはこのデータを解釈し、反映させます。
実際にどのように解釈されているかについては【Android】プログラムから端末をタッチする【ADB】で説明されているのでご覧ください。sendeventはあたかもタッチパネルなどから送られてきたデータのように、任意のデータを送ることができるコマンドです。
つまり、geteventで得たデータをsendeventで送り直すことでタッチ操作を再現することができます。
しかし、このコマンドも実行速度が遅く、完全再現とは行きません。AndroidはLinuxベースのため、デバイスファイルを使用しています。
WindowsといったUnix系でないOSを使っている方には馴染みが無いかもしれませんが、
デバイスファイルとは、接続されている様々なデバイスとやり取りを行うのに使用する特殊なファイルのことです。
例えば、タッチパネルのデバイスファイルを開くと、geteventで得たようなタッチパネルの操作に関するデータを読み出すことができます。
逆に、デバイスファイルに書き込むとsendeventと同じように、書き込んだデータはそのデバイスから送られてきたものとして処理されます。
デバイスファイル (device file)
デバイススペシャルファイル
このあたりが参考になると思います。では実際にデバイスファイルを開いてみましょう。
先程の画像に/dev/input/event4というパスが記載されていると思います。
これがデバイスファイルの場所になります。
/dev/inputディレクトリにはevent0、event1....といくつかのデバイスファイルが存在しており、それがタッチパネルや物理キー、センサーなどと対応しています。対応する番号は端末によって違うので、注意してください。このコマンドを実行するとそのデバイスからのデータが流れてきます。が、こうなります。
デバイスファイルから得られる生データはバイナリデータであり、文字で表示するものではないのです。
getEventやsendEvent、冒頭で紹介したinputコマンドは、バイナリ⇔文字(数値)の変換を行ってくれているのです。ちなみに、と、することで生データをファイルに保存することができるのでとすると、タッチデータを再現することができますが、ここにも罠があります。
それは、実行速度が早すぎることです（苦笑）。
数秒間で記録したイベントデータが一瞬で流れてしまうので、早すぎてうまく操作できないと思います。
操作を再現するにはsleepを挟むなどして、適切なタイミングでデータが送られるようにしなければいけません。要はPC側から送られてくるタッチイベントをデバイスファイルに流せれば良いわけです。
シェルスクリプトでも書けるかもしれませんが、せっかくAndroid Studioで開発を行っているので
Java/Kotlinで書ければ楽ですよね。しかし、今まで好き勝手にデバイスファイルにアクセスしていましたが、shell権限があってこそ成せた技なのです。つまり、通常のアプリにシステムファイルをいじる権限はないのです。（Root化されていれば別ですが）
自分も諦めかけていましたがこんな質問を見つけました。
How does vysor create touch events on a non rooted device?
VysorはRootを取っていない端末でどうやってリアルタイムのタッチイベントを実行しているのか？という質問です。
そして解答はWhat he does is, he then starts his Main class as a separate process using this shell user. Now, the Java code inside that Main class has the same privileges as the shell user (because duh, it's linux).彼が何をしているのかというと、Shellユーザーの権限を使用してMainクラスを別プロセスで起動しているんだよ。これでMainクラス内のJavaコードはShellユーザーと同じ権限を持っているわけさ（だってAndroidはLinuxだからね）つまり、shellからapkパッケージに含まれるクラスを実行するとその起動されたプログラムもshell権限を使用できるのです。
言われてみれば、不思議な事ではありませんが、思いつきませんでした。
今回はこの手法でリアルタイムタッチを実装しようと思います。前述のようにアプリからシステム領域に介入するにはshellの力が必要です。
まず、apkパッケージに含まれるクラスをshell権限で起動するには以下のようにします。apkファイルへのパスはで取得できますが、ここで普通にAndroid Studioでデバッグをしていると複数のパスが表示されます。
これはInstant Runという、ビルド時間を短縮したりプログラムの変更をリアルタイムで反映させる機能を使っている際に起こる現象です。
apkを複数に分割することで、変更時に差分のみをビルド、インストールして時短を図っているものと思われます。
しかし、分割されてしまっては上記のコマンドが正しく動かないので、Instant Runを無効にする必要があります。
設定の場所は以下のとおりです。
さらに注意なのが、ユーザーが起動するアプリ本体とshell権限で起動するプログラムは、同じパッケージに属するものの、プロセスが違うため、staticの共有などは一切できません。
その為、やり取りをしたい場合はsocketなどを通して行うことになります。まずは以下のコードを見てください。このコードはここを参考に、新しいAPIを使用するように多少変更しています。通常はアクセスできないシステムのメソッドやインスタンスに、shell権限を利用してリフレクションでアクセスするという力技を行っています。
「injectInputEvent」というのがそうで、そのメソッドにイベントデータを渡すとイベントが実行されます。
そのメソッドは実際どこにあるのか、AOSPのソースを見てみたところ、ここの914行目にありました。
Hideアノテーションで普通はアクセス出来ないようになっています。
リフレクション？という方はこの記事が参考になるかと思います。パソコンから送られてくるイベントを上記のInputServiceクラスを使用して実行します。単純なサーバープログラムです。
PCとのデータのやり取りをjsonを使ってモダンにすることも考えたのですが、
大したことはしないので、空白を区切りとしたcsvのような形式で送ることにしました。Android側の実装はこれだけです。
全体のコードはこちら次にPC側の実装を行います。C# &amp; WPFで作成しようと思います。
WinFormsを選ばなかった理由は、仕様的？に画像を60FPSで表示することが困難だったからです。
実装してみたら体感30FPSくらいでした。
DoubleBufferedを無効にすると60FPSになりましたがチラツキがすごく、実用的ではありませんでした。WPFも微妙な感じがしますが、GPUを描画に使っている分WinFormsよりはマシです。
本気でやるならOpenGL(C#ならOpenTK)などのグラフィックAPIを使うことになりますね...
まさか、送信側より受信側がボトルネックになるとは思いませんでした^^;クライアントの全体のコードはこちらこの先頻繁に使う機能をまとめておきます。
あるデータから必要な数値のみを取り出す、といった場合正規表現がかなり便利です。
さらにその検証にOnline regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript
こういったサイトがとても便利です。どんなOSのアプリケーションにも標準で入力、出力する機能が備わっています。
一般的な動画変換ソフトでは入出力をファイルで行いますが、FFmpegは標準入出力が使えるので出力先をstdoutにすることで、プログラムからデコードされたデータを読むことができます。また、FFmpegの場合、stderrからログが出力される仕様になっています。
以下のプログラムはFFmpegを起動し、stdout、stderrとのコネクションを確立するものです。必要な引数を設定しFFmpegを起動します。
出力からデータを取得する方法には２つの方法があり、１つ目がイベントに登録する方法、２つ目がストリームを取得し自分で読む方法です。
前者は手軽に取得することができますが、文字データに変換されるのでバイナリデータのやり取りには使用できません。
後者はストリームを扱うので少々面倒ですが細かい制御が可能です。
今回、stderrからはログが流れてくるので前者を、stdoutからは画像のバイナリデータが流れてくるので後者の方法でデータを読み出します。今後送られてくる生データを復元するには画像のサイズが必須です。
FFmpegは変換を開始する時に、これから出力するストリームの情報をログに出力するのでそこから画像のサイズを抜き取る荒業を行います。
またbytePerFrameという変数は1フレームの画像の生成に必要なバイト数です。
画像の縦x横x1ピクセルに使用するバイト数で算出できます。
今回はFFmpegにrgb24で出力するよう設定している(rgbにそれぞれ8bitで24bit)ので1ピクセルに使用するバイト数は3です。
画像の仕組みの知識に不安がある方は、意外と知らない？画像の基礎知識とファイルの構造。を読んでみてください。ストリームからデータを取得し、MemoryStreamに蓄積していきます。
1フレーム分のデータが確保できた場合、MemoryStream内のデータを画像に復元します。
WritableBitmapに配列から復元してくれるメソッドがあるのでそれを使用します。
また、WritableBitmapへのアクセスはUIスレッドで行う必要があります。始めに adb shell getevent -iを実行し、出力を読み取っていますが、
このコマンドはAndroidの入力デバイスに関するデータを表示するコマンドです。
ここでは、タッチパネルがとり得る座標の最大値を取得しています。
そして、InputHostを起動しています。
起動するまで１秒待機と荒いことをやっていますがご了承ください。接続周りの準備は完了したので、あとはInputHostにデータを送信していくだけです。imageのマウスに関するイベントを使用し、データを送信しています。
空白区切で２つ目の0,1,2という数値は0がDonw、1がUp、2がMoveの意味です。
また、キーイベントは以下のようにしています。空白区切で２つ目は上と同じ意味です。
３つ目はキーの固有番号で、KeyEventで確認ができます。
また、端末に実装されていないキーも送ることができます。
例えば120にはPrintScreenキーが割り振られています。
スクリーンショットは普段は電源キーと音量Downの同時押しで行っていますが
このキーを送信するだけでスクリーンショットが取れたりします。
すぐに試したい方はで再現できます。ポートフォアーティングやInputHostをshellから起動するなど、
面倒なことは全てクライアントソフトに実装したので簡単です。１．Android側でアプリを起動し、スタートを押す
２．クライアントソフトを起動するこれだけです。
これで画面が映し出され、マウスで画面を操作することができます。Shellでapk内のクラスを実行するというのが普段のアプリ開発で無いことなので最初は戸惑いましたが、実装することができました。
今回の機能でadbは必須になってしまったので通常のユーザーに配布するならadbを導入して貰う必要が出てしまいました。
最も、今はadbのみのダウンロードができるようになっているので、導入の敷居も下がってると思いますが。（同梱はありなのかな？）これでだいぶVysorに近づいてきました。
ただ、まだ文字入力やファイル転送ができていないので、次はそこを実装したいと思います。
では、最後までご覧下さりありがとうございました。


