<!DOCTYPE html><html><head><meta charset="utf-8" /><title>Windows PCかつオフライン環境でお気軽に画像認識する ML.NET 1.0 対応版 - Qiita</title><meta content="width=device-width,initial-scale=1,shrink-to-fit=no,viewport-fit=cover" name="viewport" /><meta content="#55c500" name="theme-color" /><meta content="XWpkTG32-_C4joZoJ_UsmDUi-zaH-hcrjF6ZC_FoFbk" name="google-site-verification" /><meta content="telephone=no" name="format-detection" /><link rel="canonical" href="https://qiita.com/ksasao/items/8a76d6048e28defeb39a" /><link href="/manifest.json" rel="manifest" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link as="script" href="https://www.googletagservices.com/tag/js/gpt.js" rel="preload" /><link href="https://securepubads.g.doubleclick.net" rel="preconnect" /><script async="" src="https://www.googletagservices.com/tag/js/gpt.js"></script><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="nEoSwWLTtnSN2EFOoVwr/BqgPdAW/eXq0eLYM1YB/zOTTQhwTPpzeUfqL/HDGZKYJBKM5bS8d12ZrBmOBxYRfw==" /><link rel="shortcut icon" type="image/x-icon" href="https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico" /><link rel="apple-touch-icon" type="image/png" href="https://cdn.qiita.com/assets/favicons/public/apple-touch-icon-ec5ba42a24ae923f16825592efdc356f.png" /><link rel="stylesheet" media="all" href="https://cdn.qiita.com/assets/public/article-2eaa7dbedc42a8ea65c722cda46d0ebb.min.css" /><script src="https://cdn.qiita.com/assets/public/v3-article-bundle-63de2d91fef827269d3f6b958db2335b.min.js" defer="defer"></script><meta name="twitter:card" content="summary_large_image"><meta content="@Qiita" name="twitter:site" /><meta content="@ksasao" name="twitter:creator" /><meta property="og:type" content="article"><meta property="og:title" content="Windows PCかつオフライン環境でお気軽に画像認識する ML.NET 1.0 対応版 - Qiita"><meta property="og:image" content="https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0&amp;w=1200&amp;mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND1WMmx1Wkc5M2N5QlFRLU9CaS1PQnBPT0NxdU9EbGVPRHFlT0NwT09Ecy1lU3NPV2lnLU9CcC1PQml1YXdsLWk3dmVPQnEtZVV1LVdEai1pcWplaXRtT09CbWVPQ2l5Qk5UQzVPUlZRZ01TNHdJT1d2dnVXX25PZUppQSZ0eHQtY29sb3I9JTIzMzMzJnR4dC1mb250PUhpcmFnaW5vJTIwU2FucyUyMFc2JnR4dC1zaXplPTU0JnR4dC1jbGlwPWVsbGlwc2lzJnR4dC1hbGlnbj1jZW50ZXIlMkNtaWRkbGUmcz1kZTI5NzQ0NGY3MzFhMTczMDc4NzVlZmQ0ODdkYjMzYQ&amp;mark-align=center%2Cmiddle&amp;blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RR3R6WVhOaGJ3JnR4dC1jb2xvcj0lMjMzMzMmdHh0LWZvbnQ9SGlyYWdpbm8lMjBTYW5zJTIwVzYmdHh0LXNpemU9NDUmdHh0LWFsaWduPXJpZ2h0JTJDYm90dG9tJnM9ZDczOWEyNDBjNGUxMzQ3NjQxMzc0Njg3Y2FhYjcwZDE&amp;blend-align=center%2Cmiddle&amp;blend-mode=normal&amp;s=9b5aaee5ea5e637e011fdc9faf3a0ec8"><meta property="og:description" content="

TL;DR

Windows, つよいGPUがない, インターネットに画像をアップできない, アドミン権限がないなどの環境でも動作する、転移学習を利用した画像認識アプリを .NET Framework (Windows Forms..."><meta content="https://qiita.com/ksasao/items/8a76d6048e28defeb39a" property="og:url" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><meta content="Windows,C#,機械学習,転移学習,ML.NET" name="keywords" /><script>!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};
if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];
s.parentNode.insertBefore(t,s)}(window, document,'script',
'https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '668972150489891');
fbq('track', 'PageView');</script><style data-emotion-css="17jxvjw 11t2ec1 1dvr2p8 18lkoru 1g4cku8 1iupg5d ijvq0v 15cocm3 12rp90f 115f4t 1b8uj5v 79elbk 16hhh7b fcbn8c 1gj7nt 154zy0m yikrym 1jqivyb 1ode1bp le4d8r 1hbd3g7 1nzh4zz 38fzdi helsa7 8qb8m4 2imjyh he5w1s 70qvj9 3ojehk 100alwu 1dtnjt5 10ougpm 1ay9vb9 m19uds cgzq40 1wa99t2 1l3zk9f 4czcte 1yzj1fm 1uv1qiv 109dbrr 5jpx49 mnxgyc 1vlpknv fsjkhv 1b17vb0 7i7f4d"}>.css-17jxvjw{display:grid;display:-ms-grid;grid-template-columns:80px minmax(0,1fr) 300px;-ms-grid-columns:80px minmax(0,1fr) 300px;grid-template-rows:minmax(270px,auto) 1fr;-ms-grid-rows:minmax(270px,auto) 1fr;max-width:1280px;margin-right:auto;margin-left:auto;padding-top:24px;padding-right:24px;padding-left:24px;}@media (max-width:1200px){.css-17jxvjw{padding-bottom:0;padding-left:0;padding-right:0;}}@media (max-width:992px){.css-17jxvjw{grid-template-columns:80px 452px 300px;-ms-grid-columns:80px 452px 300px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}@media (max-width:770px){.css-17jxvjw{display:block;}}@media (max-width:480px){.css-17jxvjw{padding-top:0;}}.css-11t2ec1{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;z-index:5;position:-webkit-sticky;position:sticky;top:calc(56px + 24px + 16px + 32px - 16px);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:16px;width:80px;}.css-11t2ec1:after{content:'';display:table;}.css-11t2ec1:before{content:'';display:table;}@media (max-width:770px){.css-11t2ec1{display:none;}}.css-1dvr2p8{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-18lkoru{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;background-color:#FFFFFF;}.css-1g4cku8{display:inline-block;vertical-align:middle;height:20px;width:20px;fill:#55C500;}.css-1iupg5d{color:#55C500;cursor:pointer;font-size:14px;font-weight:bold;}.css-ijvq0v{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-15cocm3{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:#FFFFFF;border:2px solid #6E6F70;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:2px 0px 0px;width:40px;}.css-12rp90f{display:inline-block;vertical-align:bottom;height:17.77777777777778px;width:16px;fill:#6E6F70;}.css-115f4t{color:#6E6F70;font-size:14px;font-weight:bold;}.css-1b8uj5v{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;margin-bottom:16px;padding:0;}.css-79elbk{position:relative;}.css-16hhh7b{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;padding:0;}.css-fcbn8c{display:none;bottom:initial;left:initial;right:initial;top:initial;left:100%;top:calc(-8px - (14px * 1.8) - 16px - 4px);}.css-1gj7nt{color:rgba(0,0,0,0.6);font-size:14px;font-weight:bold;line-height:1.8;padding:8px 16px;}.css-154zy0m{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.87);cursor:pointer;font-size:16px;font-weight:normal;line-height:1.8;padding:4px 16px;}.css-154zy0m:hover{-webkit-text-decoration:none;text-decoration:none;background-color:#F2F2F2;}.css-yikrym{width:20px;}.css-1jqivyb{color:rgba(0,0,0,0.6);font-size:13px;}.css-1ode1bp{background-color:rgba(0,0,0,0.12);height:1px;width:100%;margin:8px 0;}.css-le4d8r{display:inline-block;vertical-align:middle;height:13px;width:13px;fill:rgba(0,0,0,0.6);}.css-1hbd3g7{height:250px;}.css-1nzh4zz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:16px 32px;background-color:#FBE69E;color:rgba(0,0,0,0.87);line-height:1.5;font-weight:600;}@media (max-width:770px){.css-1nzh4zz{padding:16px;}}.css-38fzdi{color:#CA832A;margin-right:4px;}.css-helsa7{background-color:#FFFFFF;padding:32px;margin-bottom:24px;}@media (max-width:992px){.css-helsa7{margin:0 auto 40px;}}@media (max-width:480px){.css-helsa7{margin:0 0 40px;padding:32px 16px;}}.css-8qb8m4{margin-bottom:48px;}.css-2imjyh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-he5w1s{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:100%;}@media (max-width:770px){.css-he5w1s{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}}.css-70qvj9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.css-3ojehk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;margin-right:4px;}.css-100alwu{display:inline-block;border-radius:50%;line-height:1;overflow:hidden;vertical-align:middle;}.css-1dtnjt5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-10ougpm{color:rgba(0,0,0,0.87);font-size:14px;font-weight:600;line-height:1.8;margin-right:4px;text-wrap:break-word;word-break:break-all;}.css-1ay9vb9{margin-right:16px;}.css-m19uds{color:rgba(0,0,0,0.6);font-size:14px;line-height:1.8;}.css-cgzq40{color:rgba(0,0,0,0.87);font-size:32px;font-weight:bold;line-height:1.4;margin-top:8px;text-wrap:break-word;word-break:break-all;}.css-1wa99t2{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.6);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:8px;}.css-1l3zk9f{color:rgba(0,0,0,0.6);font-size:20px;margin-right:8px;}.css-4czcte{margin-right:4px;color:inherit;font-size:14px;line-height:1.8;}.css-4czcte:not(:last-child)::after{content:',';margin-right:4px;}.css-1yzj1fm{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:32px;}.css-1uv1qiv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-size:20px;height:32px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-right:16px;outline:none;padding:0;width:32px;}.css-109dbrr{background-color:#F9F9F9;border-top:1px solid rgba(0,0,0,0.12);bottom:0;box-shadow:0px 1px 4px rgba(0,0,0,0.14);display:none;height:calc(env(safe-area-inset-bottom,0px) + 56px);-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding-bottom:env(safe-area-inset-bottom);position:-webkit-sticky;position:sticky;width:100%;z-index:2000;}@media (max-width:770px){.css-109dbrr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}.css-5jpx49{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-evenly;-webkit-justify-content:space-evenly;-ms-flex-pack:space-evenly;justify-content:space-evenly;width:100%;}.css-mnxgyc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1vlpknv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;margin-right:4px;background-color:#FFFFFF;}.css-fsjkhv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1b17vb0{color:#6E6F70;font-size:14px;font-weight:bold;margin-left:4px;}.css-7i7f4d{display:none;bottom:initial;left:initial;right:initial;top:initial;bottom:32px;right:0;}</style></head><body><div class="allWrapper"><div><div id="GlobalHeader-react-component-9cfdfe8c-a497-4719-b9ba-5a218b4d14fe"><div class="st-Header"><div class="st-Header_container"><div class="st-Header_start"><a href="/" class="st-Header_logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 426.57 130"><circle cx="167.08" cy="21.4" r="12.28"></circle><path d="M250.81 29.66h23.48v18.9h-23.48z"></path><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z"></path><circle cx="216.33" cy="21.4" r="12.28"></circle></svg></a><div class="st-Header_communitySelector" tabindex="0"><span class="fa fa-caret-down"></span></div><div class="st-Header_dropdown"><div class="st-Header_dropdownHeading">Qiita Teams that are logged in</div><div class="st-Header_dropdownItemNote">You are not logged in to any team</div><hr class="st-Header_dropdownDivider st-Header_dropdownDivider-shrink"/><a href="https://teams-center.qiita.com/find_team" class="st-Header_dropdownItem"><span class="fa fa-fw fa-sign-in st-Header_dropdownItemIcon"></span><div>Log in to Qiita Team</div></a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Community</div><a href="/organizations" class="st-Header_dropdownItem">Organization</a><a href="/official-events/open" class="st-Header_dropdownItem">Event</a><a href="/advent-calendar" class="st-Header_dropdownItem">Advent Calendar</a><a href="https://qiitadon.com/" class="st-Header_dropdownItem" target="_blank">Qiitadon (β)</a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Service</div><a href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Jobs</a><a href="https://zine.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Zine</a><a href="https://blog.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Blog</a></div><form class="st-Header_search" action="/search" method="get"><span class="fa fa-search st-Header_searchIcon"></span><input type="search" class="st-Header_searchInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form><form class="st-Header_searchModal" action="/search" method="get"><input type="text" class="st-Header_searchModalInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form></div><div class="st-Header_end"><div class="st-Header_searchButton"><span class="fa fa-search"></span></div><a class="st-Header_signupButton" href="/signup?redirect_to=%2Fksasao%2Fitems%2F8a76d6048e28defeb39a">Signup</a><a class="st-Header_loginLink" href="/login?redirect_to=%2Fksasao%2Fitems%2F8a76d6048e28defeb39a">Login</a></div><div class="st-Header_overlay"></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="GlobalHeader" data-dom-id="GlobalHeader-react-component-9cfdfe8c-a497-4719-b9ba-5a218b4d14fe">{"unreadNotificationsCount":null,"realms":[{"humanName":"Qiita","isCurrentRealm":true,"isQiita":true,"isQiitaTeam":false,"loggedInUser":null,"teamId":null,"url":"https://qiita.com/"}],"teamFindUrl":"https://teams-center.qiita.com/find_team","isTeamOnlyUser":null,"currentUser":null}</script>
      
</div><div class="st-HeaderAlert st-HeaderAlert-warning"><div class="st-HeaderAlert_body"></div></div><script type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"/","name":"Qiita"}},{"@type":"ListItem","position":2,"item":{"@id":"/tags/windows","name":"Windows"}}]}</script><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","datePublished":"2018-12-09T19:29:06.000+09:00","dateModified":"2019-05-26T16:51:58.000+09:00","headline":"Windows PCかつオフライン環境でお気軽に画像認識する ML.NET 1.0 対応版","image":"https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0\u0026w=1200\u0026mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND1WMmx1Wkc5M2N5QlFRLU9CaS1PQnBPT0NxdU9EbGVPRHFlT0NwT09Ecy1lU3NPV2lnLU9CcC1PQml1YXdsLWk3dmVPQnEtZVV1LVdEai1pcWplaXRtT09CbWVPQ2l5Qk5UQzVPUlZRZ01TNHdJT1d2dnVXX25PZUppQSZ0eHQtY29sb3I9JTIzMzMzJnR4dC1mb250PUhpcmFnaW5vJTIwU2FucyUyMFc2JnR4dC1zaXplPTU0JnR4dC1jbGlwPWVsbGlwc2lzJnR4dC1hbGlnbj1jZW50ZXIlMkNtaWRkbGUmcz1kZTI5NzQ0NGY3MzFhMTczMDc4NzVlZmQ0ODdkYjMzYQ\u0026mark-align=center%2Cmiddle\u0026blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RR3R6WVhOaGJ3JnR4dC1jb2xvcj0lMjMzMzMmdHh0LWZvbnQ9SGlyYWdpbm8lMjBTYW5zJTIwVzYmdHh0LXNpemU9NDUmdHh0LWFsaWduPXJpZ2h0JTJDYm90dG9tJnM9ZDczOWEyNDBjNGUxMzQ3NjQxMzc0Njg3Y2FhYjcwZDE\u0026blend-align=center%2Cmiddle\u0026blend-mode=normal\u0026s=9b5aaee5ea5e637e011fdc9faf3a0ec8","mainEntityOfPage":"https://qiita.com/ksasao/items/8a76d6048e28defeb39a","author":{"@type":"Person","address":"","email":null,"identifier":"ksasao","name":"ksasao","image":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F43450%2Fprofile-images%2F1580891297?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=e8e680f6114900fe05b3daf56987880e","url":"https://qiita.com/ksasao","description":"","memberOf":[{"@type":"Organization","address":"東京都港区虎ノ門一丁目17番1号 虎ノ門ヒルズビジネスタワー","legalName":"日鉄ソリューションズ株式会社","image":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/5f593dbfc9b43ff3b5a3abd19a0e274dea090585/original.jpg?1540194581","logo":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/c7162dfc415b13511f9913252f443b7afd69f1d5/original.jpg?1540194581","identifier":"nssol","description":"お堅いと評判のユーザ系SIerです。※各記事の内容は個人の見解であり、所属する組織の公式見解ではありません。"}]},"publisher":{"@type":"Organization","name":"Qiita","logo":{"@type":"ImageObject","url":"//cdn.qiita.com/assets/public/qiita-logo-c39ded593afa388e2e1ba435b110554e.png"}}}</script><style type="text/css">.wb-CampaignLink {
  background-color: #333333;
  width: 100%;
}

.wb-CampaignLink_container {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  max-width: 1100px;
  margin: 0 auto;
  font-size: 13px;
  padding: 0.8em;
}
.wb-CampaignLink_container > a {
  color: #fff;
}

.wb-CampaignLink_container > a:hover {
  text-decoration: underline;
}</style><div class="wb-CampaignLink"><div class="wb-CampaignLink_container"><a target="_blank" id="header_text_message_1" href="https://zine.qiita.com/interview/202107-hitachi-3/?utm_source=qiita&amp;utm_medium=header-banner">日立の研究者が、2年間ドイツ人工知能研究センターで学んだこと</a><a target="_blank" id="header_text_message_2" href="https://zine.qiita.com/interview/202107-hitachi-3/?utm_source=qiita&amp;utm_medium=header-banner">詳しくはこちら</a></div><script>td.trackEvent(
  'front_events',
  {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"ksasao","type":"items","id":"8a76d6048e28defeb39a"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Show","data":{"message":"日立の研究者が、2年間ドイツ人工知能研究センターで学んだこと","url":"https://zine.qiita.com/interview/202107-hitachi-3/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
)</script><script>document.getElementById('header_text_message_1').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"ksasao","type":"items","id":"8a76d6048e28defeb39a"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_1","message":"日立の研究者が、2年間ドイツ人工知能研究センターで学んだこと","url":"https://zine.qiita.com/interview/202107-hitachi-3/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
  )
})</script><script>document.getElementById('header_text_message_2').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"ksasao","type":"items","id":"8a76d6048e28defeb39a"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_2","message":"日立の研究者が、2年間ドイツ人工知能研究センターで学んだこと","url":"https://zine.qiita.com/interview/202107-hitachi-3/?utm_source=qiita\u0026utm_medium=header-banner","sub_message":"詳しくはこちら"}}
  )
})</script></div><script type="application/json" id="js-react-on-rails-context">{"railsEnv":"production","inMailer":false,"i18nLocale":"en","i18nDefaultLocale":"en","href":"https://qiita.com/ksasao/items/8a76d6048e28defeb39a","location":"/ksasao/items/8a76d6048e28defeb39a","scheme":"https","host":"qiita.com","port":null,"pathname":"/ksasao/items/8a76d6048e28defeb39a","search":null,"httpAcceptLanguage":null,"actionPath":"public/items#show","settings":{"analyticsTrackingId":"UA-24675221-12","assetsMap":{},"csrfToken":"orm5dgfoaShayzWCrgMeYhvc9LfHtTfh0wYlfb9jyEytvqPHKcGsJZD5Wz3MRqcGJW5FgmX0pVabSOTA7nQmAA==","locale":"en"},"currentUser":null,"isLoggedIn":false,"recaptchaSiteKey":"6LfNkiQTAAAAAM3UGnSquBy2akTITGNMO_QDxMw6","serverSide":false}</script>
<div id="PersonalArticlePage-react-component-e2440b2c-bfa2-4688-ab80-5c03a82cfce5"><div class="p-items_wrapper"><div class=" css-17jxvjw"><div class="css-11t2ec1"><div class="css-1dvr2p8"><button class=" css-18lkoru"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/ksasao/items/8a76d6048e28defeb39a/likers" class="css-1iupg5d">56</a></div><div class="css-ijvq0v"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-115f4t">43</span></div><div class="css-1b8uj5v"><span class="fa fa-twitter"></span></div><div class="css-1b8uj5v"><span class="fa fa-facebook"></span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-fcbn8c"><div class="css-1gj7nt">Improve article</div><a href="/drafts/8a76d6048e28defeb39a/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/ksasao/items/8a76d6048e28defeb39a/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/ksasao/items/8a76d6048e28defeb39a/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/ksasao/items/8a76d6048e28defeb39a/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/ksasao/items/8a76d6048e28defeb39a.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div><div class="p-items_options"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_toc"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_main"><div class="css-1nzh4zz"><span class="fa fa-fw fa-warning css-38fzdi"></span><p>More than 1 year has passed since last update.</p></div><div class="css-helsa7"><div class="css-8qb8m4"><div class="it-AdcalRibbon"><a href="/organizations/nssol"><img src="https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/c7162dfc415b13511f9913252f443b7afd69f1d5/original.jpg?1540194581" class="it-AdcalRibbon_orgImage"/></a><span><a href="/advent-calendar/2018/nssol" class="it-AdcalRibbon_title">NSSOL<!-- --> Advent Calendar<!-- --> <!-- -->2018</a>Day 10</span></div><div class="css-2imjyh"><div class="css-he5w1s"><div class="css-70qvj9"><div class="css-3ojehk"><a href="/ksasao"><img class="css-100alwu eyfquo10" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43450/profile-images/1580891297" width="24" height="24" loading="lazy"/></a></div><div class="css-1dtnjt5"><a href="/ksasao" class="css-10ougpm">@<!-- -->ksasao</a><div class="css-1ay9vb9"><span><meta content="2018-12-09T10:29:06Z"/><time dateTime="2019-05-26T07:51:58Z" class="css-m19uds">updated at 2019-05-26</time></span></div></div></div></div></div><h1 class="css-cgzq40">Windows PCかつオフライン環境でお気軽に画像認識する ML.NET 1.0 対応版</h1><div class="css-1wa99t2"><span class="fa fa-tags mr-1of2 css-1l3zk9f" aria-hidden="true"></span><a href="/tags/windows" class="css-4czcte">Windows</a><a href="/tags/csharp" class="css-4czcte">C#</a><a href="/tags/%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92" class="css-4czcte">機械学習</a><a href="/tags/%e8%bb%a2%e7%a7%bb%e5%ad%a6%e7%bf%92" class="css-4czcte">転移学習</a><a href="/tags/ml.net" class="css-4czcte">ML.NET</a></div></div><section class="it-MdContent"><div id="personal-public-article-body"><div>
<h1>
<span id="tldr" class="fragment"></span><a href="#tldr"><i class="fa fa-link"></i></a>TL;DR</h1>

<p>Windows, つよいGPUがない, インターネットに画像をアップできない, アドミン権限がないなどの環境でも動作する、転移学習を利用した画像認識アプリを .NET Framework (Windows Forms) で作成しました。</p>

<p>アプリケーションをダウンロードし、分類したい名前を付けたフォルダに数枚ずつ画像を用意するだけで短時間で簡単に学習ができます。Pythonなどをインストールする必要もありません。色々なものを分類して最近の画像認識の精度を体感してみてください。</p>

<p>アプリケーションは、Microsoft がオープンソースで開発を進めている<a href="https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet" rel="nofollow noopener" target="_blank">ML.NET</a> (ML.NET単体では Linux, Macなどでも動きます) を利用しています。実装されている TensorFlow API を利用して、学習済みの Inception モデルを読み込み、画像特徴を抽出し、<a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.sdcamulticlasstrainer?view=ml-dotnet" rel="nofollow noopener" target="_blank">Stochastic Dual Coordinate Ascent(SDCA)</a> を利用した多クラス分類器用いて転移学習をします。</p>

<ul>
<li><a href="https://github.com/ksasao/ImageClassification" rel="nofollow noopener" target="_blank">ソースコード</a></li>
<li><a href="https://github.com/ksasao/ImageClassification/raw/master/app/ImageClassificationApp1.0.0.zip" rel="nofollow noopener" target="_blank">アプリ (Windows 10/x64/4GB以上のメモリ/Core i 程度のCPU/.NET Framework 4.6.1以降で動作)</a></li>
</ul>

<h1>
<span id="アプリケーションの利用方法" class="fragment"></span><a href="#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E5%88%A9%E7%94%A8%E6%96%B9%E6%B3%95"><i class="fa fa-link"></i></a>アプリケーションの利用方法</h1>

<ol>
<li>
<a href="https://github.com/ksasao/ImageClassification/raw/master/app/ImageClassificationApp1.0.0.zip" rel="nofollow noopener" target="_blank">アプリ</a>をダウンロードして展開し、<code>ImageClassificationApp1.0.0\ImageClassificationApp.exe</code> を起動します。</li>
<li>画像を学習するには、[学習する] のボタンをクリックし、開いたダイアログから画像を分類済みのフォルダ(下図の場合は SampleImages フォルダ)を選択してOKをクリックします。
<a href="https://camo.qiitausercontent.com/325f975f158a6c3f853e4e943fec87da43561d47/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f64333137633932612d343563642d633133372d323566662d3663366361626131313034642e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fd317c92a-45cd-c137-25ff-6c6caba1104d.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=aa23bc81f65fd6cb6d88a87a6d3b9a46" alt="image" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/43450/d317c92a-45cd-c137-25ff-6c6caba1104d.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fd317c92a-45cd-c137-25ff-6c6caba1104d.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=997d32e7cb5ddf722c9613d371f0919b 1x" loading="lazy"></a>
</li>
<li>10秒から1分程度で学習が完了します。<a href="https://camo.qiitausercontent.com/13d1b2d7574456c9f145c28b2e0c9c123644a579/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f39653463653936652d396330312d613263362d636535302d3033336261653736363038372e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F9e4ce96e-9c01-a2c6-ce50-033bae766087.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=ec841e1842721f487cd36ee9395cd50f" alt="image" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/43450/9e4ce96e-9c01-a2c6-ce50-033bae766087.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F9e4ce96e-9c01-a2c6-ce50-033bae766087.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=498c1ad8b0d59d098b2551654d9b1aa6 1x" loading="lazy"></a>下図のように表示されたら画像を Drag &amp; Drop すると認識結果と確信度(0～1, 1が最も高い)が表示されます。 <a href="https://camo.qiitausercontent.com/a27f5234fd820d97b91beaae783e24a6e3f38c74/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f33376636343033332d623963322d343735352d643864302d3735636435633364303736612e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F37f64033-b9c2-4755-d8d0-75cd5c3d076a.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=952331e132c80c763eb2ccfb8ac6a479" alt="image" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/43450/37f64033-b9c2-4755-d8d0-75cd5c3d076a.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F37f64033-b9c2-4755-d8d0-75cd5c3d076a.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=246c2008c823d6e48d4ec9eb0bb2f966 1x" loading="lazy"></a>
</li>
<li>あらかじめ学習したモデルを利用することも可能です。先ほど画像を学習したフォルダに<code>imageClassifier.zip</code>というファイルが生成されていますので、それを読み込んでみてください。学習済みモデルのファイル名は適宜変更可能です。また学習に利用した画像も不要です。<a href="https://camo.qiitausercontent.com/8a6699355129fdd331b15dca169961224590f030/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f38653336376463382d333332322d623032662d393765352d3665373737663739336634362e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F8e367dc8-3322-b02f-97e5-6e777f793f46.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=42312efa9cdd20e3131d60e106e7a688" alt="image" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/43450/8e367dc8-3322-b02f-97e5-6e777f793f46.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F8e367dc8-3322-b02f-97e5-6e777f793f46.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=f1acbc94d9d6fa89f5fd80b4f194c6eb 1x" loading="lazy"></a>
</li>
</ol>

<h1>
<span id="net-開発者向けの解説" class="fragment"></span><a href="#net-%E9%96%8B%E7%99%BA%E8%80%85%E5%90%91%E3%81%91%E3%81%AE%E8%A7%A3%E8%AA%AC"><i class="fa fa-link"></i></a>.NET 開発者向けの解説</h1>

<h2>
<span id="mlnet-とは" class="fragment"></span><a href="#mlnet-%E3%81%A8%E3%81%AF"><i class="fa fa-link"></i></a>ML.NET とは</h2>

<p><a href="https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet" rel="nofollow noopener" target="_blank">ML.NET</a> は Microsoft がオープンソースで進めている .NET 開発者向け機械学習フレームワークです(<a href="https://github.com/dotnet/machinelearning" rel="nofollow noopener" target="_blank">GitHub</a>)。クロスプラットフォームで開発されており、Windows, Linux,  macOS で動作します。Windows Hello, Bing Ads PowerPoint デザインアイディアなどでも使われています。<br>
類似のものとして、<a href="https://docs.microsoft.com/en-us/windows/ai/" rel="nofollow noopener" target="_blank">Windows Machine Learning</a> がありますが、こちらは Windows 10 以降の OS に特化したものとなります。API等に互換性はありません。</p>

<h2>
<span id="net-core-版-mlnet-を-windows-forms-から利用する" class="fragment"></span><a href="#net-core-%E7%89%88-mlnet-%E3%82%92-windows-forms-%E3%81%8B%E3%82%89%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B"><i class="fa fa-link"></i></a>.NET Core 版 ML.NET を Windows Forms から利用する</h2>

<p>ML.NET はクロスプラットフォームを実現するため .NET Core で作成されています。.NET Core で作成した DLL は、.NET Framework で作成しているアプリケーションからは直接参照することはできませんが、.NET Standard ライブラリを作成し、その中で .NET Core を利用するコードを記述すれば、.NET Framework から参照できるようになります。<del>今回は ML.NET 0.7.0 (.NET Core 2.0) を利用しているため、.NET Standard 2.0 / .NET Framework 4.6.1 以降が必要です。また、依存しているネイティブライブラリが x64 を対象としているため 64bit環境でのみ動作します。<br>
なお、 2018年12月時点の最新版である ML.NET 0.8.0 は、.NET Core 2.1 ベースとなっており、.NET Framework から利用するためには、.NET Standard 2.1 が必要となりますが <a href="https://github.com/dotnet/standard/milestone/3" rel="nofollow noopener" target="_blank">未リリース</a>です。</del>2019年5月時点の ML.NET 1.0 では .NET Core 2.1 ベースになっていますが、この記事の範囲内では .NET Core 2.0 でコンパイルしても動作するため、.NET Standard 2.0 でビルドしています。ビルドには .NET Framework 4.6.1 以降が必要です。また、依存しているネイティブライブラリが x64 を対象としているため 64bit環境でのみ動作します。</p>

<ol>
<li>.NET Standard 2.0 のクラスライブラリのプロジェクトを作成し、nuget を利用して、必要なライブラリ(今回は、Microsoft.ML 1.0.0, Microsoft.ML.ImageAnalytics 1.0.0, Microsoft.ML.TensorFlow 0.12.0)を追加する
<a href="https://camo.qiitausercontent.com/b795f32db41475fd31e411c615630896da425d0b/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f61623964383236612d346436622d636137392d613965642d3064313338333634396538312e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fab9d826a-4d6b-ca79-a9ed-0d1383649e81.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=411f4b5714755ec99c1b53e76c2f5c2f" alt="image" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/43450/ab9d826a-4d6b-ca79-a9ed-0d1383649e81.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fab9d826a-4d6b-ca79-a9ed-0d1383649e81.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=403eebb6361a98a0d9c5b1f358cfa89f 1x" loading="lazy"></a>
<a href="https://camo.qiitausercontent.com/96f8da9c95e759f50d038199c4296a8bc658b878/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f34333435302f30323138316137372d363631652d336665332d623432352d3666376238396466383135382e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F43450%2F02181a77-661e-3fe3-b425-6f7b89df8158.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=8be91c6fd42bdd254a8b3c7baf7b18a3" alt="image.png" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43450/02181a77-661e-3fe3-b425-6f7b89df8158.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F43450%2F02181a77-661e-3fe3-b425-6f7b89df8158.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=b2b4ad99548e037599c633273515877d 1x" loading="lazy"></a>
</li>
<li>1.のプロジェクトを .NET Framework のプロジェクトから参照する</li>
<li>.NET Framework のプロジェクトの .csproj を開き、<code>&lt;RestoreProjectStyle&gt;PackageReference&lt;/RestoreProjectStyle&gt;</code> を最初の <code>&lt;PropertyGroup&gt;</code> 内の先頭に追加する
<a href="https://camo.qiitausercontent.com/69aa5e7c6e212dd54b2f9404531a4b2b4c28efe6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f35636233633765392d313733652d313631322d333537652d6530363763363831323136352e706e67" target="_blank" rel="nofollow noopener"><img src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F5cb3c7e9-173e-1612-357e-e067c6812165.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=7096022f3bde90d08b90477938dbe0c8" alt="image" data-canonical-src="https://qiita-image-store.s3.amazonaws.com/0/43450/5cb3c7e9-173e-1612-357e-e067c6812165.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F5cb3c7e9-173e-1612-357e-e067c6812165.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=e2e4d03dea2c9dabe7e92371fd8282d7 1x" loading="lazy"></a>
</li>
<li>x64でビルドする</li>
</ol>

<p>下記のようなメッセージが出てデバッグ実行に失敗する場合は、10秒くらい待ってもう一度実行してください。</p>

<blockquote>
<p>The OutputPath property is not set for project 'CoreReferenceForm.csproj'.  Please check to make sure that you have specified a valid combination of Configuration and Platform for this project.  Configuration='Debug'  Platform='x64'.  This error may also appear if some other project is trying to follow a project-to-project reference to this project, this project has been unloaded or is not included in the solution, and the referencing project does not build using the same or an equivalent Configuration or Platform.  CoreReferenceForm           </p>
</blockquote>

<h3>
<span id="net-framework-版-mlnet" class="fragment"></span><a href="#net-framework-%E7%89%88-mlnet"><i class="fa fa-link"></i></a>.NET Framework 版 ML.NET</h3>

<p>Windows プラットフォーム限定となりますが、ML.NET の .NET Framework 版も提供されています。.NET Framework プロジェクトから、上記と同様に利用することが可能です。</p>

<h3>
<span id="参考" class="fragment"></span><a href="#%E5%8F%82%E8%80%83"><i class="fa fa-link"></i></a>参考</h3>

<ul>
<li><a href="https://www.buildinsider.net/language/dotnetcore/05" rel="nofollow noopener" target="_blank">.NET Standardなライブラリプロジェクトを作成して参照する</a></li>
<li><a href="https://www.hanselman.com/blog/ReferencingNETStandardAssembliesFromBothNETCoreAndNETFramework.aspx" rel="nofollow noopener" target="_blank">Referencing .NET Standard Assemblies from both .NET Core and .NET Framework</a></li>
</ul>

<h2>
<span id="実装について" class="fragment"></span><a href="#%E5%AE%9F%E8%A3%85%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><i class="fa fa-link"></i></a>実装について</h2>

<p>ML.NETのサンプルにある <a href="https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_TensorFlowEstimator" rel="nofollow noopener" target="_blank">Image Classification</a> をベースにしています。以下は説明のため部分的に抜粋しています。詳しくは <a href="https://github.com/ksasao/ImageClassification" rel="nofollow noopener" target="_blank">ソースコード</a>を参照してください。</p>

<h3>
<span id="学習" class="fragment"></span><a href="#%E5%AD%A6%E7%BF%92"><i class="fa fa-link"></i></a>学習</h3>

<p>ML.NET では下記のようにパイプラインを構成していきます。</p>

<div class="code-frame" data-lang="csharp"><div class="highlight"><pre class="with-code"><code><span class="kt">var</span> <span class="n">pipeline</span> <span class="p">=</span> <span class="n">mlContext</span><span class="p">.</span><span class="n">Transforms</span><span class="p">.</span><span class="n">Conversion</span><span class="p">.</span><span class="nf">MapValueToKey</span><span class="p">(</span><span class="n">outputColumnName</span><span class="p">:</span> <span class="n">LabelTokey</span><span class="p">,</span> <span class="n">inputColumnName</span><span class="p">:</span> <span class="s">"Label"</span><span class="p">)</span>
                <span class="p">.</span><span class="nf">Append</span><span class="p">(</span><span class="n">mlContext</span><span class="p">.</span><span class="n">Transforms</span><span class="p">.</span><span class="nf">LoadImages</span><span class="p">(</span><span class="n">outputColumnName</span><span class="p">:</span> <span class="s">"input"</span><span class="p">,</span> <span class="n">imageFolder</span><span class="p">:</span> <span class="n">imagesFolder</span><span class="p">,</span> <span class="n">inputColumnName</span><span class="p">:</span> <span class="k">nameof</span><span class="p">(</span><span class="n">ImageNetData</span><span class="p">.</span><span class="n">ImagePath</span><span class="p">)))</span>
                <span class="p">.</span><span class="nf">Append</span><span class="p">(</span><span class="n">mlContext</span><span class="p">.</span><span class="n">Transforms</span><span class="p">.</span><span class="nf">ResizeImages</span><span class="p">(</span><span class="n">outputColumnName</span><span class="p">:</span> <span class="s">"input"</span><span class="p">,</span> <span class="n">imageWidth</span><span class="p">:</span> <span class="n">ImageNetSettings</span><span class="p">.</span><span class="n">imageWidth</span><span class="p">,</span> <span class="n">imageHeight</span><span class="p">:</span> <span class="n">ImageNetSettings</span><span class="p">.</span><span class="n">imageHeight</span><span class="p">,</span> <span class="n">inputColumnName</span><span class="p">:</span> <span class="s">"input"</span><span class="p">))</span>
                <span class="p">.</span><span class="nf">Append</span><span class="p">(</span><span class="n">mlContext</span><span class="p">.</span><span class="n">Transforms</span><span class="p">.</span><span class="nf">ExtractPixels</span><span class="p">(</span><span class="n">outputColumnName</span><span class="p">:</span> <span class="s">"input"</span><span class="p">,</span> <span class="n">interleavePixelColors</span><span class="p">:</span> <span class="n">ImageNetSettings</span><span class="p">.</span><span class="n">channelsLast</span><span class="p">,</span> <span class="n">offsetImage</span><span class="p">:</span> <span class="n">ImageNetSettings</span><span class="p">.</span><span class="n">mean</span><span class="p">))</span>
                <span class="p">.</span><span class="nf">Append</span><span class="p">(</span><span class="n">mlContext</span><span class="p">.</span><span class="n">Model</span><span class="p">.</span><span class="nf">LoadTensorFlowModel</span><span class="p">(</span><span class="n">featurizerModelLocation</span><span class="p">).</span>
                     <span class="nf">ScoreTensorFlowModel</span><span class="p">(</span><span class="n">outputColumnNames</span><span class="p">:</span> <span class="k">new</span><span class="p">[]</span> <span class="p">{</span> <span class="s">"softmax2_pre_activation"</span> <span class="p">},</span> <span class="n">inputColumnNames</span><span class="p">:</span> <span class="k">new</span><span class="p">[]</span> <span class="p">{</span> <span class="s">"input"</span> <span class="p">},</span> <span class="n">addBatchDimensionInput</span><span class="p">:</span> <span class="k">true</span><span class="p">))</span>
                <span class="p">.</span><span class="nf">Append</span><span class="p">(</span><span class="n">mlContext</span><span class="p">.</span><span class="n">MulticlassClassification</span><span class="p">.</span><span class="n">Trainers</span><span class="p">.</span><span class="nf">LbfgsMaximumEntropy</span><span class="p">(</span><span class="n">labelColumnName</span><span class="p">:</span> <span class="n">LabelTokey</span><span class="p">,</span> <span class="n">featureColumnName</span><span class="p">:</span> <span class="s">"softmax2_pre_activation"</span><span class="p">))</span>
                <span class="p">.</span><span class="nf">Append</span><span class="p">(</span><span class="n">mlContext</span><span class="p">.</span><span class="n">Transforms</span><span class="p">.</span><span class="n">Conversion</span><span class="p">.</span><span class="nf">MapKeyToValue</span><span class="p">(</span><span class="n">PredictedLabelValue</span><span class="p">,</span> <span class="s">"PredictedLabel"</span><span class="p">))</span>
                <span class="p">.</span><span class="nf">AppendCacheCheckpoint</span><span class="p">(</span><span class="n">mlContext</span><span class="p">);</span>
</code></pre></div></div>

<p>上記のコードでは</p>

<ul>
<li>画像ファイルとその画像のラベル(クラス名; 日本語 (UTF-8) が利用可能)が記載された.tsvファイル読み込み</li>
<li>画像のリサイズ</li>
<li>Tensorflowモデルの読み込みと特徴抽出に利用する層(softmax2_pre_activation)の指定</li>
<li>
<a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.sdcamulticlasstrainer?view=ml-dotnet" rel="nofollow noopener" target="_blank">Stochastic Dual Coordinate Ascent(SDCA)</a> を利用した画像特徴の多クラス分類</li>
</ul>

<p>といったような各処理をつないでいます。パイプラインの構成は、画像に限らず、自然言語処理や数値(CSVファイル)データの学習でも同様です。詳しくは、ML.NETの<a href="https://dotnet.microsoft.com/learn/machinelearning-ai/ml-dotnet-get-started-tutorial" rel="nofollow noopener" target="_blank">チュートリアル</a>や<a href="https://github.com/dotnet/machinelearning-samples" rel="nofollow noopener" target="_blank">サンプルコード</a>を参照してください。</p>

<p>パイプラインができたら、そこに学習データを渡して学習を行います。</p>

<div class="code-frame" data-lang="csharp"><div class="highlight"><pre class="with-code"><code><span class="kt">var</span> <span class="n">data</span> <span class="p">=</span> <span class="n">mlContext</span><span class="p">.</span><span class="n">Data</span><span class="p">.</span><span class="n">LoadFromTextFile</span><span class="p">&lt;</span><span class="n">ImageNetData</span><span class="p">&gt;(</span><span class="n">path</span><span class="p">:</span> <span class="n">dataLocation</span><span class="p">,</span> <span class="n">hasHeader</span><span class="p">:</span> <span class="k">false</span><span class="p">);</span>
<span class="kt">var</span> <span class="n">model</span> <span class="p">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="nf">Fit</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
</code></pre></div></div>

<p>つづいて、できたモデルを評価します。</p>

<div class="code-frame" data-lang="csharp"><div class="highlight"><pre class="with-code"><code><span class="kt">var</span> <span class="n">classificationContext</span> <span class="p">=</span> <span class="n">mlContext</span><span class="p">.</span><span class="n">MulticlassClassification</span><span class="p">;</span>
<span class="nf">ConsoleWriteHeader</span><span class="p">(</span><span class="s">"Classification metrics"</span><span class="p">);</span>
<span class="kt">var</span> <span class="n">metrics</span> <span class="p">=</span> <span class="n">classificationContext</span><span class="p">.</span><span class="nf">Evaluate</span><span class="p">(</span><span class="n">trainData</span><span class="p">,</span> <span class="n">labelColumnName</span><span class="p">:</span> <span class="n">LabelTokey</span><span class="p">,</span> <span class="n">predictedLabelColumnName</span><span class="p">:</span> <span class="s">"PredictedLabel"</span><span class="p">);</span>
<span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">$"LogLoss is: </span><span class="p">{</span><span class="n">metrics</span><span class="p">.</span><span class="n">LogLoss</span><span class="p">}</span><span class="s">"</span><span class="p">);</span>
<span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">$"PerClassLogLoss is: </span><span class="p">{</span><span class="n">String</span><span class="p">.</span><span class="nf">Join</span><span class="p">(</span><span class="s">" , "</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">PerClassLogLoss</span><span class="p">.</span><span class="nf">Select</span><span class="p">(</span><span class="n">c</span> <span class="p">=&gt;</span> <span class="n">c</span><span class="p">.</span><span class="nf">ToString</span><span class="p">()))}</span><span class="s">"</span><span class="p">);</span>
</code></pre></div></div>

<p>モデルの保存も簡単です。</p>

<div class="code-frame" data-lang="csharp"><div class="highlight"><pre class="with-code"><code><span class="n">mlContext</span><span class="p">.</span><span class="n">Model</span><span class="p">.</span><span class="nf">Save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">trainData</span><span class="p">.</span><span class="n">Schema</span><span class="p">,</span> <span class="n">outputModelLocation</span><span class="p">);</span>
</code></pre></div></div>

<h3>
<span id="推論" class="fragment"></span><a href="#%E6%8E%A8%E8%AB%96"><i class="fa fa-link"></i></a>推論</h3>

<p>推論はモデルを読み込んで、画像ファイルを渡すだけです。作成したモデルにはラベル(クラス名)も含まれています。</p>

<div class="code-frame" data-lang="csharp"><div class="highlight"><pre class="with-code"><code><span class="c1">// モデル読み込み</span>
<span class="n">loadedModel</span> <span class="p">=</span> <span class="n">mlContext</span><span class="p">.</span><span class="n">Model</span><span class="p">.</span><span class="nf">Load</span><span class="p">(</span><span class="n">modelLocation</span><span class="p">,</span> <span class="k">out</span> <span class="kt">var</span> <span class="n">modelInputSchema</span><span class="p">);</span>
<span class="kt">var</span> <span class="n">predictor</span> <span class="p">=</span> <span class="n">loadedModel</span><span class="p">.</span><span class="n">MakePredictionFunction</span><span class="p">&lt;</span><span class="n">ImageNetData</span><span class="p">,</span> <span class="n">ImageNetPrediction</span><span class="p">&gt;(</span><span class="n">env</span><span class="p">);</span>

<span class="c1">// 画像読み込み</span>
<span class="kt">var</span> <span class="n">predictor</span> <span class="p">=</span> <span class="n">mlContext</span><span class="p">.</span><span class="n">Model</span><span class="p">.</span><span class="n">CreatePredictionEngine</span><span class="p">&lt;</span><span class="n">ImageNetData</span><span class="p">,</span> <span class="n">ImageNetPrediction</span><span class="p">&gt;(</span><span class="n">loadedModel</span><span class="p">);</span>
<span class="kt">var</span> <span class="n">testData</span> <span class="p">=</span> <span class="n">ImageNetData</span><span class="p">.</span><span class="nf">ReadImage</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">"---"</span><span class="p">);</span>

<span class="n">ImageNetPrediction</span> <span class="n">data</span> <span class="p">=</span> <span class="n">predictor</span><span class="p">.</span><span class="nf">Predict</span><span class="p">(</span><span class="n">testData</span><span class="p">);</span>
<span class="k">return</span> <span class="n">data</span><span class="p">.</span><span class="n">PredictedLabelValue</span> <span class="p">+</span> <span class="s">" "</span> <span class="p">+</span> <span class="n">data</span><span class="p">.</span><span class="n">Score</span><span class="p">.</span><span class="nf">Max</span><span class="p">();</span>
</code></pre></div></div>
</div></div></section><div class="css-1yzj1fm"><div class="css-1uv1qiv"><span class="fa fa-twitter"></span></div><div class="css-1uv1qiv"><span class="fa fa-facebook"></span></div></div><div class="apm-Content"><div class="apm-Content_title">Why not register and get more from Qiita?</div><ol class="apm-Content_list"><li>We will deliver articles that match you<div class="description">By following users and tags, you can catch up information on technical fields that you are interested in as a whole</div></li><li>you can read useful information later efficiently<div class="description">By &quot;stocking&quot; the articles you like, you can search right away</div></li><div><a class="apm-Content_help" href="https://help.qiita.com/ja/articles/qiita-login-user" target="_blank"><i class="fa fa-fw fa-arrow-circle-right"></i>What you can do with signing up</a></div></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2Fksasao%2Fitems%2F8a76d6048e28defeb39a&amp;realm=qiita" class="apm-Content_button apm-Content_button-signup">Sign up</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2Fksasao%2Fitems%2F8a76d6048e28defeb39a&amp;realm=qiita" class="apm-Content_button apm-Content_button-signin">Login</a></div></div><div class="css-helsa7"></div></div></div></div><div class="css-109dbrr"><div class="css-5jpx49"><div class="css-mnxgyc"><button class=" css-1vlpknv"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/ksasao/items/8a76d6048e28defeb39a/likers" class="css-1iupg5d">56</a></div><div class="css-fsjkhv"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-1b17vb0">43</span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-7i7f4d"><div class="css-1gj7nt">Improve article</div><a href="/drafts/8a76d6048e28defeb39a/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/ksasao/items/8a76d6048e28defeb39a/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/ksasao/items/8a76d6048e28defeb39a/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/ksasao/items/8a76d6048e28defeb39a/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/ksasao/items/8a76d6048e28defeb39a.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="PersonalArticlePage" data-dom-id="PersonalArticlePage-react-component-e2440b2c-bfa2-4688-ab80-5c03a82cfce5">{"authorAnalyticsTrackingId":null,"organizationAnalyticsTrackingId":null}</script>
      
<footer id="globalFooter" class="st-Footer"><div class="st-Footer_container"><div class="st-Footer_start"><div class="st-Footer_logo"><svg viewbox="0 0 426.57 130" xmlns="http://www.w3.org/2000/svg"><circle cx="167.08" cy="21.4" r="12.28" /><path d="M250.81 29.66h23.48v18.9h-23.48z" /><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z" /><circle cx="216.33" cy="21.4" r="12.28" /></svg></div><div class="st-Footer_catchcopy">How developers code is here.</div><div class="st-Footer_socials"><a class="fa fa-twitter" href="https://twitter.com/qiita"></a><a class="fa fa-facebook-square" href="https://www.facebook.com/qiita/"></a></div></div><div class="st-Footer_end"><div class="st-Footer_qiita"><div class="st-Footer_label">Qiita</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="/about">About</a><a href="/terms">Terms</a><a href="/privacy">Privacy</a><a target="_blank" href="http://help.qiita.com/ja/articles/qiita-community-guideline">Guideline</a><a target="_blank" href="https://help.qiita.com/ja/articles/others-brand-guideline">Design Guideline</a></div><div class="st-Footer_column"><a href="/release-notes">Release</a><a href="/api/v2/docs">API</a><a href="/feedback/new">ご意見</a><a href="https://help.qiita.com">Help</a><a target="_blank" href="https://qiita.com/ads?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Advertisement</a></div></div></div><div class="st-Footer_increments"><div class="st-Footer_label">Increments</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="https://increments.co.jp/company/">About</a><a href="https://increments.co.jp/jobs/">採用情報</a><a href="https://blog.qiita.com">Blog</a></div><div class="st-Footer_column"><a href="https://teams.qiita.com/">Qiita Team</a><a href="https://jobs.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Jobs</a><a href="https://zine.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Zine</a></div></div></div></div></div><div class="st-Footer_copyright">© 2011-2021 Increments Inc.</div></footer><div id="Snackbar-react-component-d6274a8c-2693-429b-80cd-018d445d6563"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="Snackbar" data-dom-id="Snackbar-react-component-d6274a8c-2693-429b-80cd-018d445d6563">{}</script>
      
<div id="LoginModal-react-component-05e740cb-25db-4492-af74-20d81d4cddec"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="LoginModal" data-dom-id="LoginModal-react-component-05e740cb-25db-4492-af74-20d81d4cddec">{}</script>
      
<div id="StockModal-react-component-3c80f788-0b6d-4dbb-9605-c01ce2af0219"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="StockModal" data-dom-id="StockModal-react-component-3c80f788-0b6d-4dbb-9605-c01ce2af0219">{}</script>
      
</div><div id="dataContainer" style="display: none;" data-config="{&quot;actionPath&quot;:&quot;public/items#show&quot;,&quot;settings&quot;:{&quot;analyticsTrackingId&quot;:&quot;UA-24675221-12&quot;,&quot;assetsMap&quot;:{},&quot;csrfToken&quot;:&quot;zMh8a+8Che68v7df/ItqFIrTtf2sgdaVyJNc/W4+6kfDz2bawStA43aN2eCeztNwtGEEyA7ARCKA3Z1APykECw==&quot;,&quot;locale&quot;:&quot;en&quot;},&quot;currentUser&quot;:null}" /></body></html><script type="application/json" data-js-react-on-rails-store="AppStoreWithReactOnRails">{"snackbar":{"type":"","body":"","isActive":false},"article":{"article":{"body":"\n\u003ch1\u003e\n\u003cspan id=\"tldr\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#tldr\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eTL;DR\u003c/h1\u003e\n\n\u003cp\u003eWindows, つよいGPUがない, インターネットに画像をアップできない, アドミン権限がないなどの環境でも動作する、転移学習を利用した画像認識アプリを .NET Framework (Windows Forms) で作成しました。\u003c/p\u003e\n\n\u003cp\u003eアプリケーションをダウンロードし、分類したい名前を付けたフォルダに数枚ずつ画像を用意するだけで短時間で簡単に学習ができます。Pythonなどをインストールする必要もありません。色々なものを分類して最近の画像認識の精度を体感してみてください。\u003c/p\u003e\n\n\u003cp\u003eアプリケーションは、Microsoft がオープンソースで開発を進めている\u003ca href=\"https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet\" rel=\"nofollow noopener\" target=\"_blank\"\u003eML.NET\u003c/a\u003e (ML.NET単体では Linux, Macなどでも動きます) を利用しています。実装されている TensorFlow API を利用して、学習済みの Inception モデルを読み込み、画像特徴を抽出し、\u003ca href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.sdcamulticlasstrainer?view=ml-dotnet\" rel=\"nofollow noopener\" target=\"_blank\"\u003eStochastic Dual Coordinate Ascent(SDCA)\u003c/a\u003e を利用した多クラス分類器用いて転移学習をします。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/ksasao/ImageClassification\" rel=\"nofollow noopener\" target=\"_blank\"\u003eソースコード\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/ksasao/ImageClassification/raw/master/app/ImageClassificationApp1.0.0.zip\" rel=\"nofollow noopener\" target=\"_blank\"\u003eアプリ (Windows 10/x64/4GB以上のメモリ/Core i 程度のCPU/.NET Framework 4.6.1以降で動作)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"アプリケーションの利用方法\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E5%88%A9%E7%94%A8%E6%96%B9%E6%B3%95\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eアプリケーションの利用方法\u003c/h1\u003e\n\n\u003col\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ksasao/ImageClassification/raw/master/app/ImageClassificationApp1.0.0.zip\" rel=\"nofollow noopener\" target=\"_blank\"\u003eアプリ\u003c/a\u003eをダウンロードして展開し、\u003ccode\u003eImageClassificationApp1.0.0\\ImageClassificationApp.exe\u003c/code\u003e を起動します。\u003c/li\u003e\n\u003cli\u003e画像を学習するには、[学習する] のボタンをクリックし、開いたダイアログから画像を分類済みのフォルダ(下図の場合は SampleImages フォルダ)を選択してOKをクリックします。\n\u003ca href=\"https://camo.qiitausercontent.com/325f975f158a6c3f853e4e943fec87da43561d47/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f64333137633932612d343563642d633133372d323566662d3663366361626131313034642e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fd317c92a-45cd-c137-25ff-6c6caba1104d.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=aa23bc81f65fd6cb6d88a87a6d3b9a46\" alt=\"image\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/43450/d317c92a-45cd-c137-25ff-6c6caba1104d.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fd317c92a-45cd-c137-25ff-6c6caba1104d.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=997d32e7cb5ddf722c9613d371f0919b 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e10秒から1分程度で学習が完了します。\u003ca href=\"https://camo.qiitausercontent.com/13d1b2d7574456c9f145c28b2e0c9c123644a579/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f39653463653936652d396330312d613263362d636535302d3033336261653736363038372e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F9e4ce96e-9c01-a2c6-ce50-033bae766087.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=ec841e1842721f487cd36ee9395cd50f\" alt=\"image\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/43450/9e4ce96e-9c01-a2c6-ce50-033bae766087.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F9e4ce96e-9c01-a2c6-ce50-033bae766087.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=498c1ad8b0d59d098b2551654d9b1aa6 1x\" loading=\"lazy\"\u003e\u003c/a\u003e下図のように表示されたら画像を Drag \u0026amp; Drop すると認識結果と確信度(0～1, 1が最も高い)が表示されます。 \u003ca href=\"https://camo.qiitausercontent.com/a27f5234fd820d97b91beaae783e24a6e3f38c74/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f33376636343033332d623963322d343735352d643864302d3735636435633364303736612e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F37f64033-b9c2-4755-d8d0-75cd5c3d076a.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=952331e132c80c763eb2ccfb8ac6a479\" alt=\"image\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/43450/37f64033-b9c2-4755-d8d0-75cd5c3d076a.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F37f64033-b9c2-4755-d8d0-75cd5c3d076a.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=246c2008c823d6e48d4ec9eb0bb2f966 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eあらかじめ学習したモデルを利用することも可能です。先ほど画像を学習したフォルダに\u003ccode\u003eimageClassifier.zip\u003c/code\u003eというファイルが生成されていますので、それを読み込んでみてください。学習済みモデルのファイル名は適宜変更可能です。また学習に利用した画像も不要です。\u003ca href=\"https://camo.qiitausercontent.com/8a6699355129fdd331b15dca169961224590f030/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f38653336376463382d333332322d623032662d393765352d3665373737663739336634362e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F8e367dc8-3322-b02f-97e5-6e777f793f46.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=42312efa9cdd20e3131d60e106e7a688\" alt=\"image\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/43450/8e367dc8-3322-b02f-97e5-6e777f793f46.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F8e367dc8-3322-b02f-97e5-6e777f793f46.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=f1acbc94d9d6fa89f5fd80b4f194c6eb 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch1\u003e\n\u003cspan id=\"net-開発者向けの解説\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#net-%E9%96%8B%E7%99%BA%E8%80%85%E5%90%91%E3%81%91%E3%81%AE%E8%A7%A3%E8%AA%AC\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e.NET 開発者向けの解説\u003c/h1\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"mlnet-とは\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#mlnet-%E3%81%A8%E3%81%AF\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eML.NET とは\u003c/h2\u003e\n\n\u003cp\u003e\u003ca href=\"https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet\" rel=\"nofollow noopener\" target=\"_blank\"\u003eML.NET\u003c/a\u003e は Microsoft がオープンソースで進めている .NET 開発者向け機械学習フレームワークです(\u003ca href=\"https://github.com/dotnet/machinelearning\" rel=\"nofollow noopener\" target=\"_blank\"\u003eGitHub\u003c/a\u003e)。クロスプラットフォームで開発されており、Windows, Linux,  macOS で動作します。Windows Hello, Bing Ads PowerPoint デザインアイディアなどでも使われています。\u003cbr\u003e\n類似のものとして、\u003ca href=\"https://docs.microsoft.com/en-us/windows/ai/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eWindows Machine Learning\u003c/a\u003e がありますが、こちらは Windows 10 以降の OS に特化したものとなります。API等に互換性はありません。\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"net-core-版-mlnet-を-windows-forms-から利用する\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#net-core-%E7%89%88-mlnet-%E3%82%92-windows-forms-%E3%81%8B%E3%82%89%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e.NET Core 版 ML.NET を Windows Forms から利用する\u003c/h2\u003e\n\n\u003cp\u003eML.NET はクロスプラットフォームを実現するため .NET Core で作成されています。.NET Core で作成した DLL は、.NET Framework で作成しているアプリケーションからは直接参照することはできませんが、.NET Standard ライブラリを作成し、その中で .NET Core を利用するコードを記述すれば、.NET Framework から参照できるようになります。\u003cdel\u003e今回は ML.NET 0.7.0 (.NET Core 2.0) を利用しているため、.NET Standard 2.0 / .NET Framework 4.6.1 以降が必要です。また、依存しているネイティブライブラリが x64 を対象としているため 64bit環境でのみ動作します。\u003cbr\u003e\nなお、 2018年12月時点の最新版である ML.NET 0.8.0 は、.NET Core 2.1 ベースとなっており、.NET Framework から利用するためには、.NET Standard 2.1 が必要となりますが \u003ca href=\"https://github.com/dotnet/standard/milestone/3\" rel=\"nofollow noopener\" target=\"_blank\"\u003e未リリース\u003c/a\u003eです。\u003c/del\u003e2019年5月時点の ML.NET 1.0 では .NET Core 2.1 ベースになっていますが、この記事の範囲内では .NET Core 2.0 でコンパイルしても動作するため、.NET Standard 2.0 でビルドしています。ビルドには .NET Framework 4.6.1 以降が必要です。また、依存しているネイティブライブラリが x64 を対象としているため 64bit環境でのみ動作します。\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e.NET Standard 2.0 のクラスライブラリのプロジェクトを作成し、nuget を利用して、必要なライブラリ(今回は、Microsoft.ML 1.0.0, Microsoft.ML.ImageAnalytics 1.0.0, Microsoft.ML.TensorFlow 0.12.0)を追加する\n\u003ca href=\"https://camo.qiitausercontent.com/b795f32db41475fd31e411c615630896da425d0b/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f61623964383236612d346436622d636137392d613965642d3064313338333634396538312e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fab9d826a-4d6b-ca79-a9ed-0d1383649e81.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=411f4b5714755ec99c1b53e76c2f5c2f\" alt=\"image\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/43450/ab9d826a-4d6b-ca79-a9ed-0d1383649e81.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2Fab9d826a-4d6b-ca79-a9ed-0d1383649e81.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=403eebb6361a98a0d9c5b1f358cfa89f 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\n\u003ca href=\"https://camo.qiitausercontent.com/96f8da9c95e759f50d038199c4296a8bc658b878/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f34333435302f30323138316137372d363631652d336665332d623432352d3666376238396466383135382e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F43450%2F02181a77-661e-3fe3-b425-6f7b89df8158.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=8be91c6fd42bdd254a8b3c7baf7b18a3\" alt=\"image.png\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43450/02181a77-661e-3fe3-b425-6f7b89df8158.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F43450%2F02181a77-661e-3fe3-b425-6f7b89df8158.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=b2b4ad99548e037599c633273515877d 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e1.のプロジェクトを .NET Framework のプロジェクトから参照する\u003c/li\u003e\n\u003cli\u003e.NET Framework のプロジェクトの .csproj を開き、\u003ccode\u003e\u0026lt;RestoreProjectStyle\u0026gt;PackageReference\u0026lt;/RestoreProjectStyle\u0026gt;\u003c/code\u003e を最初の \u003ccode\u003e\u0026lt;PropertyGroup\u0026gt;\u003c/code\u003e 内の先頭に追加する\n\u003ca href=\"https://camo.qiitausercontent.com/69aa5e7c6e212dd54b2f9404531a4b2b4c28efe6/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f34333435302f35636233633765392d313733652d313631322d333537652d6530363763363831323136352e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F5cb3c7e9-173e-1612-357e-e067c6812165.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=7096022f3bde90d08b90477938dbe0c8\" alt=\"image\" data-canonical-src=\"https://qiita-image-store.s3.amazonaws.com/0/43450/5cb3c7e9-173e-1612-357e-e067c6812165.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F43450%2F5cb3c7e9-173e-1612-357e-e067c6812165.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=e2e4d03dea2c9dabe7e92371fd8282d7 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003ex64でビルドする\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e下記のようなメッセージが出てデバッグ実行に失敗する場合は、10秒くらい待ってもう一度実行してください。\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eThe OutputPath property is not set for project 'CoreReferenceForm.csproj'.  Please check to make sure that you have specified a valid combination of Configuration and Platform for this project.  Configuration='Debug'  Platform='x64'.  This error may also appear if some other project is trying to follow a project-to-project reference to this project, this project has been unloaded or is not included in the solution, and the referencing project does not build using the same or an equivalent Configuration or Platform.  CoreReferenceForm           \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"net-framework-版-mlnet\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#net-framework-%E7%89%88-mlnet\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e.NET Framework 版 ML.NET\u003c/h3\u003e\n\n\u003cp\u003eWindows プラットフォーム限定となりますが、ML.NET の .NET Framework 版も提供されています。.NET Framework プロジェクトから、上記と同様に利用することが可能です。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"参考\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e参考\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.buildinsider.net/language/dotnetcore/05\" rel=\"nofollow noopener\" target=\"_blank\"\u003e.NET Standardなライブラリプロジェクトを作成して参照する\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.hanselman.com/blog/ReferencingNETStandardAssembliesFromBothNETCoreAndNETFramework.aspx\" rel=\"nofollow noopener\" target=\"_blank\"\u003eReferencing .NET Standard Assemblies from both .NET Core and .NET Framework\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"実装について\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E8%A3%85%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実装について\u003c/h2\u003e\n\n\u003cp\u003eML.NETのサンプルにある \u003ca href=\"https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_TensorFlowEstimator\" rel=\"nofollow noopener\" target=\"_blank\"\u003eImage Classification\u003c/a\u003e をベースにしています。以下は説明のため部分的に抜粋しています。詳しくは \u003ca href=\"https://github.com/ksasao/ImageClassification\" rel=\"nofollow noopener\" target=\"_blank\"\u003eソースコード\u003c/a\u003eを参照してください。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"学習\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AD%A6%E7%BF%92\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e学習\u003c/h3\u003e\n\n\u003cp\u003eML.NET では下記のようにパイプラインを構成していきます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"csharp\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003epipeline\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTransforms\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eConversion\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eMapValueToKey\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutputColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eLabelTokey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einputColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"Label\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAppend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTransforms\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eLoadImages\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutputColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"input\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eimageFolder\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eimagesFolder\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einputColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003enameof\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eImageNetData\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eImagePath\u003c/span\u003e\u003cspan class=\"p\"\u003e)))\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAppend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTransforms\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eResizeImages\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutputColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"input\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eimageWidth\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eImageNetSettings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eimageWidth\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eimageHeight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eImageNetSettings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eimageHeight\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einputColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"input\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAppend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTransforms\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eExtractPixels\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutputColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"input\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einterleavePixelColors\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eImageNetSettings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echannelsLast\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eoffsetImage\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eImageNetSettings\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emean\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAppend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eLoadTensorFlowModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efeaturizerModelLocation\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\n                     \u003cspan class=\"nf\"\u003eScoreTensorFlowModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutputColumnNames\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"s\"\u003e\"softmax2_pre_activation\"\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e \u003cspan class=\"n\"\u003einputColumnNames\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"p\"\u003e[]\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"s\"\u003e\"input\"\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e \u003cspan class=\"n\"\u003eaddBatchDimensionInput\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAppend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMulticlassClassification\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTrainers\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eLbfgsMaximumEntropy\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elabelColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eLabelTokey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003efeatureColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"softmax2_pre_activation\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAppend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTransforms\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eConversion\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eMapKeyToValue\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ePredictedLabelValue\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"PredictedLabel\"\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAppendCacheCheckpoint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e上記のコードでは\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e画像ファイルとその画像のラベル(クラス名; 日本語 (UTF-8) が利用可能)が記載された.tsvファイル読み込み\u003c/li\u003e\n\u003cli\u003e画像のリサイズ\u003c/li\u003e\n\u003cli\u003eTensorflowモデルの読み込みと特徴抽出に利用する層(softmax2_pre_activation)の指定\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.sdcamulticlasstrainer?view=ml-dotnet\" rel=\"nofollow noopener\" target=\"_blank\"\u003eStochastic Dual Coordinate Ascent(SDCA)\u003c/a\u003e を利用した画像特徴の多クラス分類\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eといったような各処理をつないでいます。パイプラインの構成は、画像に限らず、自然言語処理や数値(CSVファイル)データの学習でも同様です。詳しくは、ML.NETの\u003ca href=\"https://dotnet.microsoft.com/learn/machinelearning-ai/ml-dotnet-get-started-tutorial\" rel=\"nofollow noopener\" target=\"_blank\"\u003eチュートリアル\u003c/a\u003eや\u003ca href=\"https://github.com/dotnet/machinelearning-samples\" rel=\"nofollow noopener\" target=\"_blank\"\u003eサンプルコード\u003c/a\u003eを参照してください。\u003c/p\u003e\n\n\u003cp\u003eパイプラインができたら、そこに学習データを渡して学習を行います。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"csharp\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eData\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eLoadFromTextFile\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eImageNetData\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;(\u003c/span\u003e\u003cspan class=\"n\"\u003epath\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003edataLocation\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehasHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"k\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epipeline\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eFit\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eつづいて、できたモデルを評価します。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"csharp\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003eclassificationContext\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMulticlassClassification\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"nf\"\u003eConsoleWriteHeader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Classification metrics\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003emetrics\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eclassificationContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eEvaluate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etrainData\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elabelColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eLabelTokey\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003epredictedLabelColumnName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s\"\u003e\"PredictedLabel\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e$\"LogLoss is: \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003emetrics\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eLogLoss\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"n\"\u003eConsole\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eWriteLine\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e$\"PerClassLogLoss is: \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eJoin\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\" , \"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003emetrics\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ePerClassLogLoss\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eSelect\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eToString\u003c/span\u003e\u003cspan class=\"p\"\u003e()))}\u003c/span\u003e\u003cspan class=\"s\"\u003e\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eモデルの保存も簡単です。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"csharp\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eSave\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etrainData\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSchema\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eoutputModelLocation\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"推論\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E6%8E%A8%E8%AB%96\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e推論\u003c/h3\u003e\n\n\u003cp\u003e推論はモデルを読み込んで、画像ファイルを渡すだけです。作成したモデルにはラベル(クラス名)も含まれています。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"csharp\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e// モデル読み込み\u003c/span\u003e\n\u003cspan class=\"n\"\u003eloadedModel\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eLoad\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003emodelLocation\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"k\"\u003eout\u003c/span\u003e \u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003emodelInputSchema\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003epredictor\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eloadedModel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eMakePredictionFunction\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eImageNetData\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eImageNetPrediction\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;(\u003c/span\u003e\u003cspan class=\"n\"\u003eenv\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// 画像読み込み\u003c/span\u003e\n\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003epredictor\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003emlContext\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eModel\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eCreatePredictionEngine\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"n\"\u003eImageNetData\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eImageNetPrediction\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;(\u003c/span\u003e\u003cspan class=\"n\"\u003eloadedModel\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003etestData\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eImageNetData\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eReadImage\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efilename\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\"---\"\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eImageNetPrediction\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epredictor\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ePredict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etestData\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ePredictedLabelValue\u003c/span\u003e \u003cspan class=\"p\"\u003e+\u003c/span\u003e \u003cspan class=\"s\"\u003e\" \"\u003c/span\u003e \u003cspan class=\"p\"\u003e+\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eScore\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eMax\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n","createdAt":"2018-12-09T10:29:06Z","elapsedYearsFromLastModifiedAt":2,"encryptedId":"lFB2qezUvNvkFK3WoiyQMGGJyQdqRDNY--jjW4pwQ8WS0VjxGj--XhaBczhxZWvptwo/pMByHQ==","isBanned":false,"isDeprecated":true,"isDestroyableByViewer":false,"isEditRequestReadableByViewer":true,"isEditRequestSendableByViewer":true,"isLikableByViewer":true,"isLikedByViewer":false,"isPublic":true,"isSlide":false,"isStockableByViewer":true,"isStockedByViewer":false,"isSubscribableByViewer":false,"isSubscribedByViewer":false,"isUpdatableByViewer":false,"isUpdated":true,"lastModifiedAt":"2019-05-26T07:51:58Z","likesCount":56,"linkUrl":"https://qiita.com/ksasao/items/8a76d6048e28defeb39a","organization":null,"originalId":736560,"stockedCount":43,"title":"Windows PCかつオフライン環境でお気軽に画像認識する ML.NET 1.0 対応版","toc":"\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#tldr\"\u003eTL;DR\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E5%88%A9%E7%94%A8%E6%96%B9%E6%B3%95\"\u003eアプリケーションの利用方法\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#net-%E9%96%8B%E7%99%BA%E8%80%85%E5%90%91%E3%81%91%E3%81%AE%E8%A7%A3%E8%AA%AC\"\u003e.NET 開発者向けの解説\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#mlnet-%E3%81%A8%E3%81%AF\"\u003eML.NET とは\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#net-core-%E7%89%88-mlnet-%E3%82%92-windows-forms-%E3%81%8B%E3%82%89%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B\"\u003e.NET Core 版 ML.NET を Windows Forms から利用する\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#net-framework-%E7%89%88-mlnet\"\u003e.NET Framework 版 ML.NET\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e参考\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E8%A3%85%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6\"\u003e実装について\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AD%A6%E7%BF%92\"\u003e学習\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E6%8E%A8%E8%AB%96\"\u003e推論\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","totalPv":8784,"uuid":"8a76d6048e28defeb39a","banReason":null,"adventCalendarItem":{"day":10,"calendar":{"name":"NSSOL","urlName":"nssol","year":2018,"organization":{"logoUrl":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/c7162dfc415b13511f9913252f443b7afd69f1d5/original.jpg?1540194581","urlName":"nssol"}}},"author":{"encryptedId":"A46WbDYb28N5UURgyn1wERqzxPg=--bfVtYqiNAbr8UnuR--TjaPXzQjkHVBalrJaIuqtA==","originalId":43450,"description":"","facebookUrl":null,"githubUrl":"https://github.com/ksasao","isBlockingViewer":false,"isFollowableByViewer":true,"isFollowedByViewer":false,"isTweetWebNotificationReceivable":true,"linkedinUrl":null,"name":"Kazuhiro Sasao","profileImageUrl":"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43450/profile-images/1580891297","profileImageUrlW48":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F43450%2Fprofile-images%2F1580891297?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=a316ac28eb9588c1df09166b7d408251","profileImageUrlW75":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F43450%2Fprofile-images%2F1580891297?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=e8e680f6114900fe05b3daf56987880e","urlName":"ksasao","websiteUrl":"","twitterUrl":"https://twitter.com/ksasao","twitterUrlName":"ksasao","revealedOrganizations":{"edges":[{"node":{"encryptedId":"CMM+DtLI8ulOC3Z8zovg13WwAhCFN80vaBM=--/SJA1INsIoQ6VjHD--qpp2JNi8mtGOzW+f3Lk88Q==","isBetaReleaseEnabled":false,"isFollowableByViewer":false,"isFollowedByViewer":false,"name":"日鉄ソリューションズ株式会社","logoUrl":"https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/c7162dfc415b13511f9913252f443b7afd69f1d5/original.jpg?1540194581","urlName":"nssol","description":"お堅いと評判のユーザ系SIerです。※各記事の内容は個人の見解であり、所属する組織の公式見解ではありません。","url":"https://www.nssol.nipponsteel.com"}}]}},"tags":[{"name":"Windows","urlName":"windows"},{"name":"C#","urlName":"csharp"},{"name":"機械学習","urlName":"%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92"},{"name":"転移学習","urlName":"%e8%bb%a2%e7%a7%bb%e5%ad%a6%e7%bf%92"},{"name":"ML.NET","urlName":"ml.net"}],"followingLikers":{"edges":[]},"comments":{"totalCount":3}},"comments":[],"client":null,"ads_event_emitter":null}}</script>
