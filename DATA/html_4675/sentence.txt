More than 1 year has passed since last update.マイクロソフトがWindows10でのONNXをサポートを公式に宣言したのが2018年3月。
多くの人々が苦労しているであろう深層学習の実装について現実的な手段の一つとして期待できるのではないでしょうか？今回はONNXのサポートの具合がどんなもんかを勉強を兼ねて確かめてみました。「RaspberryPi3 Model B+ にて WEBカメラの画像 で推論する」ところまでを目標にします。
（ユニバーサルWindowsアプリで作成するので一般のWindows10でも普通に動作します。）まずはパソコン側を整えます。MSのサイトからダウンロードですね。Insider Preview版を使用するので安全のために仮想環境などでやるのが良いと思います。
ちなみに私は面倒だったので無謀にもメイン環境を更新してしまいましたが。まぁ何とかなる。以下の環境で開発します。これもInsider Preview版を使用します。リンク先の中段くらいに以下の記述があると思うので、そこからファイルをダウンロード
（これ以外のビルドはRaspberryPi3B+に焼いても起動しない）Additional Insider Preview downloads
　RaspberryPi 3B+ Technical Preview Build 17661ダウンロードしたファイルを実行すると、
インストーラーが少々不親切ですが以下のフォルダにイメージファイル(FFUファイル)が出力されます。
C:\Program Files (x86)\Microsoft IoT\FFU\RaspberryPi2FFUファイルを「Windows10 IoT Core Dashboard」でSDカードに焼けばOKです。
Windows10 IoT Core Dashboardがない人はここから落とすSDカードを刺して起動するとネットワーク経由のOSアップデートが始まるので完了まで放置します。自分で作っても良いし、落としてきても良い
https://github.com/onnx/models
今回は「mobilenet v2」を使用します。適当に準備すればいいのだが、どうもモデルサイズが大きいとエラー吐いて読めないので、mobilenetとか小さいモデルが推奨。ちなみにalexnetはラズパイNG、ローカルPCはOKだった。関係無いけど、ONNXって「オニキス」っていうんですね。少し前まで知らなかった。上記のgithubページから飛ぶことができます。
リンクも貼っておきます。
https://github.com/onnx/models/blob/master/models/image_classification/synset.txt
こっちも良いかも
https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3aWindows10 IoT Core用のアプリケーションはユニバーサルWindowsアプリケーション(UWP)として作成します。
ソリューション全体はgithubを参照ください(Github)Visual C# → Windowsユニバーサル → 空白のアプリ(ユニバーサルWindows)　を選択します。
ターゲットバージョンと最小バージョンは、今回は「Build 17738」をターゲットにします。
コマンドプロンプトを起動します。
先ほどダウンロードしたモデルファイルがあるディレクトリに移動し、以下のコマンドでモデルのラッパークラスを生成します。必要に応じてファイル名を変えてください。すると「MobileNetv2-1.0.cs」が生成されます。
中身は以下のような感じになります。(2018.10.11追記)
 Windows10 ver1809リリースに伴い、最新のmlgen.exeは以下のフォルダにあります。
「C:\Program Files (x86)\Windows Kits\10\bin\10.0.17763.0\x64\mlgen.exe」モデルの入力クラス、出力クラス、モデル本体クラスの３つが生成されました。&lt;余談&gt;
WindowsMLはWindows10 version 1803から実装されていますが、どうも現在は仕様変更が入っているようです。1803ではTensorFloat型は未実装です。もうすぐリリースのversion 1809以降はTensorFloat型が基本になるんじゃないでしょうか。
&lt;余談終わり&gt;次に、プロジェクトへモデルを追加します。
モデルファイルをAssetsフォルダへ、ラッパークラスはプロジェクトのルートに置いておきます。

こんな感じ
この時、モデルファイルのプロパティを以下のように変更しておきます。粛々とコーディングします。
3分クッキングのように軽くペタッと貼っていますが、うまくいかなくて苦労しました。
この記事を参考にさせていただきました。3分で分かる！ONNXフォーマットとWindows Machine Learning！大事そうなところや苦労したポイントだけピックアップして書きます。
コード全体はgithubを参照ください(Github)作成したラッパークラスの中身を確認し、そのクラス名のインスタンスを作成します。
今回は「Model」というクラスが生成されているので、以下のコードになります。モデルを読み込むタイミングとしては、UIロード完了イベントなどが良いと思います。今回は、スレッドタイマを使用してUIとは別スレッドでWEBカメラから画像を読み込み推論していきます。スレッドタイマやWEBカメラの詳細な使い方は他の方の作例を参照ください。
ここでは呼び出しだけ記述しておきます。
まずWEBカメラから画像を取得する処理です。書き出しはこんな感じ。このスコープの中に処理を実装していきます。※ちなみに、WebカメラにロジクールC270を使うと怪しい動作をする。大人しく違うWebカメラを使うのが良い。海外でも同じ報告が上がっていたのでどうもUWPのライブラリの問題の気がする。
（ローカルx86/x64環境で実行すると例外を吐いてフレームが取得できない、リモートARM環境は映像がちらつくが一応動く）VideoFrameクラスのままでは使えないのでデータ変換をしていきます。
まずはリサイズしつつSoftwareBitmapオブジェクトに変換します次に、WriteableBitmapに変換し、さらにバイト配列に変換します。ここで、わざわざラムダ式で実行しているのは、UIと別スレッド(ex.スレッドタイマなど)で実行することを前提にしているためです。もう一息です。
1次元配列にできましたが、現在のデータには問題があります。これを力業で直します。OpenCV使ったりするのも良いかもしれません。
ただ、処理がそこまで遅いかというと遅くないので力業も悪くないと思います。※mobilenet向けの正規化処理、平均値を0にしたり標準偏差で割る必要があるかどうか分からないです。
とりあえず、上記の処理で何となく結果が出るので、ここでは上記の処理だけにしておきます。今までつらつらコードを書きましたが、肝心の推論はたったの数行で終わります。上記のInput型とOutput型は、モデルファイルのラッパークラスに含まれているモノです。
したがって使用するモデルに応じて名称が変わります。今回のコードはUIとは別スレッドで実行することを前提にしているのでDispatcher.RunAsyncを使います。結果表示用の「Text_Result_1st」という名前のTextBlockに結果を代入して完了です。
また「classList」のインスタンスは自作の「IDとクラス名のリスト」のクラスです。最後は以下の手順で完了です。以上で、電源投入すると自動でソフトが立ち上がり、延々と推論を繰り返すデバイスができあがります。
起動完了まで3分半くらい？です。遅いわけでは無いですが微妙です。UWPアプリに関する情報が少なくて以外と苦労しました。
作ってみて改めて感じるのは、Windows10でONNXモデルが扱えるのは大きいです。
ディープラーニング実装のハードルが劇的に下がる気がします。
特に組込機器ではWindows 10 IoT Core/Enterpriseが走ると思うので、C#でソフト作って動作させられます。
現状、ONNXモデルのサポート範囲は広くないかもしれませんが、それでも強力です。来年は産業界への深層学習の展開が加速しそうです。
2019年頭にはLATTEPANDA ALPHAが日本でも発売するので盛り上がりそうな気がします。
あとは、NVIDIA JetsonにWindows10 IoTが対応してくれるとすごく助かるのですが・・・。そんな日がくるだろうか？以下の記事を参考にさせていただきました。ありがとうございます。ONNXモデルを作るにあたり、便利なツールであるMMdnnの簡単な解説を書きました。(2018.09.04)
https://qiita.com/koppe/items/7f85f5411539390c4499
kerasモデルをONNXに変換できました。ONNXの可能性を感じますね。


