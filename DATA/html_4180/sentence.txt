AR FoundationをRuntime NavMeshと組み合せた例をなかなか見つけることができず、自分でやってみると少し引っかかる点があったため共有します。なお、今回のプロジェクトはMITライセンスで公開しています。
https://github.com/Machikof/ARNavMeshSampleAR Foudationで検知した平面をタップすると、その上にオブジェクト（エージェント）が生成され、自分（端末）を追いかけるようになります。
追いかける先は自分でなくともいいので、ARコンテンツを開発する上でかなり応用の効く技術だと思います。下の記事を参考にしながら構築していきます。画像のように、シーン上にAR SessionとAR Default PlaneとAR Session Origin、そしてその子にAR Cameraを追加します。

AR Session OriginにAR Plane ManagerとAR Raycast Managerを追加し、AR Plane ManagerのDetection ModeをHorizontalにします。UnityTechnologiesから提供されているNavMeshComponentsを入れます。プロジェクトを落としたら、NavMeshComponents-master/Assetsの中のGizmosとNavMeshComponentsをコピーし、自分のプロジェクトのAssets直下に置きます。シーン上に「NavMeshSurface」というオブジェクトを設置し、同名のコンポーネントを追加します。
インスペクタの値はそのままで構いません。
次に、実行中にNavMeshをベイクするスクリプトを用意します。今回は簡単のためにコルーチンを使いましたが、負荷が気になる場合はベイクを一度きりにした方がいいでしょう。
このスクリプトをNavMeshSurfeceにアタッチし、bakeUpdateTimeには3や５など適当な値を入れます。いよいよ端末を追いかけるエージェントを作っていきます。
以下がエージェント側のスクリプトです。targetPosにはXZ平面上に射影したカメラ位置を入れ、ApproachToCamera()で目的地に設定します。今回はCapsuleを使いますが、任意のキャラクターアセットを使っても問題ありません。
卓上で動かすことを想定しているので、Scaleは0.1倍です。
NavMeshAgentと上のスクリプトを追加し、インスペクタのARカメラにはシーン上のAR Cameraをアタッチします。
ここで、動かす環境（机の上など）によってはNavMeshの精度が足りない場合があります（自分はここで引っかかりました）。
その場合、以下のようにRadiusを小さくするといいでしょう。あとは画面をタップした位置にエージェントを生成するスクリプトを書きます。
ググればすぐに出てきますが、こちらも一応載せておきます。ARFoundation Remoteでのデバッグを円滑にするため、エディタと端末で処理を分けています。
書き方はステップアップUnityのモバイルARの章を参考にしています。ARは特に動作確認のためにビルドする手間がかかるため、こうした一手間で作業がグッと楽になります。ステップアップUnity
https://www.amazon.co.jp/dp/B08W8L2LGJ/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1


