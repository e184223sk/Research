More than 3 years have passed since last update.MRDesignLabsのライブラリ自体はFluent Design Systemの要素を取り入れられたライブラリ群で、それらのサンプルとして追加されたものがゲームとしても楽しいLunaModuleがあります。
このゲームは両手でジェスチャー操作ができます。今回はLunaModuleで実現しているジェスチャー部分を抜き出したサンプルを作成しました。LunaModuleをデプロイして遊びたい方はこちらを参考にしてください。LunarModuleで追加されている機能は３つあります。このうち今回はジェスチャーに関するLocalHandInputの説明と使い方を紹介します。Local Hnad InputはMRDesignLabsのハンドジェスチャーの機能を利用してTap&amp;Holdの移動量を検出するコンポーネントです。Tap地点を起点に指の移動量や速度の取得ができます。プロパティは以下のものを持っています。両手ジェスチャを実現するためにはMRDesignLabsのいくつかの機能を使う必要があります。HoloLensの操作で使うジェスチャーはMRDesignLabsのInputSourceHandsを使うと取得可能です。
LocalHandInputの前に少しInputSourceHandsの両手検出の仕組みについて説明します。Hierarchy上は「InputMapping」-「InputSource」-「Hands」のコンポーネントで定義されています。開発者がジェスチャー操作についての情報を取得するためには以下のようにInputSourceクラスから取得します。考え方は非常にシンプルです。顔位置（＝カメラ）を中心に手は左右にあるでしょうということを利用しています。
つまり「顔よりも右側のジェスチャーは右手操作」、「顔よりも左側のジェスチャーは左手操作」として検出します。
MrDesignlLabsのInput Suorce Handsはこの考え方をもとにして両手ジェスチャーの検出を可能にしています。
次に実際の判別方法ですが、下図のようにカメラの正面方向のベクトルと手の方向ベクトルからそれらの法線を計算しカメラの上方向のベクトルとの内積（距離）を計算します。この数値がLocalHandInputコンポーネントにもあった「Min Confidence」プロパティに関係します。図の場合、顔の位置から見て右側に0.2mの位置でジェスチャーを検出している状態です。この時のConfidenceの値を計算すると0.2になります。よってLocalHandInputでは右手は検出できている状態になります。例えば、右側0.1mのまで手を近づけるとConfidenceは0.1になるので、「Min Confidence」を下回ります。この場合、右手としては検出されない状態になります。
左手の場合も考え方は一緒です。上から見た図。真ん中が顔、球体が手を模式化。Z軸の緑色の線は顔の正面方向のベクトル(Forward)。赤線は手の方向を指すベクトル(Right Hand)で黄線が(1)-(2)の平面に対する法線ベクトル(Cross)を指します。次に両手ジェスチャーのサンプルコードの実装を行ってみたいと思います。サンプルでは右手、左手のホールド操作でcubeを動かすサンプルを作ります。
まずは、HoloLensで試すMRDesignLabs - 空セットアップとBounding Boxの利用を参考にMRDesignLabsのAsset設定までを完了してください。MRDesignLabsのアセットを設定後、シーンを作成します。サンプルはLocalHnadInput.unityで作成しました。
デフォルトのカメラの代わりにMRDesignLabsアセットのHoloLens.Prefabを配置します。次に空のGameObjectを設定し名前を変更します（サンプルではrootに設定）。次にFitBoxhierarchyに追加します。最後にFitboxコンポーネントのStartup Objectに先ほど作った空のGameObjectを追加します。次に右手、左手の操作で操作するcubeをRootの下に作成します。
次にそれぞれのcubeにLocalHandInputコンポーネントを追加します。LocalHandInput自体はHierarchyのどこのオブジェクトに設置していても動作します。今回はわかりやすく操作するコンポーネントに対して割り当てています。プロパティ等の設定は上記に記載しています。ここでは変更が必要な個所についてのみ記載します。変更箇所は以下の３つです。左右別々に検出するので「Handedness」を「Right(左手用にはLeft)」、「Min Confidence」は「0.1」、「Input Scale」を「7」としました。
これで、顔中心から0.1m以上右のセンサー認識範囲が右手操作として認識される範囲です。最後にジェスチャーでCubeを動かすロジックを実装します。
Projectの任意の場所にC# Scriptを作成してください。今回は「HoloMultiHandInputSamples\Scripts\ManipilateCubde」として作成しました。
作成したらVisual Studioでロジックを実装します。
実装コードは以下の通りです。
LocalHandInputからホールド中の座標を取得する場合は、LocalPositionプロパティを用います。今回はこの値をcubeに渡して操作しています。また、センサーがそれぞれの手を検出している場合はcubeを青に、センサーからロストしている場合は赤色になるように実装しています。まずは両方のCubeが青い状態からホールドして操作をしてみてください。最後に、作成したManupilateCubeを先ほど作った左右のCubeに追加してHoloLens用のビルド設定でビルドを実施し実機へデプロイすれば完了です。起動するとMRDesignLabsのロゴ表示がされますのでタップをするとcubeが２個表示されます。あとは色々操作して両手ジェスチャーの感覚をつかんてみてください。この機能は記述時点ではLunarModuleに同梱されているMRDesignLabsの機能となっています。よって使うためには https://github.com/Microsoft/MRDesignLabs_Unity_LunarModuleからとるようにしてください。便利そうなのでそのうちMRDesignLabsに入ってほしいなとおもいつつ。
次回はLunarModuleのチュートリアルで使用されている「Hand Coach」の解説をしたいと思います。


