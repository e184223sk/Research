Azure Cognitive Services の Text Analytics API を利用した NLP アプリがありまして、どうも期待通りに使えず、何が原因かと探る一環として、自分でも同 API を試してみることにしました。こんな引数で成功して、こんな引数で失敗して、エラーは何で、みたいなことをざっと見渡したいと考えました。すると。１画面に収まる記述量で同 API を使えてしまいましたとさ。すごい。せっかくなのでメモを残します。Text Analytics API の Detect Language を試しました。同 API は REST API です。公式ドキュメントでは HTTP Request / Response について説明されており、サンプルも curl ワンライナーや System.Net.Http.HttpClient クラスを利用したものが紹介されています。ここでは C# で Azure.AI.TextAnalytics.TextAnalyticsClient クラスを利用しました。環境は Linux 上の .NET 5.0.302 を利用しました。コマンドは下記です。.NET に標準で含まれないパッケージを利用しますので、プロジェクトにパッケージを追加します。コマンドは下記です。パッケージを追加した結果のプロジェクト・ファイルは下記です。書いたコードは下記です。文字コードは UTF-8 です。
MICROSOFT_TEXT_ANALYTICS_ENDPOINT と MICROSOFT_TEXT_ANALYTICS_KEY はプレースホルダです。コマンドは下記です。
無事に Japanese と判別されました。冒頭で「１画面に収まる記述量」と書きましたが、２つのファイル experiment.csproj と Program.cs のファイルサイズの合計は、1174バイトでした。お手軽です。


