More than 3 years have passed since last update.以前、新人の研修担当をしていた時に、その新人が『社内ドキュメントを検索できるツールあったら便利じゃないか』という提案したことがある。完成イメージ画像まで作っていて、名前は 『検索君』 だった。弊社では、一部クラウド化はされているものの、様々な事情で未だ NAS に大量のドキュメントが置かれている。
管理はしっかりされている一方、とにかく量が多く階層も深く、探すのが辛かった。新人が、しっかりと新人の目でその不満点を見ていた事に感心し、作るのも簡単そうだったのでサクッと作ってみた。初代検索くんは、数時間で作られてこともあり、便利さは限定的だった。とにかく、現実との乖離 はサービスの価値としては致命的なので、これをまず何とかしたい。二代目でやりたい事は、実際のソースコードは全てGithub にある。github.com/kentork/kensakukun
github.com/kentork/tansakukunNTFS ファイルシステムには、 MFT ( Master File Table ) という全てのファイルエントリを管理する親玉ファイルが存在する。どうやら、 Everything 等の高速 Index 検索ツールもこれを使って高速化しているらしいと聞き、検索君もこれを使って高速化できないだろうかと挑戦してみた。以下、参考にWikipedia - マスター ファイル テーブル
NTFSの読み方全然無い。
ソースコードはチラチラと見つかるが、古かったりよく分からなかったりと、とにかく無い。取り敢えず、良さそうなサンプルソースをいくつか読み解きながら、主にこのコードを参考に進めた。CCS LABS C#: Accessing the Master File Table● 参考stackoverflow - How do we access MFT through C#

How to read file attributes using Master File Table data

Get file info from NTFS-MFT reference number
役割としては検索君とは独立しているため、プロジェクトを切りだした。github.com/kentork/tansakukunC# を書くのは久しぶりなので、まずは C# の環境を作るところから始める。
以下、 scoop は使えるものとして進めるまずは、DotNet SDK を入れる。※ 今回は、x86向けにビルドする必要があるので、アーキテクチャを指定している。x64 を使っている人は何とか頑張ってください次に、gh コマンド で Github プロジェクトを作り、C# プロジェクトとして初期化する。サンプルソース を実行してみたが、以下でエラーが出たので、ちょっと直した。実行これで、一応動いたんだけど、取れるのはファイル名だけだった。
以降、カスタマイズしていく。まずは、これをフルパスにする機能を追加した。ファイルをリストしている間に、実はフォルダも全部リストアップしていたのでそれを使った。
やっていることは、親への Reference を辿りながら、パスを結合していくというシンプルなもの。C# 的に再帰ってどうなの？とは思ったけど、眠くてこれ以外にアルゴリズムが思いつかなかった。これで、フルパスが取れるようになった。
ローカルマシンで確認した所、『C:』から350万ぐらいのファイルを読み込んで、2分弱 ( CPU Core i5, Mem 16GB )。早い。ここで、試しに社内の NAS に繋いでみようと思ったが、１つ疑問が。あれ、共有フォルダって Drive Letter 無いよね？とは言え、ホスト名とか入れれば動くんでしょ、と思ってやってみたが、駄目だった。
ネットワークドライブの割当も駄目。え、NAS 繋がらないの？ 意味ないじゃん！！しかし、MFT をつかっているであろう高速 Index ツールにも、共有フォルダに対応する物はあるので、できないことは無いのでは、と思っている。今の所、対策は無い。[追記]
さっき、出張から戻った同僚に相談したら、なんだかんだで MFT を取るのは難しんじゃないかと言う感じになった。
さて、次の方法を考えないと。。。次に、検索エンジンを groonga から Elasticsearch に変更。
安定感、アクセスのしやすさ、情報の多さ、これまでの経験を含めて、Elasticsearch がベストと判断。Elasticsearch は Docker として立ち上げる。
これは、検索君のプロジェクトで管理している。Elasticsearch のイメージは、library/elasticsearch ではなく docker.elastic.co/elasticsearch/elasticsearch が公式サポート版。今の所、クラスタを組む気は無いため、single-node で動作している。上記で Elasticsearch を立ち上げたら、まずは tansakukun の方から入れ込む。
C# から Elasticsearch を操作をする場合、以下クライアントが公式にサポートされている。Bulk API が提供されているのは Elasticsearch.Net だけ なので、コッチを使う。ポイントとしては、10000 ファイルでチャンクしたのは、HTTPリクエストと大量データ送信の程よい均衡点を探しての事。
設定ファイルで変更可能であり、現在は 2~50000 ファイルあたりでもパフォーマンス調査しているが、失敗もなく時間増加も線形的なので、もっと増やしてみたい。先程の350万レコードを挿入して、大体 15 分程度だった。まぁまぁ早い。※ 後で気付いたけど、Elasticsearch に日本語検索のプラグイン入れてなかった。パフォーマンス確実に変わるので、上記は参考程度に。これは、以前の Ruby + Sinatra のままでも良かったのだが、クエリ検索の機能があまり優秀ではなかったりして、もう少し本格的にしていきたいなぁと。で、そうなると Ruby + Sinatra だと少し不安だなぁ。ということで、 Elixir にした。
速度や安定感もさることながら、データ加工 が素晴らしい。パイプラインやパターンマッチ等で流れるようにデータが加工できるのがとても良く、データを少し加工して返すシンプルな API サーバとしてとても優秀だと実感した。
以下の資料に、その素晴らしさがまとめられている。やや関数型を意識した風Elixir／Phoenixご紹介辛かったのは、まとまった良い情報が Web 上にあまり無いこと。
同時期に Rust も書いていたが、あっちは公式も充実していたし記事も多かった。
仕方なく、昔買った プログラミングElixir を見ながら頑張った。メインプロジェクトとして、Elasticsearch 等クラスタ管理も仕切る。github.com/kentork/kensakukunElixir を書くのも久しぶりなので、まずは Elixir の環境を作るところから始める。
以下、 scoop は使えるものとして進める本来は、Docker で動かしたかったが、変更監視 → Recompile の手法が見つけられなかったので、今回はローカルでの動作を前提とする。次に、gh コマンド で Github プロジェクトを作り、Elixir プロジェクトとして初期化する。今回は、Phoenix 等のフルスタックフレームワークは要らないので、シンプルに plug だけの web サーバを考える。Webサーバは cowboy で、Rack 的な Web インターフェイスに plug。
JSON パーサとして poison を利用。
Elasticsearch へのクエリは、クライアントを使わずに httpotion でリクエストする。クライアントで使う Google API 用の Client ID は、クライアントに埋め込見たくない。
ので、エンドポイントを 1つ設けてある。これは、通常の HTTP を用いる普通のやり方。特に無し。350 万件から部分一致件検索で 1000件取得して 150 ms 前後。
以前に比べて数倍~数十倍早いんじゃなかろうか。インクリメンタル検索も夢じゃない？※ 後で気付いたけど、Elasticsearch に日本語検索のプラグイン入れてなかった。パフォーマンス変わるので参考程度に。本番 ( と言っても社内だが ) に向けて、Docker 化はしておきたい。
公式のパッケージが Hex や Rebar を含んでおらず、入れていないと毎度聞かれるのが面倒なので、あらかじめ入れたイメージを作っておく。サービス定義はこんな感じ渡した環境変数は、config/prod.exs で参照している。
API_TOKEN だけは、便宜上 .env から取得している。動かす時は、一度初期化が必要。ここは、ほぼ初代からの流用である。バージョンだけ上げている。
やはり、Riotjs + Bulma.css の組み合わせは、ぱっと作るのに向いている。配信は、Caddy が担当している。これだけで、 HTTPS + HTTP2 (+ quic) + Reverse Proxy。素晴らしい。ここまでで Docker 化終わってるので。現在、ローカルでは一応動いている。検索は確実に早くなるでしょう。しかし、Index 化が早くならなくては余り意味がない。
最新の情報があるという保証がなければ、サービスの価値は低い。
少なくとも、1日1回は走らせたい。その為には、せいぜい 30分~1時間以内 は欲しい。とにかく、ネットワークの向こうの NAS をいかに高速に Index するか考えなくては。
MFT が取れるのか、それとも取れないのか。
MFT から取らないのなら、他に方法は無いのか。


