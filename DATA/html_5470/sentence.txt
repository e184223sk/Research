More than 3 years have passed since last update.PostgreSQLを使っていたら、日付のソートってどれぐらいの処理速度なんだろう？と気になったので計測してみました。環境：psql (PostgreSQL) 10.2 Windows版、Npgsql（v3.2.6 - 2017/12/3）、データディレクトリはHDD、.NET Framework 4.6データ挿入はアプリケーション（C#）側から行っています。パフォーマンスの比較はPostgreSQLにログインし、コマンドラインから\timingコマンドを使って行います。公式ドキュメントによると、timestamp型が日付と時刻を両方管理するのに使えそうです。タイムゾーンあり（TIMESTAMPTZ）、なし（TIMESTAMP）の2つがあります。標準SQLではTIMESTAMPはタイムゾーンが含まれなく、TIMESTAMPTZはPostgreSQLの独自の拡張だそうです。INTERVAL型は時刻と時刻の差分を表す時間（Npgsqlのドキュメントによれば、.NETでいうところのTimeSpan）なので、時刻を表すのにはちょっと違うかなと考えて除外しました。
また、UNIX時間を64ビット整数のbigintとしてそのまま格納する方法もあります。それ以外にも、タイムスタンプをある一定のフォーマットの文字列TEXT（VARCHAR(N)でもOK）として（ここでは2001-09-09T10:46:40+09:00のような「ISO 8601形式」を用います）格納する方法もあります。
1つのカラムに1データであることにとらわれない場合は、JSONの中にタイムスタンプを文字列として埋め込んでしまう方法もあります。その場合は、JSONのバイナリ型であるJSONBとしてカラムを定義し、その中にタイムスタンプの要素を作ります。おそらく文字列の場合と似た挙動になるのではないかなと思います。したがって、以下の5つのデータ型を調べることになります。挿入まではC#で行います。ランダムな並びの整数を日本標準時のUNIX時間として、日付形式に変換し格納します。開始値は10億（UNIX時間で2001/09/09 10:46:40+09:00）とし、一定間隔（この例では31）でUNIX時間の配列を1000万件作成します。これをランダムにシャッフルし、様々なデータ型に変換し、格納してソート時間を比較します。作成したデータを改行区切りのJSONで保存します（格納すれば関係ないので形式はなんでもいいですが、UTF8エンコードでファイルに書き出して7.78GBだったので一気にオンメモリでシリアライズする…的なことをすると死にます）。データ生成部分はこんな感じにCreateDataというクラスで。Guid.NewGuid()がおおよそユニークな乱数として利用できることから入れ替え時に利用しています。Membership.GeneratePassword()はランダムな128文字の文字列を作るために使っています（これはソートに無関係なデータであり後々使います）。JSONシリアライザーにはServiceStack.Textを使っています。エントリーポイント本当にランダムなの？ということで最初の10件を表示してみます。確かにランダムですね。日付型のカラムのみで構成される、単一カラムのデータテーブルを作成し、ソートにかかる時間を比較します。次のような定義です。TEXTはVARCHAR(N)でもいいです。PrimaryKeyやインデックスはとりあえずは作りません（後で作ります）。5つの型について比較します。DBの初期設定と起動、データベースの作成を行っておきます。Npgsqlによる挿入コードは以下の通り。TimestamptzでDateTimeOffsetではなく、DateTimeなのがちょっと直感的ではありませんがこれが仕様のようです（公式ドキュメントの.NET Native TypeがDateTimeになっています）。Qiitaでも検証している方がいます。参考：https://qiita.com/kkino90h/items/147aed6162c82a1022f9各3回ずつクエリを実行します。1回目と2回目で明らかに速くなっているのはOSのファイルキャッシュなど、何かしらのキャッシュが効いていそうです。条件を切り離すのが難しいですが、キャッシュが効いていないときと効いているときの処理時間がおおよそ比例していればまぁ大丈夫かなと。タイムゾーンありより若干速そう。多分これが一番速いはずです。アンチパターンと言われそうな形。Locale=Cだからまだマシなものの、他のロケールだったらもっとパフォーマンス悪くなると思います。ロケールとソートの速度の関係については下記の記事がとても詳しいです。参考：https://qiita.com/fujii_masao/items/2a715fb5a3f718d22ab4JSONながら意外と健闘している！？　テキストとして取得する-&gt;&gt;演算子ではなく、配列として取得する-&gt;演算子だとソートはできるものの、この2倍ぐらい遅いので注意してください（気付かずにやり直した）。ちょっとキャッシュ関係が再現性が紛らわしいですが、（明示的にキャッシュをクリアする方法もわからなく、DROP TABLE, DROP DATABASEをして再格納しても1回目の遅い状況を再現できなかった）。各3回の処理時間のうちのTimeの中間値をまとめると次のようになります。※1000万件のランダムなタイムスタンプを昇順ソート大方予想通りの結果になりました。JSONBを除けばTEXT型が最も遅く、日付や時間でフィルタリングする場合に再度パースするオーバーヘッドがつくので、普通は使う意味がないです。JSONBも結局TEXTとして取り出してソートなので、やっていることはそこまで変わらなそう。本格的にやるならタイムスタンプ用のカラムを定義したほうが良さそう（似たような悩みはStackOverFlowを見ていたらそこそこありました）。
BIGINTは確かに最速ですが、フィルタリングする場合やタイムゾーンがある場合にちょっと面倒になるので、ここでの速度を取るか可読性を取るかはよく検討する必要がありそうです。各テーブルの容量を取ると次のようになります。JSONBがちょっと特殊ですが、サイズが多いほどソートが遅くなるようです。3の単一カラムの5ケースを1つのデータテーブルに統合します。挿入は以下の通り。単一の場合最速だったBigIntと、中間だったTimstamptz、最も遅かったJsonbの比較を行います。レコードあたりのサイズが大きくなっている分ソートに時間がかかっていますが、遅い型でソートしたときに遅くなるのはやはり変わらない模様（BigIntとTimestamptzが逆転しているのが謎）。Timestamptzの初回だけ遅くなっているのはやはり何らかのキャッシュが関係してそうですね。データテーブルの容量を取ります。tstz～jsonの単純合計とはならなかったのが興味深いですが、容量に比例してソートは遅くなっています。今までずっとインデックスを張ってきませんでしたが、multiテーブルのtstzカラム（Timestamptz）に対してインデックスを張ってみます。インデックスを張らない状態と張った状態で2005年のデータを抽出し、WHEREを比較します。あれ、インデックスを張ると遅くなってる！？WHEREが4.8秒→5.2秒と若干遅くなり、フルソートが最悪で34秒→3分42秒と大幅に悪化しました。ただEXPLAIN ANALYZEで分析してみると、インデックスを張ったほうが総コストは下がっています。処理時間は34秒→3分42秒と悪化しているのに、総コストは216万→98万と改善しています。インデックスが激遅になってしまうのは、シャッフルされたカラムに対してインデックスを張ったのが原因だったようです（後述）。そもそも論でこんなランダムな日付のデータをデータベースに突っ込むべきではないし、突っ込むにしてもソートしてから突っ込むべきですよね。インデックスなしの場合に「Workers Launched: 2」という並列化のようなもの（パラレルスキャンというそうです）が自動でなされているのも興味深いです。今のPostgreSQLはとてもお利口なので、インデックスなしの1000万件をソートするとかいうアホなクエリを書いても、自動でいろいろチューニングしてくれるのでしょう。なので、この例ではたまたまそうでしたが、インデックスないほうが処理が速く終わるというのは、かなり特殊な状況と認識しておいたほうがよさそうです。EXPLAIN ANALYZEでの総コスト値はインデックスがあったほうが少ないので。インデックスの明確なデメリットはあります。以下、インデックスがある場合、ない場合でのpg_total_relation_size（インデックス込みのバイト数）です。インデックスだけで200MB以上使用しています。乱用は厳禁です。INDEXをUNIQUE INDEXにしてみましたが、大して変わらなかったので省略します。一旦インデックスを削除し、プライマリーキーを張ってみました。結果はインデックスの場合と変わらなかったので省略します。追加で実験してみたところ興味深いことがわかりました。先程の「SELECT * FROM multi ORDER BY tstz」というソートですが、一旦ソートしてから別のテーブルに格納し、同じようにソートしてみます（後半の場合のソートは事実上意味がない）。そしてその時間をインデックスあり・なしで比較します。このようにソート済みのテーブルmulti2を作ります。インデックスなしでソートすると次のようになります。インデックスなしの場合は、未ソートのテーブルmultiの場合とほぼ変わりません。未ソートの場合は、インデックスを作成すると大幅にパフォーマンスが悪化（34秒→3分42秒）しましたが、ソート済みテーブルの場合はどうでしょうか？格納時にソートすることでインデックススキャンが速くなりました！　ソート済みの場合は、インデックス未作成の場合よりフルソートでも3～4秒速くなりました。これがインデックスの本来のパフォーマンスでしょう。詳細は省略してしまいましたが、WHEREによる比較もインデックスがない場合より速くなりました（1年分を抽出するので時間が半分に）。PostgreSQL（SQL全般）のデフォルトのインデックスに、Btreeとよばれるデータ構造を使用しています。これが2分探索木に近いデータ構造であるため、ソートされたデータに対してインデックスを張ったほうが明らかにパフォーマンスが良いです。なるほど、これはいい勉強になりました。EXPLAIN ANALYZEでも確認してみます。multiが未ソート、multi2が事前にソート済みです。multi2はソート後にインデックスを張り、multiはソート前にインデックスを張ってソートのクエリをEXPLAIN ANALYZEをします。どちらもIndex Scanが用いられています。総コストを見ると、multi2（ソート済み）が44万であるのに対して、multi（未ソート）は倍以上の98万です。ソート済みだから当たり前だろうと思うかもしれませんが、Seq Scanの場合はソートの有無にかかわらず総コストは変わりませんでした。どちらもインデックスを外してもう一度EXPLAIN ANALYZEしてみます。4.3ではコンソールを用いて、レコードのソートの有無とシーケンシャルソートの実行時間がほとんど変わらないということを確認しましたが、さすがにそれは腑に落ちないのでC#（Npgsql）側でも確認してみます。
なぜ腑に落ちないのかというと、ソート済みのテーブルで「SELECT * FROM テーブルORDER BY ソート済みカラム」をやったとしても、やっていることは実質的に「SELECT * FROM テーブル」と変わらないからです。つまり、ソート済みのテーブルと未ソートのテーブルで、結果的にORDER BYの処理時間が無視できる…さすがにそれはないだろう。となったわけです。まず、multiから以下のような4つの派生テーブルを作ります。インデックスには各テーブルのtstz（Timestamptz）を使います。まず、スキャンの方式ですが、SELECT * FROM テーブル（全レコードスキャン）は、EXPLAIN ANALYZEで確認したところインデックスの有無にかかわらずSeq Scanが用いられました。ORDER BYを用いると、インデックスありの場合はIndex Scanになり、インデックスなしの場合はSeq Scanとなりました。スキャン方式をまとめると次のようになります。4テーブルに対して、「SELECT *　FROM テーブル」と「SELECT *　FROM テーブル ORDER BY tstz」の2つのクエリをC#側から行い、実行時間を比較します。どれもほぼ変わりません。全部シーケンシャルスキャンだからそれはそう。ソート×、インデックス○な場合だけ桁が違います。これはコンソールの場合と同じです。インデックス×、ソートの有無でソートの速度が違うかというと、見た目はソート○のほうが遅いという謎な結果ですが、初回は特に外れ値のように遅いので、ディスクアクセスやキャッシュの誤差の範囲内かと考えられます。ソート済みのほうが遅くなるというのはEXPLAIN ANALYZEからも説明できません。したがって、シーケンシャルなソートにおいて、事前ソートの有無はパフォーマンスに影響を与えるということを確認できなかったといえるでしょう。4.4の冒頭の疑問は解決しませんでしたが、コンソールからやってもアプリケーションからやっても同じ結果になるのはまあそういうものであると受け止めるしかありません。C#でのコードは以下の通りです。単一カラムの場合はデータ型によってシーケンシャルスキャンの遅い速いがありましたが、これはインデックスがあった場合でも同様になるのでしょうか？
tstz（TIMESTAMPTZ型）についてソート済みであるmulti_tstz、int（BIGINT型）についてソート済みのmulti_int、jsonカラム（JSONB型）のtimestampフィールドについてソート済みであるmulti_jsonの各3つのテーブルを作成します。4.3～4.4で事前にソート済みかどうかが、シーケンシャルなソートにおけるパフォーマンスに影響を及ぼさないであろうということがわかったので、この状態でソート操作を行い、インデックスの有無による処理時間を見ます。以下同様。JSONBのmulti_jsonのインデックス作成はちょっと特殊で、同じくBtreeインデックスを利用しますが、フィールドを()でくくります。結果は以下の通り。シーケンシャルな場合は若干JSONBが遅かったですが、インデックスの場合はどれもほぼ変わらないように見えます。ただ、これだけではなんとも言えないのでJSONBについては後ほどレコードのサイズを変えて実験してみます。インデックス絡みでだいぶ脱線してしまいましたがまとめます最後に、JSONBでKVSで格納する場合に、ソートに無関係なデータのサイズとソート時間をインデックス有り・無しで比較します。これまでの調査で、シーケンシャルなソート時間と全体のデータのサイズはほぼ比例することがわかったので、インデックスなしの場合のソート時間は無関係なデータが増えるほど遅くなるはずです。ただし、インデックスとは文字通り”索引”なので、インデックスありかつレコードの件数が同一な場合において、無関係なデータが増えても定数時間で検索できれば、これほど嬉しいことはありません。今回はインデックスとしてGINインデックスではなく、フィールドに対してBtreeインデックスを使います。なぜならGINインデックスはORDER BYのような比較演算子に対応していないためです。公式ドキュメントより、jsonb型の問い合わせでサポートしているデフォルトのGIN演算子クラスは、トップレベルのキーが存在するかの演算子として?、?&amp;、?|があり、パス／値が存在するかの演算子として@&gt;がありますBtreeインデックスを効率よく使うために、ランダムではなく事前にソート済みのデータを用います。ソート済みのデータをソートするというのも不思議な話ですが、事前にソートしようがしまいがシーケンシャル（インデックスを張らない場合）なソートにおいて処理時間が特に変わらなかったから仕方ありません。気持ち悪ければ、事前に昇順にソートしたデータを、ORDER BY…DESCで降順ソートすると置き換えて読んでも構いません。事実、4.5で登場したjson-&gt;&gt;'timestamp'について昇順ソート済みのmulti_jsonテーブルに対して、シーケンシャルなソートを行ってみると昇順でソートしようが、降順でソートしようが時間は変わりません。ここでは、無関係なデータとして128文字のランダムな英数字を用いて、その文字列を配列として格納します。配列の要素数を1、3、5と変化させたテーブル、one, three, fiveを作り、インデックスの有無でORDER BYの時間を比較します。JSON生成部分のC#プログラムを再掲します（全部のコードは2を参照）。この引数のtakeLengthを1,3,5と変化させます。CreateDataのクラスに連続したデータを読み書きするクラスを作ります。例えば5の場合はこのようになります。全く意味のないゴミデータです。ファイルへの読み書きは次の通り。これまでと同様に1000万レコード作ります。挿入は以下の通り。インデックスをつけない状態のテーブルサイズは次の通り。これまでのようにjson-&gt;&gt;'timestamp'にインデックスをつければインデックススキャンになるのかと思ったら、インデックスを使われる場合と使われない場合がありました。oneはインデックススキャンになっているのに、threeとfiveはシーケンシャルスキャンです。なんやそれ？？　仕方がないので、インデックスをjson-&gt;&gt;'timestamp'ではなくidカラムに対して付与してみます。int型のidカラムに対してだとさすがにインデックススキャンが用いられました。さすがにこれは予想外だったので、計画を変更して、「SELECT * FROM テーブル ORDER BY id」で比較します。idカラムに対してインデックスを不可した場合はインデックススキャンになることを確認しました。以下のような流れで行います（事前にインデックスは全てはずしておきます）。時間比較はまたコンソールの\timingで行いました。その前に、json-&gt;&gt;'timestamp'をインデックスなしでソートした場合の時間を張っておきます。概ねテーブルサイズに比例しています。中央値[ms/GB]は中央値[ms]をテーブルサイズで割って1000掛けて算出しています。次に、idをインデックスなしでソートします。jsonでのソート時間より若干速いぐらいが期待されます。oneのみキャッシュが効いたのか高速になっていますが、ほとんどjson-&gt;&gt;'timestamp'でソートしたときと変わりません。idにインデックスを張って再びソートします。インデックスを張ると、レコード数に対して定数時間でソート可能というのはさすがになりませんでしたが、threeとfiveのテーブルにおいてインデックスを張らない場合の3～4倍の速度でソートできています。線形時間であるものの、インデックスを張らない場合より傾きが緩やかであったというべきでしょう。
もちろんこれはソート済みの段階でインデックスを張ったので、ランダムに近いような状態だとこれまで見てきたようにシーケンシャルスキャンより遅くなることもあります。非常に長い投稿になってしまいましたが、これまでの内容を振り返ります。以上です。データベース素人ですが、インデックスについてモヤモヤしたことが解決して勉強になりました。以下、チラ裏ですが、処理している途中HDDがガリガリ言っていつ壊れるか不安で仕方なかったので、今度似たようなことをやるときは作業用のSSDを買おうと思いました。fiveのテーブル（8GB程度）をインデックスでソートしている途中のタスクマネージャーのスクショです。

メモリの食べ過ぎに注意しましょう。


