VRヘビーユーザーからすれば当たり前のことかもしれませんが、
OculusQuestにマイクが搭載されているのはご存じでしたでしょうか。ボイスチャットに利用されることがほとんどで、
その他の用途で使われている事例をあまり見たことがありませんでした。
(たぶん世の中にはたくさんある)しかし、最近目にした記事にボイスチャット以外の用途でマイクを使った事例がありました。
【参考リンク】：Synamon、ロゼッタと「リアルタイム多言語翻訳システム装備のVRオフィス」を共同開発一言で説明すると、翻訳VRアプリです。
マイクを音声認識の受け口として利用しています。そこで、私も勉強がてら"OculusQuestのマイクを利用したVRアプリ作りに挑戦してみたい"と思い、実際に作りました。勉強がてら作成していた翻訳VRできました！😎OculusQuestのマイクで拾った音声を音声認識APIに渡して、認識結果を翻訳APIに渡す、、、というやり方です💪次はマルチ対応していきます😆#OculusQuest #Unity pic.twitter.com/k95D73gEnh先ほどのアプリで利用した翻訳の部分はMicrosoft Translatorを利用しています。登録の手順を覚えている範囲でメモします。
この手順に関してですが、2021/04/03時点の情報となります。
私も使い方がわからなかったため、過去に執筆された記事等手掛かりに進めてましたが、UIや手順に変更があり、そこそこ苦労しました。この記事もそうなる可能性が高いのでご注意ください。まずは下記からMicrosoft AzureのHome画面を開きます。ログインしたらHome画面上部からTranslatorを検索し、
Marketplaceの欄のTranslatorを選び、登録に進みます。
登録画面で必要な項目を選択します。ここでPricing tierの欄をfreeにしておけば無料で使えるはずです。(たぶん)
設定完了したらAPIを利用する際に必要な値を下記画面から確認できます。
翻訳VRアプリ内のコードは他のAPIに置換できるよう、モジュール化しているためわかりにくいかなと思い、シンプルな翻訳デモを作りました。
英語→日本語、日本語→英語が翻訳可能です。
もちろんMicrosoft Translatorが対応している言語であれば他の言語でも翻訳可能です。
【参考リンク】：Language and region support for text and speech translation念のため使ったライブラリ等のバージョンも書いときます。Unity 2019.4.8f1
UniTask.2.2.4
UniRx 7.1.0翻訳デモのコードです。APIのリクエスト用のJson、APIのレスポンス用のJsonのそれぞれをシリアライズ、デシリアライズするための構造体を用意する必要があります。リクエスト用のJsonはルートが配列でないとAPIの都合上だめだったのでごり押ししています。
var jsonData = "[" + JsonUtility.ToJson(speechData) + "]";【参考リンク】：【Unity(C#)】WebAPIで返ってきたJSONデータの扱いでつまったところ全然関係ない内容ですが、知らなかったのでメモします。(下記参考リンクのまんまですが...)【参考リンク】：UnityでDropDownのOptionリストに、enumの定義値をラベルとしてスクリプトからセットするEnumの値をvar languages = Enum.GetNames(typeof(Language));で配列化してDropDownの値に追加します。あとはDropDownの値変更を監視して、変更時にenumに値を設定してあげればOKです。記事内にも書いた通り、翻訳APIの箇所はモジュール化しているので他の無料で使えるAPIと比較して精度など試してみようと思います。次は音声認識機能について書きます。Microsoft Translator テキスト API で、日本語を英語に翻訳するサンプル
UniTaskの使い方2020 / UniTask2020
Quickstart: Get started with Translator


