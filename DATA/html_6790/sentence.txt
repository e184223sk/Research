More than 3 years have passed since last update.Elasticsearchに.NETからつなげるクライアントライブラリの5.0がリリースされた記念ということで、Elasticsearch5.0から入ったIngest Nodeをこのライブラリを使ったらどう使えるのよ、というところを試した記録です。5.0のリリースの案内はこちら
NEST 5.0 released試した環境は以下の通りです。の直後に生成されたproject.jsonに対して追加した例がこちら。"Nest": "5.0.0"の箇所です。X-Packを導入して認証を求められる環境に対して接続する場合は、以下のような方法がある。Tweeterのtweetを例として、Ingest Nodeを使用例を説明したIngest Node: A Client's Perspectiveを参考にします。Pipeline、Processorの内容や大まかな流れとしては、こういう理解で良いと思います。Apache Solrで言うところのUpdateRequestProcessorや、古くはFAST ESPで言うところのDocument Proccessorに相当するもんだと思います。使えるProcessorについては、公式ドキュメントを確認されたい。
https://www.elastic.co/guide/en/elasticsearch/reference/5.1/ingest-processors.html
experimentalとかついているのもあるので、そこは注意が必要。以下、今回使ってたProcessorごとにコメントしていく。型を変換するくらいなら、最初からその型でフィールドを宣言してたらいいがな、ということもあろうかと思います。
または、マッピングをちゃんと書いておけばいいじゃない、と。しかしながら、そうはイカのふんどし、のっぴきならない事情に対応する１つのアプローチとして、Convertが使えるかもしれません。この例は、Tweet.Retweetsがstring型だけども、入っている値はIntegerなのでintegerに変換する場合の例です。
Fieldに変換元の値が入っているフィールド、Typeに変換先の型を書きます。ConvertProcessorTypeでは、次の項目が設定できます。何らかのスクリプトを実行して、その結果を格納したいんや！というときに使えそうです。Langでは、デフォルトがpainlessというelasticさんのオリジナル言語です。
他にはgroovyやpythonも使えるそうですし、得意なのを選べばいいと思います。上の例では、retweetsに格納されている値に対して、外から与えられたパラメータ params.valの値を乗じる、ということをやっています。
もちろん、if文やfor文なども使えるので、ちょっとした加工であれば、独自のIngestNodeプラグインを書くまでもなく、これで出来そうです。ctx.XXXXXXXと、ctxとフィールド名でパイプラインで処理されている中身のデータに対してアクセスできるようです。
また引数はparamsで指定し、key, valueのように設定しておくことで、スクリプトではparamsでアクセスできるようです。ctxがContextに見えれば、何も説明なくてもApacheのcommons-chainのようなもんか、と想像できて納得できるのではと思います。みんな大好きGrok！Logstashでログファイルを読み込んで加工する、といった場合において、もっともお世話になったのではないでしょうか。上の例では、Messageフィールドに入っている値をPatternsで設定した条件にあてはめ、結果を格納します。もし、Messageが「Hello World!」という文字列だったらば、word1フィールドに"Hello"、word2フィールドに"World!"と展開されてはいることになります。固定値を入れてやりたいとき、ありますよね。そういうときに使えそうです。上の例では、fixedFieldというところに"fixedValue1, fixedValue2"という値を設定します。.Fieldの書き方ですが、.Field(t =&gt; t.XXXXXX)　というような書き方ができますが、.Field("フィールド名")のように書くと、
Tweetクラスに存在しないフィールドを指定することもできるようです。もちろん、そんなことをすると検索した結果をDeserializeしてオブジェクトとしてとってきたときに、値が取れないということになるわけですが、Pipelineを通っている間だけ使う仮の値を格納するとか、そういう用途では使うことがあるかもしれません。カンマ区切りやタブ区切り、改行コードで区切られた文字列があって、これをSplitして各要素として使いたいとき、特にAggregationしたいフィールドでは、こういうことが多いように思います。
keywordやtag情報をDBに格納するときに、指定文字で連結して入れる、とかそんなシステムがあるかもしれません。上の例では、fixedFieldに入っている文字列をSeparatorで指定した"," で区切って、結果をfixedFieldに格納します。
今回は、Set ProcessorでfixedFieldには、"fixedValue1, fixeValue2"　と入っていましたが（この時点では、fixedFieldはただのstring)、ここでSplitされることで、fixedFieldは、["fixedValue1", " fixedValue2"]とarrayになることが確認できます。単純にカンマで区切ってしまうと、今回の例ですとfixedValue2の前に半角空白が入ってしまいます。
Separatorをこうしてやると、変な空白はなくなります。メモ）　Trim ProcessorはArrayのフィールドには適用できない大文字に変換して格納しなおす、というだけのもの。わかりやすいので説明を割愛します。TweetクラスIndex作成これをIndexすると、先のPipelineで処理された結果、こうなる。
Consoleより検索を実行して確認Ingest Nodeは、Apache Solrで独自のProcessorを作ってUpdate Request Processorsに追加していた人、FAST ESPをやっていた人にはすごく馴染みやすいと思う。
もちろん、どこまでIngest Nodeでやって、どこまでを投げる側が事前にやっておくか、といった線引きはあるだろう。NESTは、書き方ってこういう感じなのね、と１度確認できれば、学習コストがあまり高くない、分かりやすい作りになっているように思う。
kibana/Consoleで出来ることと、似たような感じで実装されているので、メソッドも探しやすい。
.NETCoreもサポートされているところが個人的にかなりプラス評価。まだ開発は活発に行われているようなので、バグに泣くかもしれないけども、そこはご愛敬。


