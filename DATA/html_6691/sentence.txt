　今回は前回言ったように単項演算(一つのTensorを受け取る)クラスを定義していきたいと思います。　UnaryFunctionは以下のように一つのTensorを受け取り一つのTensorを返すような操作を想定しています。　それでは実装していきますが内容はほぼBinaryFunctionと変わらないです。ForwardとBackwardを加工して返す関数を定義しているのと、プロパティを定義しているだけです。これで、単項演算の実装に移ってもいいのですがさらに具体性を高めたクラスを追加します。　ここで機械学習で用いるMean関数とReLU関数について考えます。これらはどちらも一つの入力と一つの出力を扱うようにでき、UnaryFunctionと見なすことができます。しかし、ReLU関数はMean関数とは異なり、出力されたTensorの一つの要素が入力の一つの要素によって作られているということです。　これを図で表すと以下のようになります。
　↓ReLU
↓Mean(集合演算)
　上のような関数では、要素ごとに行う関数のForwardとBackwardを定義しておけば処理ができるので、
　このような関数クラスをLambdaとして実装します。$f(x)$と$f'(x)$をコンストラクタに入力するように実装します。　Lambdaは実装しなくてもMinusは実装できますが、これによってReLUや他の関数が簡単に定義できるようになります。それではTensorクラスにマイナスオペレーターを実装します。　これだけで済みます。Lambdaは具体性が高い分実装時に大幅に手間を省くことができます。　モデルを作る際に$nn.Linear$だとか$F.relu$だとか短く関数を使用できれば大変便利ですが、私のライブラリで使用しようとすると　
　となり大変使いづらいです。そこでstaticクラスを用意して関数として上の処理を呼び出すようにします。
　ついでにReLUなども実装してみます。　これで$F.ReLU(input)$でForward処理を呼び出せるようになりました。　今回は単項演算を実装しました。追加で、ライブラリの利便性を高めるための実装も行いました。本当は行列積と単項演算は一回でまとめるつもりでしたが、思いの外行列積に手間取ってしまい三回に膨れ上がってしまいました。これでまだ機械学習には触れてないというのが恐ろしいです。
　次は集合演算を実装したいと思います。具体的には(Mean, Sum, Max, Min)です。


