More than 1 year has passed since last update.ボイスチャットの実装に当たっていろいろなライブラリがありますが、
メジャーどころで情報が多そうなPhotonを使うことにしました。しかしながらPhoton2のボイスチャットの実装方法に関する記事を
見つけることができませんでした。公式のドキュメント読めば余裕かな？と思ってましたが、
実際に繋がっているかどうかのテストとかも面倒で意外と時間使ったのでメモします。まずはPhoton Voice 2というアセットの導入です。
アセットストアからインポートします。PUN2もインポートします。次にアプリケーションIDを作成する必要があります。
アカウント作成後に下記のようにPhotonVoiceという種類の
アプリケーションを作成します。Photonアプリケーションの作成下記パスのPhotonServerSettingsのアプリケーションIDを設定します。
Assets\Photon\PhotonUnityNetworking\Resources\PhotonServerSettings先ほど作成したPhotonVoiceという種類のアプリケーションIDを入力します。
次にHierarchyに必要なコンポーネントを用意します。
PhotonVoiceNetworkとRecorderが必要です。適当なオブジェクトにアタッチして、
赤枠で囲った箇所が合ってればだいたい問題ないです。
AvatarというPrefabをアタッチしている箇所にはPhotonNetwork経由で生成する
アバター(同期オブジェクト)を設定しています。【参考リンク】：【Unity(C#),PUN2】OculusQuestのハンドトラッキング同期実装Avatar側にも設定が必要なので見ていきます。SpeakerとPhotonVoiceViewが必要です。
AudioSourceは自動で追加されます。赤枠で囲った箇所を設定します。
SpeakerInUseは自身のオブジェクトからアタッチします。これでおおよその設定が完了しました。今回利用したアバターは下記画像のものです。
球体が頭部で口は独立したオブジェクトとして頭部の子階層に配置されています。NormcoreというVR/ARの通信同期実装のためのライブラリから拝借しました。今回はこの口のオブジェクトを声に合わせてパクパクさせたいと思います。もともとNormcoreのライブラリで口をパクパクさせるコードが
ドキュメントに公開されていますのでそれをPUN2用に利用してみます。実際のコード全文が下記です。_voice.RecorderInUse.TransmitEnabled = true;
の箇所で音声のやり取りを開始しています。_voice.RecorderInUse.LevelMeter.CurrentAvgAmp
で直前の0.5秒間の平均した音の波形を取得しています。この波形を利用して口のオブジェクトのY軸方向のスケールを変化させています。最後のSyncMouthメソッドの中で口のオブジェクトの大きさの変化を双方のクライアントで同期しています。GIFなので音はありませんが、相手の音がHMDから聞こえてきて
口がパクパクしているのを確認できました。繋がったり、繋がらなかったり、音声が極端に小さかったりと
不具合まみれだったので原因がわかり次第追記していこうと思います。


