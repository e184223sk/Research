More than 3 years have passed since last update.a = 1 で固定し
解α,βを正の整数0～100までの組み合わせ
(0,0)
(0,1)
...
(100,99)
(100,100)
101×101=10201通りを学習させてみました。
ニューラルネットワークはとりあえずこうしてみました。
出力は恒等関数です。
図のxの使い方がややおかしいとは思いますが感じは伝わっていると思います。
学習率は1で何もしてません。前回は基本的なミスがありました。誤差が
double[] mE = new double[] { o_0_out - alpha, o_1_out - beta };
となっていたので
double[] mE = new double[] { alpha - o_0_out, beta - o_1_out };
に修正誤差逆伝播が
w1から先に修正していたため
w0はw1の修正後の値で微分してしまっていて
w0から先に誤差逆伝播するよう修正しました。なんとか形になりました。
前回はNaN(無限大）だったか
セルにこんな値が出てきてしまい
てんで話しにならなかったのですが
とりあえず、それっぽくなりました。しかし、やってみてわかったのは
誤差逆伝播するとその入力に対しての解が出るようになってしまい
それまでの学習が全部関係ない結果になります。本当は出力結果を全部掲載して説明したいところなんですが
データが多すぎておそらく投稿できないのと
できたとしてとても重くなりそうなので
最終的な重みの値だけ掲載しておきます。wa_h0_0 -2309.71639140184
wa_h0_1 -2309.71639140184
wa_h0_2 -2309.71639140184
wb_h0_0 12644370.4100154
wb_h0_1 12644370.4100154
wb_h0_2 12644370.4100154
wc_h0_0 -639010033.780352
wc_h0_1 -639010033.780352
wc_h0_2 -639010033.780352
wB_h0_0 -123332.418400352
wB_h0_1 -123332.418400352
wB_h0_2 -123332.418400352wh1_0_o0 9.40005648077475
wh1_0_o1 -100.266352010226
wh1_1_o0 9.40005648077475
wh1_1_o1 -100.266352010226
wh1_2_o0 9.40005648077475
wh1_2_o1 -100.266352010226
wB1_3_o0 100
wB1_3_o1 99


