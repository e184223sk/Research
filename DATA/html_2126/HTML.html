<!DOCTYPE html><html><head><meta charset="utf-8" /><title>Azure Cognitive ServicesのSpeech to Textで書き起こしをしてみよう - Qiita</title><meta content="width=device-width,initial-scale=1,shrink-to-fit=no,viewport-fit=cover" name="viewport" /><meta content="#55c500" name="theme-color" /><meta content="XWpkTG32-_C4joZoJ_UsmDUi-zaH-hcrjF6ZC_FoFbk" name="google-site-verification" /><meta content="telephone=no" name="format-detection" /><link rel="canonical" href="https://qiita.com/yamachu/items/dda2624abbfe4364328a" /><link href="/manifest.json" rel="manifest" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link as="script" href="https://www.googletagservices.com/tag/js/gpt.js" rel="preload" /><link href="https://securepubads.g.doubleclick.net" rel="preconnect" /><script async="" src="https://www.googletagservices.com/tag/js/gpt.js"></script><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="aqM0F8nWoJm51gvdqgOoxRJmzIsbqNrhQZRuPhDwBtoyz5V6SVoAhbZ1eWKZpZgM3+0CbXYIbinX2kxcQX1BRA==" /><link rel="shortcut icon" type="image/x-icon" href="https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico" /><link rel="apple-touch-icon" type="image/png" href="https://cdn.qiita.com/assets/favicons/public/apple-touch-icon-ec5ba42a24ae923f16825592efdc356f.png" /><link rel="stylesheet" media="all" href="https://cdn.qiita.com/assets/public/article-2eaa7dbedc42a8ea65c722cda46d0ebb.min.css" /><script src="https://cdn.qiita.com/assets/public/v3-article-bundle-63de2d91fef827269d3f6b958db2335b.min.js" defer="defer"></script><meta name="twitter:card" content="summary_large_image"><meta content="@Qiita" name="twitter:site" /><meta content="@y_chu5" name="twitter:creator" /><meta property="og:type" content="article"><meta property="og:title" content="Azure Cognitive ServicesのSpeech to Textで書き起こしをしてみよう - Qiita"><meta property="og:image" content="https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0&amp;w=1200&amp;mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND1RWHAxY21VZ1EyOW5ibWwwYVhabElGTmxjblpwWTJWejQ0R3VVM0JsWldOb0lIUnZJRlJsZUhUamdhZm1tN2pqZ1kzb3RiZmpnWlBqZ1pmamdwTGpnWmZqZ2FiamdiX2pnb2pqZ1lZJnR4dC1jb2xvcj0lMjMzMzMmdHh0LWZvbnQ9SGlyYWdpbm8lMjBTYW5zJTIwVzYmdHh0LXNpemU9NTQmdHh0LWNsaXA9ZWxsaXBzaXMmdHh0LWFsaWduPWNlbnRlciUyQ21pZGRsZSZzPWYxNTk3NzgyZDdmNGVlNzhmODkwMjE0NGU3ZDdkNTY5&amp;mark-align=center%2Cmiddle&amp;blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RSGxoYldGamFIVSZ0eHQtY29sb3I9JTIzMzMzJnR4dC1mb250PUhpcmFnaW5vJTIwU2FucyUyMFc2JnR4dC1zaXplPTQ1JnR4dC1hbGlnbj1yaWdodCUyQ2JvdHRvbSZzPTEyNDc3NjYxZGQ2ODdiYjE3YmRkZGE1MDA5ZTA3MDVj&amp;blend-align=center%2Cmiddle&amp;blend-mode=normal&amp;s=f85358d1deffce1e0bbb115652ff577c"><meta property="og:description" content="メリークリスマス！（遅刻）

Azure AI Advent Calendar 2019 25日目のエントリーです。

みなさんクリスマスイブからクリスマスにかけていかがお過ごしでしたか？
私は本記事を書くために進捗の6時間を過ごして..."><meta content="https://qiita.com/yamachu/items/dda2624abbfe4364328a" property="og:url" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><meta content="C#,Azure,CognitiveServices,SpeechToText" name="keywords" /><script>!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};
if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];
s.parentNode.insertBefore(t,s)}(window, document,'script',
'https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '668972150489891');
fbq('track', 'PageView');</script><style data-emotion-css="17jxvjw 11t2ec1 1dvr2p8 18lkoru 1g4cku8 1iupg5d ijvq0v 15cocm3 12rp90f 115f4t 1b8uj5v 79elbk 16hhh7b fcbn8c 1gj7nt 154zy0m yikrym 1jqivyb 1ode1bp le4d8r 1hbd3g7 helsa7 8qb8m4 2imjyh he5w1s 70qvj9 3ojehk 100alwu 1dtnjt5 10ougpm 1ay9vb9 m19uds cgzq40 1wa99t2 1l3zk9f 4czcte 1yzj1fm 1uv1qiv 109dbrr 5jpx49 mnxgyc 1vlpknv fsjkhv 1b17vb0 7i7f4d"}>.css-17jxvjw{display:grid;display:-ms-grid;grid-template-columns:80px minmax(0,1fr) 300px;-ms-grid-columns:80px minmax(0,1fr) 300px;grid-template-rows:minmax(270px,auto) 1fr;-ms-grid-rows:minmax(270px,auto) 1fr;max-width:1280px;margin-right:auto;margin-left:auto;padding-top:24px;padding-right:24px;padding-left:24px;}@media (max-width:1200px){.css-17jxvjw{padding-bottom:0;padding-left:0;padding-right:0;}}@media (max-width:992px){.css-17jxvjw{grid-template-columns:80px 452px 300px;-ms-grid-columns:80px 452px 300px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}@media (max-width:770px){.css-17jxvjw{display:block;}}@media (max-width:480px){.css-17jxvjw{padding-top:0;}}.css-11t2ec1{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;z-index:5;position:-webkit-sticky;position:sticky;top:calc(56px + 24px + 16px + 32px - 16px);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:16px;width:80px;}.css-11t2ec1:after{content:'';display:table;}.css-11t2ec1:before{content:'';display:table;}@media (max-width:770px){.css-11t2ec1{display:none;}}.css-1dvr2p8{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-18lkoru{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;background-color:#FFFFFF;}.css-1g4cku8{display:inline-block;vertical-align:middle;height:20px;width:20px;fill:#55C500;}.css-1iupg5d{color:#55C500;cursor:pointer;font-size:14px;font-weight:bold;}.css-ijvq0v{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;margin-bottom:16px;}.css-15cocm3{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:#FFFFFF;border:2px solid #6E6F70;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:2px 0px 0px;width:40px;}.css-12rp90f{display:inline-block;vertical-align:bottom;height:17.77777777777778px;width:16px;fill:#6E6F70;}.css-115f4t{color:#6E6F70;font-size:14px;font-weight:bold;}.css-1b8uj5v{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;margin-bottom:16px;padding:0;}.css-79elbk{position:relative;}.css-16hhh7b{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;font-size:20px;height:32px;outline:none;width:32px;padding:0;}.css-fcbn8c{display:none;bottom:initial;left:initial;right:initial;top:initial;left:100%;top:calc(-8px - (14px * 1.8) - 16px - 4px);}.css-1gj7nt{color:rgba(0,0,0,0.6);font-size:14px;font-weight:bold;line-height:1.8;padding:8px 16px;}.css-154zy0m{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.87);cursor:pointer;font-size:16px;font-weight:normal;line-height:1.8;padding:4px 16px;}.css-154zy0m:hover{-webkit-text-decoration:none;text-decoration:none;background-color:#F2F2F2;}.css-yikrym{width:20px;}.css-1jqivyb{color:rgba(0,0,0,0.6);font-size:13px;}.css-1ode1bp{background-color:rgba(0,0,0,0.12);height:1px;width:100%;margin:8px 0;}.css-le4d8r{display:inline-block;vertical-align:middle;height:13px;width:13px;fill:rgba(0,0,0,0.6);}.css-1hbd3g7{height:250px;}.css-helsa7{background-color:#FFFFFF;padding:32px;margin-bottom:24px;}@media (max-width:992px){.css-helsa7{margin:0 auto 40px;}}@media (max-width:480px){.css-helsa7{margin:0 0 40px;padding:32px 16px;}}.css-8qb8m4{margin-bottom:48px;}.css-2imjyh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-he5w1s{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;width:100%;}@media (max-width:770px){.css-he5w1s{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}}.css-70qvj9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.css-3ojehk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;margin-right:4px;}.css-100alwu{display:inline-block;border-radius:50%;line-height:1;overflow:hidden;vertical-align:middle;}.css-1dtnjt5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-10ougpm{color:rgba(0,0,0,0.87);font-size:14px;font-weight:600;line-height:1.8;margin-right:4px;text-wrap:break-word;word-break:break-all;}.css-1ay9vb9{margin-right:16px;}.css-m19uds{color:rgba(0,0,0,0.6);font-size:14px;line-height:1.8;}.css-cgzq40{color:rgba(0,0,0,0.87);font-size:32px;font-weight:bold;line-height:1.4;margin-top:8px;text-wrap:break-word;word-break:break-all;}.css-1wa99t2{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(0,0,0,0.6);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:8px;}.css-1l3zk9f{color:rgba(0,0,0,0.6);font-size:20px;margin-right:8px;}.css-4czcte{margin-right:4px;color:inherit;font-size:14px;line-height:1.8;}.css-4czcte:not(:last-child)::after{content:',';margin-right:4px;}.css-1yzj1fm{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-top:32px;}.css-1uv1qiv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:transparent;border:none;color:#6E6F70;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-size:20px;height:32px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-right:16px;outline:none;padding:0;width:32px;}.css-109dbrr{background-color:#F9F9F9;border-top:1px solid rgba(0,0,0,0.12);bottom:0;box-shadow:0px 1px 4px rgba(0,0,0,0.14);display:none;height:calc(env(safe-area-inset-bottom,0px) + 56px);-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding-bottom:env(safe-area-inset-bottom);position:-webkit-sticky;position:sticky;width:100%;z-index:2000;}@media (max-width:770px){.css-109dbrr{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}.css-5jpx49{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-evenly;-webkit-justify-content:space-evenly;-ms-flex-pack:space-evenly;justify-content:space-evenly;width:100%;}.css-mnxgyc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1vlpknv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:2px solid #55C500;border-radius:50%;cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:40px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:0;width:40px;margin-right:4px;background-color:#FFFFFF;}.css-fsjkhv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;}.css-1b17vb0{color:#6E6F70;font-size:14px;font-weight:bold;margin-left:4px;}.css-7i7f4d{display:none;bottom:initial;left:initial;right:initial;top:initial;bottom:32px;right:0;}</style></head><body><div class="allWrapper"><div><div id="GlobalHeader-react-component-66ddc423-027b-45c0-a6b1-7b2065ebd876"><div class="st-Header"><div class="st-Header_container"><div class="st-Header_start"><a href="/" class="st-Header_logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 426.57 130"><circle cx="167.08" cy="21.4" r="12.28"></circle><path d="M250.81 29.66h23.48v18.9h-23.48z"></path><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z"></path><circle cx="216.33" cy="21.4" r="12.28"></circle></svg></a><div class="st-Header_communitySelector" tabindex="0"><span class="fa fa-caret-down"></span></div><div class="st-Header_dropdown"><div class="st-Header_dropdownHeading">Qiita Teams that are logged in</div><div class="st-Header_dropdownItemNote">You are not logged in to any team</div><hr class="st-Header_dropdownDivider st-Header_dropdownDivider-shrink"/><a href="https://teams-center.qiita.com/find_team" class="st-Header_dropdownItem"><span class="fa fa-fw fa-sign-in st-Header_dropdownItemIcon"></span><div>Log in to Qiita Team</div></a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Community</div><a href="/organizations" class="st-Header_dropdownItem">Organization</a><a href="/official-events/open" class="st-Header_dropdownItem">Event</a><a href="/advent-calendar" class="st-Header_dropdownItem">Advent Calendar</a><a href="https://qiitadon.com/" class="st-Header_dropdownItem" target="_blank">Qiitadon (β)</a><div class="st-Header_dropdownDivider"></div><div class="st-Header_dropdownHeading">Service</div><a href="https://jobs.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Jobs</a><a href="https://zine.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Zine</a><a href="https://blog.qiita.com/?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=header" class="st-Header_dropdownItem" target="_blank">Qiita Blog</a></div><form class="st-Header_search" action="/search" method="get"><span class="fa fa-search st-Header_searchIcon"></span><input type="search" class="st-Header_searchInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form><form class="st-Header_searchModal" action="/search" method="get"><input type="text" class="st-Header_searchModalInput" autoComplete="off" placeholder="Search" value="" name="q" required=""/></form></div><div class="st-Header_end"><div class="st-Header_searchButton"><span class="fa fa-search"></span></div><a class="st-Header_signupButton" href="/signup?redirect_to=%2Fyamachu%2Fitems%2Fdda2624abbfe4364328a">Signup</a><a class="st-Header_loginLink" href="/login?redirect_to=%2Fyamachu%2Fitems%2Fdda2624abbfe4364328a">Login</a></div><div class="st-Header_overlay"></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="GlobalHeader" data-dom-id="GlobalHeader-react-component-66ddc423-027b-45c0-a6b1-7b2065ebd876">{"unreadNotificationsCount":null,"realms":[{"humanName":"Qiita","isCurrentRealm":true,"isQiita":true,"isQiitaTeam":false,"loggedInUser":null,"teamId":null,"url":"https://qiita.com/"}],"teamFindUrl":"https://teams-center.qiita.com/find_team","isTeamOnlyUser":null,"currentUser":null}</script>
      
</div><div class="st-HeaderAlert st-HeaderAlert-warning"><div class="st-HeaderAlert_body"></div></div><script type="application/ld+json">{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"/","name":"Qiita"}},{"@type":"ListItem","position":2,"item":{"@id":"/tags/csharp","name":"C#"}}]}</script><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","datePublished":"2019-12-27T20:45:57.000+09:00","dateModified":"2020-11-13T19:39:49.000+09:00","headline":"Azure Cognitive ServicesのSpeech to Textで書き起こしをしてみよう","image":"https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-4.0.0\u0026w=1200\u0026mark64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTM4MCZ0eHQ2ND1RWHAxY21VZ1EyOW5ibWwwYVhabElGTmxjblpwWTJWejQ0R3VVM0JsWldOb0lIUnZJRlJsZUhUamdhZm1tN2pqZ1kzb3RiZmpnWlBqZ1pmamdwTGpnWmZqZ2FiamdiX2pnb2pqZ1lZJnR4dC1jb2xvcj0lMjMzMzMmdHh0LWZvbnQ9SGlyYWdpbm8lMjBTYW5zJTIwVzYmdHh0LXNpemU9NTQmdHh0LWNsaXA9ZWxsaXBzaXMmdHh0LWFsaWduPWNlbnRlciUyQ21pZGRsZSZzPWYxNTk3NzgyZDdmNGVlNzhmODkwMjE0NGU3ZDdkNTY5\u0026mark-align=center%2Cmiddle\u0026blend64=aHR0cHM6Ly9xaWl0YS11c2VyLWNvbnRlbnRzLmltZ2l4Lm5ldC9-dGV4dD9peGxpYj1yYi00LjAuMCZ3PTg0MCZoPTUwMCZ0eHQ2ND1RSGxoYldGamFIVSZ0eHQtY29sb3I9JTIzMzMzJnR4dC1mb250PUhpcmFnaW5vJTIwU2FucyUyMFc2JnR4dC1zaXplPTQ1JnR4dC1hbGlnbj1yaWdodCUyQ2JvdHRvbSZzPTEyNDc3NjYxZGQ2ODdiYjE3YmRkZGE1MDA5ZTA3MDVj\u0026blend-align=center%2Cmiddle\u0026blend-mode=normal\u0026s=f85358d1deffce1e0bbb115652ff577c","mainEntityOfPage":"https://qiita.com/yamachu/items/dda2624abbfe4364328a","author":{"@type":"Person","address":"","email":null,"identifier":"yamachu","name":"yamachu","image":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F104085%2Fprofile-images%2F1504185427?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=cb074881c1f31aff91534ee5280be305","url":"https://qiita.com/yamachu","description":"","memberOf":[]},"publisher":{"@type":"Organization","name":"Qiita","logo":{"@type":"ImageObject","url":"//cdn.qiita.com/assets/public/qiita-logo-c39ded593afa388e2e1ba435b110554e.png"}}}</script><style type="text/css">.wb-CampaignLink {
  background-color: #333333;
  width: 100%;
}

.wb-CampaignLink_container {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  max-width: 1100px;
  margin: 0 auto;
  font-size: 13px;
  padding: 0.8em;
}
.wb-CampaignLink_container > a {
  color: #fff;
}

.wb-CampaignLink_container > a:hover {
  text-decoration: underline;
}</style><div class="wb-CampaignLink"><div class="wb-CampaignLink_container"><a target="_blank" id="header_text_message_1" href="https://increments.connpass.com/event/211948/">「AirPods Pro」を抽選でプレゼント！Qiita エンジニアフェスタ 2021 Online Meetupを9/9(木)に開催</a><a target="_blank" id="header_text_message_2" href="https://increments.connpass.com/event/211948/">詳しくはこちら</a></div><script>td.trackEvent(
  'front_events',
  {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"yamachu","type":"items","id":"dda2624abbfe4364328a"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Show","data":{"message":"「AirPods Pro」を抽選でプレゼント！Qiita エンジニアフェスタ 2021 Online Meetupを9/9(木)に開催","url":"https://increments.connpass.com/event/211948/","sub_message":"詳しくはこちら"}}
)</script><script>document.getElementById('header_text_message_1').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"yamachu","type":"items","id":"dda2624abbfe4364328a"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_1","message":"「AirPods Pro」を抽選でプレゼント！Qiita エンジニアフェスタ 2021 Online Meetupを9/9(木)に開催","url":"https://increments.connpass.com/event/211948/","sub_message":"詳しくはこちら"}}
  )
})</script><script>document.getElementById('header_text_message_2').addEventListener('click', function() {
  td.trackEvent(
    'front_events',
    {"query_parameters":{},"path_parameters":{"controller":"public/items","action":"show","user_id":"yamachu","type":"items","id":"dda2624abbfe4364328a"},"user_id":null,"event_category":"Header Text Ads Banner","event_action":"Click","data":{"index":0,"pos_id":"header_text_message_2","message":"「AirPods Pro」を抽選でプレゼント！Qiita エンジニアフェスタ 2021 Online Meetupを9/9(木)に開催","url":"https://increments.connpass.com/event/211948/","sub_message":"詳しくはこちら"}}
  )
})</script></div><script type="application/json" id="js-react-on-rails-context">{"railsEnv":"production","inMailer":false,"i18nLocale":"en","i18nDefaultLocale":"en","href":"https://qiita.com/yamachu/items/dda2624abbfe4364328a","location":"/yamachu/items/dda2624abbfe4364328a","scheme":"https","host":"qiita.com","port":null,"pathname":"/yamachu/items/dda2624abbfe4364328a","search":null,"httpAcceptLanguage":null,"actionPath":"public/items#show","settings":{"analyticsTrackingId":"UA-24675221-12","assetsMap":{},"csrfToken":"AT/DcF6lanWADrmoPKtSJrI9cIeKfEsDomEpWkS5srFZU2Id3inKaY+tyxcPDWLvf7a+Yefc/8s0Lws4FTT1Lw==","locale":"en"},"currentUser":null,"isLoggedIn":false,"recaptchaSiteKey":"6LfNkiQTAAAAAM3UGnSquBy2akTITGNMO_QDxMw6","serverSide":false}</script>
<div id="PersonalArticlePage-react-component-13bc2162-4fde-4e31-b41c-3b26afa34b40"><div class="p-items_wrapper"><div class=" css-17jxvjw"><div class="css-11t2ec1"><div class="css-1dvr2p8"><button class=" css-18lkoru"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/yamachu/items/dda2624abbfe4364328a/likers" class="css-1iupg5d">15</a></div><div class="css-ijvq0v"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-115f4t">11</span></div><div class="css-1b8uj5v"><span class="fa fa-twitter"></span></div><div class="css-1b8uj5v"><span class="fa fa-facebook"></span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-fcbn8c"><div class="css-1gj7nt">Improve article</div><a href="/drafts/dda2624abbfe4364328a/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/yamachu/items/dda2624abbfe4364328a/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/yamachu/items/dda2624abbfe4364328a/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/yamachu/items/dda2624abbfe4364328a/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/yamachu/items/dda2624abbfe4364328a.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div><div class="p-items_options"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_toc"><div class="mt-2"><div class="css-1hbd3g7"></div></div></div><div class="p-items_main"><div class="css-helsa7"><div class="css-8qb8m4"><div class="it-AdcalRibbon"><span><a href="/advent-calendar/2019/azure-ai" class="it-AdcalRibbon_title">Azure AI<!-- --> Advent Calendar<!-- --> <!-- -->2019</a>Day 25</span></div><div class="css-2imjyh"><div class="css-he5w1s"><div class="css-70qvj9"><div class="css-3ojehk"><a href="/yamachu"><img class="css-100alwu eyfquo10" src="https://qiita-image-store.s3.amazonaws.com/0/104085/profile-images/1504185427" width="24" height="24" loading="lazy"/></a></div><div class="css-1dtnjt5"><a href="/yamachu" class="css-10ougpm">@<!-- -->yamachu</a><div class="css-1ay9vb9"><span><meta content="2019-12-27T11:45:57Z"/><time dateTime="2020-11-13T10:39:49Z" class="css-m19uds">updated at 2020-11-13</time></span></div></div></div></div></div><h1 class="css-cgzq40">Azure Cognitive ServicesのSpeech to Textで書き起こしをしてみよう</h1><div class="css-1wa99t2"><span class="fa fa-tags mr-1of2 css-1l3zk9f" aria-hidden="true"></span><a href="/tags/csharp" class="css-4czcte">C#</a><a href="/tags/azure" class="css-4czcte">Azure</a><a href="/tags/cognitiveservices" class="css-4czcte">CognitiveServices</a><a href="/tags/speechtotext" class="css-4czcte">SpeechToText</a></div></div><section class="it-MdContent"><div id="personal-public-article-body"><div><p>メリークリスマス！（遅刻）</p>

<p><a href="https://qiita.com/advent-calendar/2019/azure-ai">Azure AI Advent Calendar 2019</a> 25日目のエントリーです。</p>

<p>みなさんクリスマスイブからクリスマスにかけていかがお過ごしでしたか？<br>
私は本記事を書くために進捗の6時間を過ごして寝不足です。</p>

<p>さて、今回はAzure Cognitive Servicesの中の一つである、Speech ServiceのSpeech to Textの使い方や使ってみた結果などを紹介していきます。<br>
実際に動かしてみたコードも載せるので、試してみたいけど書くの面倒だし…という方も安心してお読み下さい。</p>

<p><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/speech-to-text?WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">音声変換 - Speech Service - Azure Cognitive Services | Microsoft Docs</a></p>

<h2>
<span id="用意するもの" class="fragment"></span><a href="#%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B%E3%82%82%E3%81%AE"><i class="fa fa-link"></i></a>用意するもの</h2>

<ul>
<li>Azureのサブスクリプション</li>
<li>.NET Core 3.0のアプリケーションがビルド出来る環境</li>
<li>書き起こししたい音声</li>
</ul>

<h2>
<span id="始めてみよう" class="fragment"></span><a href="#%E5%A7%8B%E3%82%81%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86"><i class="fa fa-link"></i></a>始めてみよう</h2>

<h3>
<span id="cognitive-servicesのプロジェクトを作る" class="fragment"></span><a href="#cognitive-services%E3%81%AE%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%82%92%E4%BD%9C%E3%82%8B"><i class="fa fa-link"></i></a>Cognitive Servicesのプロジェクトを作る</h3>

<p>まずはCognitive Servicesのディレクトリを開きましょう。<br>
Azure PortalのSearchフォームに<code>cognitive services</code>と打ち込んで、ディレクトリに移動しましょう。</p>

<p><a href="https://camo.qiitausercontent.com/18e698115a2477b98ee2395ecfd452a24c0b9e97/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f31303530336636632d623066332d326331372d666134332d3065653737626330313135622e706e67" target="_blank" rel="nofollow noopener"><img width="486" alt="search-cognitive-services.png" src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F10503f6c-b0f3-2c17-fa43-0ee77bc0115b.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=8456c1453a853e4ba7bf0c6583cd1001" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/10503f6c-b0f3-2c17-fa43-0ee77bc0115b.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F10503f6c-b0f3-2c17-fa43-0ee77bc0115b.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=6108b0b42fd5dd87b7400823a90ae7df 1x" loading="lazy"></a></p>

<p>Cognitive Servicesのディレクトリに移動したら、追加ボタンを押してどのServiceを使うか指定します。<br>
日本リージョンで使っている場合<code>Speech to Text</code>とかで検索をかけると他のMarketplaceのServiceが引っかかってしまいます。<br>
日本リージョンで使っている場合は<code>音声</code>と調べると目的のServiceが出てきます。</p>

<p><a href="https://camo.qiitausercontent.com/0efea3341918c94df67115b7194df430f5adfbce/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f64613930336537652d376638642d363830302d616336642d6662386630376534323162312e706e67" target="_blank" rel="nofollow noopener"><img width="385" alt="correct-speech-services.png" src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2Fda903e7e-7f8d-6800-ac6d-fb8f07e421b1.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=7c62a9fd6b551673f908fdb84e801dfa" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/da903e7e-7f8d-6800-ac6d-fb8f07e421b1.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2Fda903e7e-7f8d-6800-ac6d-fb8f07e421b1.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=222813281793be3a352a3a0aeec82754 1x" loading="lazy"></a></p>

<p>作成を押して適当な名前をつけます。<br>
お試しで使ってみたい場合はPricing tierをF0にすると良いでしょう（画像では既にF0 tierを使っているので選択出来ないように鳴っています…）</p>

<p><a href="https://camo.qiitausercontent.com/a1a8f930a2189baeaf95f8266b8bf1f2e53fb626/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f35373234346262352d393235622d373165382d346432312d3461353263386430653834362e706e67" target="_blank" rel="nofollow noopener"><img width="574" alt="project-config-sample.png" src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F57244bb5-925b-71e8-4d21-4a52c8d0e846.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=b849114f76747209b170e4a580a42441" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/57244bb5-925b-71e8-4d21-4a52c8d0e846.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F57244bb5-925b-71e8-4d21-4a52c8d0e846.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=e73fd03c52999241b07c717ae8a3b962 1x" loading="lazy"></a></p>

<p>設定を済ませCreateを押すとプロジェクトが作成されます。<br>
遷移先のページで暫く待つと準備が出来るのでそれまでコーヒーでも飲んで待ちましょう。</p>

<p>準備が出来たあとサイドペインのQuick startを押すとどうすれば使うことが出来るのかが表示されます。<br>
本記事紹介するフローじゃない場合はこれを見ていい感じに頑張りましょう。</p>

<p>今回サンプルで紹介するプロジェクトを使う場合は</p>

<p><a href="https://camo.qiitausercontent.com/623e2a0367197a36f5b4a28651e5155e2301a6fa/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f35306137323930342d373934652d373961332d313030312d3664636332373637613361662e706e67" target="_blank" rel="nofollow noopener"><img width="933" alt="key-endpoint.png" src="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F50a72904-794e-79a3-1001-6dcc2767a3af.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;s=250bba9b300154546cebfd70d77822bf" data-canonical-src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/50a72904-794e-79a3-1001-6dcc2767a3af.png" srcset="https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F50a72904-794e-79a3-1001-6dcc2767a3af.png?ixlib=rb-4.0.0&amp;auto=format&amp;gif-q=60&amp;q=75&amp;w=1400&amp;fit=max&amp;s=c30e68a07134433c6b7e6b0f5977f1b5 1x" loading="lazy"></a></p>

<p>上記の画像にある<code>Key1</code>と<code>Endpoint</code>は後々使うのでどこかしらにメモしておきましょう。</p>

<p>以上でプロジェクト自体の容易は完了です。</p>

<h3>
<span id="アプリケーションを作る" class="fragment"></span><a href="#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E4%BD%9C%E3%82%8B"><i class="fa fa-link"></i></a>アプリケーションを作る</h3>

<p>とりあえず動くサンプルコードをこちらに用意しました。<br>
コード書きたくない、けど試してみたいという方はこちらをビルドして試してみて下さい。</p>

<p><qiita-embed-ogp src="https://github.com/yamachu/SpeechRecogSample"></qiita-embed-ogp></p>

<p>こちらのコードを使わない場合、Quick startに沿って進めれば大体いい感じになります。<br>
自分の目的に合わせてやりたいなぁという方は</p>

<p><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?tabs=linux&amp;pivots=programming-language-csharp&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">クイック スタート:オーディオ ファイルから音声を認識する - Speech サービス - Azure Cognitive Services | Microsoft Docs</a></p>

<p>を見て頑張ってみてください。</p>

<p>今回は自分の用意したサンプルコードと上記のクイックスタートを照らし合わせて解説していきます。<br>
上記のクイックスタートでは15秒未満の音声のみを対象としたものですが、15秒以上の音声を対象とすることも考え連続音声認識方式で行っています。</p>

<ol>
<li>SpeechConfigを生成する</li>
</ol>

<p><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp&amp;tabs=linux#create-a-speech-configuration&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">SpeechConfigを作成する - Speech サービス - Azure Cognitive Services | Microsoft Docs</a></p>

<div class="code-frame" data-lang="cs"><div class="highlight"><pre class="with-code"><code><span class="k">static</span> <span class="n">SpeechConfig</span> <span class="nf">InitializeSpeechConfig</span><span class="p">(</span><span class="kt">string</span> <span class="n">endpoint</span><span class="p">,</span> <span class="kt">string</span> <span class="n">subscriptionKey</span><span class="p">)</span> <span class="p">=&gt;</span>
    <span class="n">SpeechConfig</span><span class="p">.</span><span class="nf">FromEndpoint</span><span class="p">(</span><span class="k">new</span> <span class="nf">Uri</span><span class="p">(</span><span class="n">endpoint</span><span class="p">),</span> <span class="n">subscriptionKey</span><span class="p">).</span><span class="nf">Also</span><span class="p">(</span><span class="n">m</span> <span class="p">=&gt;</span>
    <span class="p">{</span>
        <span class="n">m</span><span class="p">.</span><span class="n">SpeechRecognitionLanguage</span> <span class="p">=</span> <span class="s">"ja-JP"</span><span class="p">;</span> <span class="c1">// 日本語の音声を認識したいので設定</span>
        <span class="n">m</span><span class="p">.</span><span class="n">OutputFormat</span> <span class="p">=</span> <span class="n">OutputFormat</span><span class="p">.</span><span class="n">Detailed</span><span class="p">;</span> <span class="c1">// 必要はないが、信頼度などのパラメータが欲しい場合はDetailedに設定する</span>
    <span class="p">});</span>
</code></pre></div></div>

<p>普段見ない<code>Also</code>などが出ていますが、これは拡張メソッドで見慣れている形に書き直すと</p>

<div class="code-frame" data-lang="cs"><div class="highlight"><pre class="with-code"><code><span class="kt">var</span> <span class="n">config</span> <span class="p">=</span> <span class="n">SpeechConfig</span><span class="p">.</span><span class="nf">FromEndpoint</span><span class="p">(</span><span class="k">new</span> <span class="nf">Uri</span><span class="p">(</span><span class="n">endpoint</span><span class="p">),</span> <span class="n">subscriptionKey</span><span class="p">);</span>
<span class="n">config</span><span class="p">.</span><span class="n">SpeechRecognitionLanguage</span> <span class="p">=</span> <span class="s">"ja-JP"</span><span class="p">;</span>
<span class="n">config</span><span class="p">.</span><span class="n">OutputFormat</span> <span class="p">=</span> <span class="n">OutputFormat</span><span class="p">.</span><span class="n">Detailed</span><span class="p">;</span>
<span class="k">return</span> <span class="n">config</span><span class="p">;</span>
</code></pre></div></div>

<p>と同等です。<br>
いい感じに読み替えて下さい。</p>

<p>ここの<code>endpoint</code>と<code>subscriptionKey</code>は前節でメモをした<code>Endpoint</code>と<code>key1</code>が対応しています。</p>

<ol>
<li>AudioConfigを作成し、認識結果を取得するコールバックを設定する</li>
</ol>

<p><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp&amp;tabs=linux#create-an-audio-configuration&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">AudioConfigを作成する - Speech サービス - Azure Cognitive Services | Microsoft Docs</a><br>
<a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp&amp;tabs=linux#display-the-recognition-results-or-errors&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">認識結果 (またはエラー) を表示する - Speech サービス - Azure Cognitive Services | Microsoft Docs</a></p>

<div class="code-frame" data-lang="cs"><div class="highlight"><pre class="with-code"><code><span class="k">using</span> <span class="nn">var</span> <span class="n">audioConfig</span> <span class="p">=</span> <span class="n">AudioConfig</span><span class="p">.</span><span class="nf">FromWavFileInput</span><span class="p">(</span><span class="n">f</span><span class="p">);</span>
<span class="k">using</span> <span class="nn">var</span> <span class="n">recognizer</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">SpeechRecognizer</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">audioConfig</span><span class="p">).</span><span class="nf">Also</span><span class="p">(</span><span class="n">r</span> <span class="p">=&gt;</span>
<span class="p">{</span>
    <span class="c1">// e is SpeechRecognitionEventArgs</span>
    <span class="c1">// refs: https://docs.microsoft.com/ja-jp/dotnet/api/microsoft.cognitiveservices.speech.speechrecognitioneventargs?view=azure-dotnet</span>
    <span class="n">r</span><span class="p">.</span><span class="n">Recognized</span> <span class="p">+=</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span> <span class="p">=&gt;</span> <span class="n">e</span><span class="p">.</span><span class="n">Result</span><span class="p">.</span><span class="nf">Also</span><span class="p">(</span><span class="n">result</span> <span class="p">=&gt;</span>
    <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">Reason</span> <span class="p">==</span> <span class="n">ResultReason</span><span class="p">.</span><span class="n">RecognizedSpeech</span><span class="p">)</span>
        <span class="p">{</span>
            <span class="n">resultSubject</span><span class="p">.</span><span class="nf">OnNext</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="nf">Best</span><span class="p">().</span><span class="nf">FirstOrDefault</span><span class="p">().</span><span class="nf">Let</span><span class="p">(</span><span class="n">r</span> <span class="p">=&gt;</span> <span class="k">new</span> <span class="nf">RecognitionResult</span><span class="p">()</span>
            <span class="p">{</span>
                <span class="n">File</span> <span class="p">=</span> <span class="n">f</span><span class="p">,</span>
                <span class="n">Result</span> <span class="p">=</span> <span class="n">r</span><span class="p">.</span><span class="n">Text</span><span class="p">,</span>
                <span class="n">Confidence</span> <span class="p">=</span> <span class="n">r</span><span class="p">.</span><span class="n">Confidence</span><span class="p">,</span>
            <span class="p">}));</span>
        <span class="p">}</span>
    <span class="p">});</span>

    <span class="n">r</span><span class="p">.</span><span class="n">SessionStopped</span> <span class="p">+=</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">__</span><span class="p">)</span> <span class="p">=&gt;</span> <span class="n">recognitionRunningSubject</span><span class="p">.</span><span class="nf">OnNext</span><span class="p">(</span><span class="k">true</span><span class="p">);</span>
<span class="p">});</span>
</code></pre></div></div>

<p>今回のコードでは、認識したいファイル一つごとに<code>AudioConfig</code>と<code>SpeechRecognizer</code>を生成しています。<br>
<code>SpeechRecognizer.Recognized</code>のコールバックでは認識結果を取得することが出来ます。<br>
今回は認識結果と、その認識結果の信頼度を出力しています。</p>

<ol>
<li>語句を認識する</li>
</ol>

<p><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp&amp;tabs=linux#recognize-a-phrase&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">語句を認識する - Speech サービス - Azure Cognitive Services | Microsoft Docs</a></p>

<p>上記リンクでは<a href="https://docs.microsoft.com/ja-jp/dotnet/api/microsoft.cognitiveservices.speech.speechrecognizer.recognizeonceasync?view=azure-dotnet&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">RecognizeOnceAsync</a>メソッドを使っています。<br>
こちらのメソッドだとドキュメントにあるように</p>

<blockquote>
<p>Starts speech recognition, and returns after a single utterance is recognized. The end of a single utterance is determined by listening for silence at the end or until a maximum of 15 seconds of audio is processed. </p>
</blockquote>

<p>最大15秒の無音を含まないような単一発話をターゲットとしているので、少し長めの音声には適していません。</p>

<p>そのため、本サンプルでは<a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.speechrecognizer.startcontinuousrecognitionasync?view=azure-dotnet&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">StartContinuousRecognitionAsync</a>を使用しました。</p>

<div class="code-frame" data-lang="cs"><div class="highlight"><pre class="with-code"><code><span class="k">await</span> <span class="n">recognizer</span><span class="p">.</span><span class="nf">StartContinuousRecognitionAsync</span><span class="p">().</span><span class="nf">ConfigureAwait</span><span class="p">(</span><span class="k">false</span><span class="p">);</span>

<span class="k">while</span> <span class="p">(!</span><span class="n">recognitionRunningSubject</span><span class="p">.</span><span class="n">Value</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">await</span> <span class="n">Task</span><span class="p">.</span><span class="nf">Delay</span><span class="p">(</span><span class="m">200</span><span class="p">);</span> <span class="c1">// 何秒ごとにフラグが変わるかのポーリングの秒数なのでお好きにどうぞ</span>
<span class="p">}</span>

<span class="k">await</span> <span class="n">recognizer</span><span class="p">.</span><span class="nf">StopContinuousRecognitionAsync</span><span class="p">().</span><span class="nf">ConfigureAwait</span><span class="p">(</span><span class="k">false</span><span class="p">);</span>
</code></pre></div></div>

<p>2.の<code>SessionStopped</code>で入力した音声ファイルの認識が終了したかが取得できるので、そこのイベントの結果を見て、それが起こるまでwhileループで待っている、みたいな漢字のコードになっています（いい感じに書けなかったので誰かPRお待ちしておりますｗ）。</p>

<p>以上のコードを使用することで認識をスタートすることが出来ます。</p>

<h3>
<span id="音声を用意する" class="fragment"></span><a href="#%E9%9F%B3%E5%A3%B0%E3%82%92%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B"><i class="fa fa-link"></i></a>音声を用意する</h3>

<p>前節でファイルを認識する準備ができました。<br>
それでは実際に音声を認識してみましょう。</p>

<p>今回は話者数が少なく、BGMも無い音声を認識してみます。<br>
題材としたのはよく聞いている<a href="https://ajito.fm/" rel="nofollow noopener" target="_blank">ajitofm</a>の<a href="https://ajito.fm/54/" rel="nofollow noopener" target="_blank">vol.54</a>を使用してみました。</p>

<p>本実験に関して音声の使用を快諾してくださった権利者の方々に感謝いたします。</p>

<p>Azure Cognitive Services Speech Services Speech to Textでは16bitの8or16kHzのwavファイルが入力としてサポートされています。</p>

<p><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp&amp;tabs=linux#supported-audio-input-format&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">サポートされるオーディオ入力の形式 - Speech サービス - Azure Cognitive Services | Microsoft Docs</a></p>

<p>今回の対象音声はmp3でサポートされているフォーマットと合致しません。<br>
今回は<a href="http://sox.sourceforge.net/" rel="nofollow noopener" target="_blank">SoX（Sound eXchange）</a>を使って対象の音声に変換します。</p>

<p>Macであればbrewで入れることが出来ます。</p>

<p>使い方はhelpなどを見て欲しいのですが、</p>

<div class="code-frame" data-lang="sh"><div class="highlight"><pre class="with-code"><code><span class="nv">$ </span>sox target.mp3 <span class="nt">-r</span> 16000 target.wav
</code></pre></div></div>

<p>みたいな感じで、target.mp3をtarget.wavに16kHzにダウンサンプルして変換することが出来ます。<br>
SoX以外でも同様の処理は可能なのでお好きなアプリケーションをお使い下さい。</p>

<p>さて、これでフォーマットに合致した音声が生成することが出来ました。</p>

<p>これでもうCognitive Servicesを使って音声認識をすることは出来るのですが、オプショナルとして無音区間で区切った音声を以上のファイルから作ってみたいと思います。</p>

<p>無音区間で区切ることで、音声と書き起こしの対応が付けやすいのと、今後別のサービスを使用する時に便利になったりします（後述）。</p>

<p>この無音区間での分割には<a href="https://github.com/julius-speech/julius/blob/master/adintool/README.ja.md" rel="nofollow noopener" target="_blank">Juliusのadintool</a>を使用しました。<br>
Juliusも音声認識を行うためのToolkitなので、興味のある方はぜひ試してみて下さい。</p>

<p>adintoolはWindowsの人であれば<a href="https://github.com/julius-speech/julius/releases" rel="nofollow noopener" target="_blank">GitHub Releaseページ</a>からダウンロードすることが出来ます。<br>
MacやLinuxユーザの方はリポジトリをクローンしてビルドして手に入れましょう。</p>

<p><a href="https://julius.osdn.jp/juliusbook/ja/adintool.html" rel="nofollow noopener" target="_blank">adintoolのドキュメント</a>を読んで分割していきます。<br>
ファイル入力の場合はファイル名を標準入力で取得するので、例えば以下のようなコマンドで分割してみます。</p>

<div class="code-frame" data-lang="sh"><div class="highlight"><pre class="with-code"><code><span class="nv">$ </span><span class="nb">echo </span>target.wav| adintool <span class="nt">-in</span> file <span class="nt">-out</span> file <span class="nt">-filename</span> target_separated
</code></pre></div></div>

<p>同一ディレクトリのtarget.wavを入力に使用して、target_separated.{ここに連番}.wavと言うファイルで出力するのが上記のコマンドです。<br>
私は出力されたファイルが、オリジナルのファイルの何サンプル目か何サンプル目であるかをメモっておきたかったので、</p>

<div class="code-frame" data-lang="sh"><div class="highlight"><pre class="with-code"><code><span class="nv">$ </span><span class="nb">echo </span>target.wav| adintool <span class="nt">-in</span> file <span class="nt">-out</span> file <span class="nt">-filename</span> target_separated <span class="o">&gt;</span>&amp; /dev/null| <span class="nb">grep</span> <span class="nt">-E</span> <span class="s2">"^target_separated.*"</span>| <span class="nb">sed</span> <span class="nt">-E</span> <span class="s2">"s;(.*</span><span class="se">\.</span><span class="s2">wav):.*</span><span class="se">\[</span><span class="s2"> *([0-9]+).*- ([0-9]+).*;</span><span class="se">\1</span><span class="s2"> </span><span class="se">\2</span><span class="s2"> </span><span class="se">\3</span><span class="s2">;g"</span>
</code></pre></div></div>

<p>こんな感じにしてみました。</p>

<h3>
<span id="実際に走らせる" class="fragment"></span><a href="#%E5%AE%9F%E9%9A%9B%E3%81%AB%E8%B5%B0%E3%82%89%E3%81%9B%E3%82%8B"><i class="fa fa-link"></i></a>実際に走らせる</h3>

<p>実際に実行するのは非常に簡単です。</p>

<p><qiita-embed-ogp src="https://github.com/yamachu/SpeechRecogSample"></qiita-embed-ogp></p>

<p>を使用した方はクローンしたディレクトリで</p>

<div class="code-frame" data-lang="sh"><div class="highlight"><pre class="with-code"><code><span class="nv">$ </span>dotnet run <span class="nt">--source-dir</span><span class="o">=</span><span class="k">${</span><span class="p">認識したいwavファイルがあるディレクトリ</span><span class="k">}</span> <span class="nt">--endpoint</span><span class="o">=</span><span class="k">${</span><span class="p">メモったEndpoint</span><span class="k">}</span> <span class="nt">--subscription-key</span><span class="o">=</span><span class="k">${</span><span class="p">メモったKey1</span><span class="k">}</span> <span class="nt">--result</span><span class="o">=</span><span class="k">${</span><span class="nv">CSV</span><span class="p">で認識結果を保存したい場合はここにファイル名</span><span class="k">}</span>
</code></pre></div></div>

<p>みたいな感じで走らせます。<br>
100ファイル合計10分程度のファイルの認識で約5分でした。</p>

<p>認識結果の一部を見てみましょう</p>

<p>ajitofm54.0094.wavの11714236~11897036サンプル目</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre class="with-code"><code>結果: なんか？アメリカ滞在中に面白かった事とか、あります。ええ、クライミングシューズが安かった。全然仕事じゃなかったみたいな。
正:
S: なんか、アメリカ滞在中に面白かった事とか、あります？
K: ええ、クライミングシューズが安かった。
S: 全然仕事じゃなかったみたいな。
</code></pre></div></div>

<p>見事に認識できています。<br>
クライミングシューズっていう普段でなそうなワードも認識出来ていて素晴らしいですね。</p>

<p>しかし複数話者の発話が混じっているので大変です…これに関しては<a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speaker-recognition/home&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">Speaker Recognition API</a>が日本語対応すれば、どこの部分を誰が話しているのか認識出来そうなので、期待して待ちましょう。</p>

<p>また</p>

<p>ajitofm54.0079.wavの9774236~9844036サンプル目</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre class="with-code"><code>結果: ソースコード読みたいなと思いながら、まあまだ読んでないけど。
正:
K: ソースコード読みたいなと思いながら
S: ああー（相槌）
K: まだ読んでないけど。
</code></pre></div></div>

<p>相槌が混じってしまっていますが、Domain Specificな単語も認識しています。<br>
バッチリですね……</p>

<h2>
<span id="終わりに" class="fragment"></span><a href="#%E7%B5%82%E3%82%8F%E3%82%8A%E3%81%AB"><i class="fa fa-link"></i></a>終わりに</h2>

<p>Speech to Text APIを使うためにプログラムを書いて、実際に認識するための一連の流れを紹介しました。</p>

<p>一回認識するためのプログラムを用意してしまえば、あとは音声を用意するだけで簡単に書き起こしが出来ちゃいます。</p>

<p>今回紹介できませんでしたが（日本語対応とかしていないというのもあるけど）、認識精度を上げるために<a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/how-to-custom-speech-train-model&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">話者モデル</a>を作ったり、前述した<a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speaker-recognition/home&amp;WT.mc_id=AI-MVP-5002987" rel="nofollow noopener" target="_blank">Speaker Recognition API</a>を使用することにより、更に書き起こし業務が簡単になりそうです。</p>

<p>これらをするにはある程度ファイルを分割しておいたほうが楽なので、音声準備の段階で無音区間でファイルを分割みたいなことを推奨していました。</p>

<p>またSpeech to Textサービスはリアルタイムのマイク入力も対応しているので、後々書き起こしがしたい音声の録音時にそのまま書き起こしさせたりすることが出来ます。<br>
また話者毎の認識精度を上げるためにマイクを別々に用意して、各話者毎に録音するなどの工夫次第でどんどん使いやすくなるのでぜひチャレンジしてみて下さい。</p>

<hr>

<p>さて<a href="https://qiita.com/advent-calendar/2019/azure-ai">Azure AI Advent Calendar 2019</a>完走です！</p>

<p>面白い記事を投稿してくださった皆様、本当にありがとうございました。<br>
AzureのAI技術面白いものがまだまだたくさんあります。</p>

<p>ぜひ多くのサービスを試して、こういうことが出来そう、出来たなどの例や、ここで詰まったーこうすると良いよ、みたいな知見を投稿して良いコミュニティが生まれたらいいなと覆います。</p>

<p>来年もAzure AIをよろしくお願いいたします！（誰）</p>
</div></div></section><div class="css-1yzj1fm"><div class="css-1uv1qiv"><span class="fa fa-twitter"></span></div><div class="css-1uv1qiv"><span class="fa fa-facebook"></span></div></div><div class="apm-Content"><div class="apm-Content_title">Why not register and get more from Qiita?</div><ol class="apm-Content_list"><li>We will deliver articles that match you<div class="description">By following users and tags, you can catch up information on technical fields that you are interested in as a whole</div></li><li>you can read useful information later efficiently<div class="description">By &quot;stocking&quot; the articles you like, you can search right away</div></li><div><a class="apm-Content_help" href="https://help.qiita.com/ja/articles/qiita-login-user" target="_blank"><i class="fa fa-fw fa-arrow-circle-right"></i>What you can do with signing up</a></div></ol><a href="/signup?callback_action=login_or_signup&amp;redirect_to=%2Fyamachu%2Fitems%2Fdda2624abbfe4364328a&amp;realm=qiita" class="apm-Content_button apm-Content_button-signup">Sign up</a><a href="/login?callback_action=login_or_signup&amp;redirect_to=%2Fyamachu%2Fitems%2Fdda2624abbfe4364328a&amp;realm=qiita" class="apm-Content_button apm-Content_button-signin">Login</a></div></div><div class="css-helsa7"></div></div></div></div><div class="css-109dbrr"><div class="css-5jpx49"><div class="css-mnxgyc"><button class=" css-1vlpknv"><svg size="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="#55C500" class="css-1g4cku8 e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></button><a href="/yamachu/items/dda2624abbfe4364328a/likers" class="css-1iupg5d">15</a></div><div class="css-fsjkhv"><button class=" css-15cocm3"><svg size="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 353.02 398" color="#6E6F70" class="css-12rp90f e11v00bf0"><path d="M176.72 398c-67.52 0-130.16-29-171.84-79.69l-4.46-5.42V78.05H353v234.84l-4.45 5.42C306.88 369 244.24 398 176.72 398zm-137.2-99.34c34.17 38.37 83.78 60.25 137.2 60.25s103-21.88 137.21-60.25V117.14H39.52zM0 0h351.12v40.94H0z"></path></svg></button><span class="css-1b17vb0">11</span></div><div class="css-79elbk"><button class="css-16hhh7b"><i class="fa fa-ellipsis-h"></i></button><div class="css-7i7f4d"><div class="css-1gj7nt">Improve article</div><a href="/drafts/dda2624abbfe4364328a/edit" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-code-fork css-1jqivyb" aria-hidden="true"></i></span>Send edit request</a><div class="css-1ode1bp"></div><div class="css-1gj7nt">Article information</div><a href="/yamachu/items/dda2624abbfe4364328a/revisions" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-history css-1jqivyb" aria-hidden="true"></i></span>Revisions</a><a href="/yamachu/items/dda2624abbfe4364328a/patches" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-inbox css-1jqivyb" aria-hidden="true"></i></span>Edit Requests</a><a href="/yamachu/items/dda2624abbfe4364328a/likers" class="css-154zy0m"><span class="css-yikrym"><svg size="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 392.81 429" color="rgba(0, 0, 0, 0.6)" class="css-le4d8r e31pr5q0"><path d="M14.19 5.4h53.86v149.45h90.05v44.87H14.19zM288.4 93.77h100.79q1.29 25-5.66 45.39a96.79 96.79 0 01-20.33 34.89 92 92 0 01-32.13 22.45 104 104 0 01-40.95 7.93 109.71 109.71 0 01-76-29.92 104.05 104.05 0 01-23-32.56 95.46 95.46 0 01-8.47-39.88 94.78 94.78 0 018.47-39.87 104.38 104.38 0 0123-32.42A107.71 107.71 0 01248.23 8a110.79 110.79 0 01118.48 22.49l-35.07 35.08a51.25 51.25 0 00-17.75-15 52.83 52.83 0 00-44.67-1.23 52.92 52.92 0 00-17 12 57.07 57.07 0 00-11.45 18.11 60 60 0 00-4.23 22.77 60 60 0 004.23 22.68 56.57 56.57 0 0011.45 18.19 52.62 52.62 0 0017 12 50.5 50.5 0 0020.9 4.36q20.19 0 31.07-7.51a35.75 35.75 0 0014.46-20.55h-47.39zM51.29 279.55H0v-44.86h156v44.86h-51.13V429H51.29zM283.36 381.71l-41.72-62V429h-53.86V234.69h47.47L290 312l55.9-77.29h46.9V429h-53.86V320.27l-42.43 61.44z"></path></svg></span>Show all likers</a><a href="/yamachu/items/dda2624abbfe4364328a.md" class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-file-text-o css-1jqivyb" aria-hidden="true"></i></span>Show article in Markdown</a><div class="css-1ode1bp"></div><div class="css-154zy0m"><span class="css-yikrym"><i class="fa fa-flag css-1jqivyb" aria-hidden="true"></i></span>Report article</div></div><div class="st-Modal"><div class="st-Modal_backdrop"></div><div class="st-Modal_body"><form><div class="st-Form"><span class="st-Form_label">Help us understand the problem. What is going on with this article?</span></div><div class="st-Form"><label><input type="radio" name="reason" value="illegal" required=""/>It&#x27;s illegal (copyright infringement, privacy infringement, libel, etc.)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="inappropriate_content" required=""/>It&#x27;s socially inappropriate (offensive to public order and morals)</label></div><div class="st-Form"><label><input type="radio" name="reason" value="advertising" required=""/>It&#x27;s advertising</label></div><div class="st-Form"><label><input type="radio" name="reason" value="spam" required=""/>It&#x27;s spam</label></div><div class="st-Form"><label><input type="radio" name="reason" value="guideline_violation" required=""/>Other than the above, but not suitable for the Qiita community (violation of guidelines)</label></div><div class="st-Form st-Form-right"><input type="submit" class="st-Form_submit" value="Submit"/></div></form></div></div></div></div></div></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="PersonalArticlePage" data-dom-id="PersonalArticlePage-react-component-13bc2162-4fde-4e31-b41c-3b26afa34b40">{"authorAnalyticsTrackingId":null,"organizationAnalyticsTrackingId":null}</script>
      
<footer id="globalFooter" class="st-Footer"><div class="st-Footer_container"><div class="st-Footer_start"><div class="st-Footer_logo"><svg viewbox="0 0 426.57 130" xmlns="http://www.w3.org/2000/svg"><circle cx="167.08" cy="21.4" r="12.28" /><path d="M250.81 29.66h23.48v18.9h-23.48z" /><path d="M300.76 105.26a22.23 22.23 0 01-6.26-.86 12.68 12.68 0 01-5.17-3 14.41 14.41 0 01-3.56-5.76 28 28 0 01-1.3-9.22V48.56h29.61v-18.9h-29.52V3.29h-20.17v83.34q0 11.16 2.83 18.27a27.71 27.71 0 007.7 11.2 26.86 26.86 0 0011.43 5.62 47.56 47.56 0 0012.34 1.53h15.16v-18zM0 61.7a58.6 58.6 0 015-24.21A62.26 62.26 0 0118.73 17.9 63.72 63.72 0 0139 4.78 64.93 64.93 0 0164 0a65 65 0 0124.85 4.78 64.24 64.24 0 0120.38 13.12A62 62 0 01123 37.49a58.6 58.6 0 015 24.21 58.34 58.34 0 01-4 21.46 62.8 62.8 0 01-10.91 18.16l11.1 11.1a10.3 10.3 0 010 14.52 10.29 10.29 0 01-14.64 0l-12.22-12.41a65 65 0 01-15.78 6.65 66.32 66.32 0 01-17.55 2.3 64.63 64.63 0 01-45.23-18A62.82 62.82 0 015 85.81 58.3 58.3 0 010 61.7zm21.64.08a43.13 43.13 0 0012.42 30.63 42.23 42.23 0 0013.43 9.09A41.31 41.31 0 0064 104.8a42 42 0 0030-12.39 42.37 42.37 0 009-13.64 43.43 43.43 0 003.3-17 43.77 43.77 0 00-3.3-17A41.7 41.7 0 0080.55 22 41.78 41.78 0 0064 18.68 41.31 41.31 0 0047.49 22a42.37 42.37 0 00-13.43 9.08 43.37 43.37 0 00-12.42 30.7zM331.89 78a47.59 47.59 0 013.3-17.73 43.22 43.22 0 019.34-14.47A44.25 44.25 0 01359 36a47.82 47.82 0 0118.81-3.58 42.72 42.72 0 019.26 1 46.5 46.5 0 018.22 2.58 40 40 0 017 3.84 44.39 44.39 0 015.71 4.63l1.22-9.47h17.35v85.83h-17.35l-1.17-9.42a42.54 42.54 0 01-5.84 4.67 43.11 43.11 0 01-7 3.79 44.86 44.86 0 01-8.17 2.59 43 43 0 01-9.22 1A47.94 47.94 0 01359 119.9a43.3 43.3 0 01-14.47-9.71 44.17 44.17 0 01-9.34-14.47 47 47 0 01-3.3-17.72zm20.27-.08a29.16 29.16 0 002.17 11.34 27 27 0 005.92 8.88 26.69 26.69 0 008.76 5.76 29.19 29.19 0 0021.44 0 26.11 26.11 0 008.72-5.76 27.57 27.57 0 005.88-8.84 29 29 0 002.16-11.38 28.62 28.62 0 00-2.16-11.22 26.57 26.57 0 00-5.93-8.8 27.68 27.68 0 00-19.51-7.9 28.29 28.29 0 00-10.77 2.05 26.19 26.19 0 00-8.71 5.75 27.08 27.08 0 00-5.84 8.8 28.94 28.94 0 00-2.13 11.31zm-194.97-30.5h19.78v73.54h-19.78zm49.25 0h19.78v73.54h-19.78z" /><circle cx="216.33" cy="21.4" r="12.28" /></svg></div><div class="st-Footer_catchcopy">How developers code is here.</div><div class="st-Footer_socials"><a class="fa fa-twitter" href="https://twitter.com/qiita"></a><a class="fa fa-facebook-square" href="https://www.facebook.com/qiita/"></a></div></div><div class="st-Footer_end"><div class="st-Footer_qiita"><div class="st-Footer_label">Qiita</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="/about">About</a><a href="/terms">Terms</a><a href="/privacy">Privacy</a><a target="_blank" href="http://help.qiita.com/ja/articles/qiita-community-guideline">Guideline</a><a target="_blank" href="https://help.qiita.com/ja/articles/others-brand-guideline">Design Guideline</a></div><div class="st-Footer_column"><a href="/release-notes">Release</a><a href="/api/v2/docs">API</a><a href="/feedback/new">ご意見</a><a href="https://help.qiita.com">Help</a><a target="_blank" href="https://qiita.com/ads?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Advertisement</a></div></div></div><div class="st-Footer_increments"><div class="st-Footer_label">Increments</div><div class="st-Footer_list"><div class="st-Footer_column"><a href="https://increments.co.jp/company/">About</a><a href="https://increments.co.jp/jobs/">採用情報</a><a href="https://blog.qiita.com">Blog</a></div><div class="st-Footer_column"><a href="https://teams.qiita.com/">Qiita Team</a><a href="https://jobs.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Jobs</a><a href="https://zine.qiita.com?utm_source=qiita&amp;utm_medium=referral&amp;utm_content=footer">Qiita Zine</a></div></div></div></div></div><div class="st-Footer_copyright">© 2011-2021 Increments Inc.</div></footer><div id="Snackbar-react-component-d8a9692c-d58f-49f8-ac78-6dba7a465392"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="Snackbar" data-dom-id="Snackbar-react-component-d8a9692c-d58f-49f8-ac78-6dba7a465392">{}</script>
      
<div id="LoginModal-react-component-655eb152-ab90-4374-8ad3-7c5935e920fc"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="LoginModal" data-dom-id="LoginModal-react-component-655eb152-ab90-4374-8ad3-7c5935e920fc">{}</script>
      
<div id="StockModal-react-component-13dfe848-ef85-450b-acb9-db06ce73ad37"></div>
      <script type="application/json" class="js-react-on-rails-component" data-component-name="StockModal" data-dom-id="StockModal-react-component-13dfe848-ef85-450b-acb9-db06ce73ad37">{}</script>
      
</div><div id="dataContainer" style="display: none;" data-config="{&quot;actionPath&quot;:&quot;public/items#show&quot;,&quot;settings&quot;:{&quot;analyticsTrackingId&quot;:&quot;UA-24675221-12&quot;,&quot;assetsMap&quot;:{},&quot;csrfToken&quot;:&quot;fpn9C5sVhar6FJWqxLaVvypvq0C/b2ukhiEBP7a23C8m9VxmG5kltvW35xX3EKV25+RlptLP32wQbyNd5zubsQ==&quot;,&quot;locale&quot;:&quot;en&quot;},&quot;currentUser&quot;:null}" /></body></html><script type="application/json" data-js-react-on-rails-store="AppStoreWithReactOnRails">{"snackbar":{"type":"","body":"","isActive":false},"article":{"article":{"body":"\u003cp\u003eメリークリスマス！（遅刻）\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://qiita.com/advent-calendar/2019/azure-ai\"\u003eAzure AI Advent Calendar 2019\u003c/a\u003e 25日目のエントリーです。\u003c/p\u003e\n\n\u003cp\u003eみなさんクリスマスイブからクリスマスにかけていかがお過ごしでしたか？\u003cbr\u003e\n私は本記事を書くために進捗の6時間を過ごして寝不足です。\u003c/p\u003e\n\n\u003cp\u003eさて、今回はAzure Cognitive Servicesの中の一つである、Speech ServiceのSpeech to Textの使い方や使ってみた結果などを紹介していきます。\u003cbr\u003e\n実際に動かしてみたコードも載せるので、試してみたいけど書くの面倒だし…という方も安心してお読み下さい。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/speech-to-text?WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003e音声変換 - Speech Service - Azure Cognitive Services | Microsoft Docs\u003c/a\u003e\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"用意するもの\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B%E3%82%82%E3%81%AE\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e用意するもの\u003c/h2\u003e\n\n\u003cul\u003e\n\u003cli\u003eAzureのサブスクリプション\u003c/li\u003e\n\u003cli\u003e.NET Core 3.0のアプリケーションがビルド出来る環境\u003c/li\u003e\n\u003cli\u003e書き起こししたい音声\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"始めてみよう\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%A7%8B%E3%82%81%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e始めてみよう\u003c/h2\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"cognitive-servicesのプロジェクトを作る\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#cognitive-services%E3%81%AE%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%82%92%E4%BD%9C%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eCognitive Servicesのプロジェクトを作る\u003c/h3\u003e\n\n\u003cp\u003eまずはCognitive Servicesのディレクトリを開きましょう。\u003cbr\u003e\nAzure PortalのSearchフォームに\u003ccode\u003ecognitive services\u003c/code\u003eと打ち込んで、ディレクトリに移動しましょう。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://camo.qiitausercontent.com/18e698115a2477b98ee2395ecfd452a24c0b9e97/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f31303530336636632d623066332d326331372d666134332d3065653737626330313135622e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg width=\"486\" alt=\"search-cognitive-services.png\" src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F10503f6c-b0f3-2c17-fa43-0ee77bc0115b.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=8456c1453a853e4ba7bf0c6583cd1001\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/10503f6c-b0f3-2c17-fa43-0ee77bc0115b.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F10503f6c-b0f3-2c17-fa43-0ee77bc0115b.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=6108b0b42fd5dd87b7400823a90ae7df 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eCognitive Servicesのディレクトリに移動したら、追加ボタンを押してどのServiceを使うか指定します。\u003cbr\u003e\n日本リージョンで使っている場合\u003ccode\u003eSpeech to Text\u003c/code\u003eとかで検索をかけると他のMarketplaceのServiceが引っかかってしまいます。\u003cbr\u003e\n日本リージョンで使っている場合は\u003ccode\u003e音声\u003c/code\u003eと調べると目的のServiceが出てきます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://camo.qiitausercontent.com/0efea3341918c94df67115b7194df430f5adfbce/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f64613930336537652d376638642d363830302d616336642d6662386630376534323162312e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg width=\"385\" alt=\"correct-speech-services.png\" src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2Fda903e7e-7f8d-6800-ac6d-fb8f07e421b1.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=7c62a9fd6b551673f908fdb84e801dfa\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/da903e7e-7f8d-6800-ac6d-fb8f07e421b1.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2Fda903e7e-7f8d-6800-ac6d-fb8f07e421b1.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=222813281793be3a352a3a0aeec82754 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e作成を押して適当な名前をつけます。\u003cbr\u003e\nお試しで使ってみたい場合はPricing tierをF0にすると良いでしょう（画像では既にF0 tierを使っているので選択出来ないように鳴っています…）\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://camo.qiitausercontent.com/a1a8f930a2189baeaf95f8266b8bf1f2e53fb626/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f35373234346262352d393235622d373165382d346432312d3461353263386430653834362e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg width=\"574\" alt=\"project-config-sample.png\" src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F57244bb5-925b-71e8-4d21-4a52c8d0e846.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=b849114f76747209b170e4a580a42441\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/57244bb5-925b-71e8-4d21-4a52c8d0e846.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F57244bb5-925b-71e8-4d21-4a52c8d0e846.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=e73fd03c52999241b07c717ae8a3b962 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e設定を済ませCreateを押すとプロジェクトが作成されます。\u003cbr\u003e\n遷移先のページで暫く待つと準備が出来るのでそれまでコーヒーでも飲んで待ちましょう。\u003c/p\u003e\n\n\u003cp\u003e準備が出来たあとサイドペインのQuick startを押すとどうすれば使うことが出来るのかが表示されます。\u003cbr\u003e\n本記事紹介するフローじゃない場合はこれを見ていい感じに頑張りましょう。\u003c/p\u003e\n\n\u003cp\u003e今回サンプルで紹介するプロジェクトを使う場合は\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://camo.qiitausercontent.com/623e2a0367197a36f5b4a28651e5155e2301a6fa/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3130343038352f35306137323930342d373934652d373961332d313030312d3664636332373637613361662e706e67\" target=\"_blank\" rel=\"nofollow noopener\"\u003e\u003cimg width=\"933\" alt=\"key-endpoint.png\" src=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F50a72904-794e-79a3-1001-6dcc2767a3af.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;s=250bba9b300154546cebfd70d77822bf\" data-canonical-src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104085/50a72904-794e-79a3-1001-6dcc2767a3af.png\" srcset=\"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F104085%2F50a72904-794e-79a3-1001-6dcc2767a3af.png?ixlib=rb-4.0.0\u0026amp;auto=format\u0026amp;gif-q=60\u0026amp;q=75\u0026amp;w=1400\u0026amp;fit=max\u0026amp;s=c30e68a07134433c6b7e6b0f5977f1b5 1x\" loading=\"lazy\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e上記の画像にある\u003ccode\u003eKey1\u003c/code\u003eと\u003ccode\u003eEndpoint\u003c/code\u003eは後々使うのでどこかしらにメモしておきましょう。\u003c/p\u003e\n\n\u003cp\u003e以上でプロジェクト自体の容易は完了です。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"アプリケーションを作る\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E4%BD%9C%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003eアプリケーションを作る\u003c/h3\u003e\n\n\u003cp\u003eとりあえず動くサンプルコードをこちらに用意しました。\u003cbr\u003e\nコード書きたくない、けど試してみたいという方はこちらをビルドして試してみて下さい。\u003c/p\u003e\n\n\u003cp\u003e\u003cqiita-embed-ogp src=\"https://github.com/yamachu/SpeechRecogSample\"\u003e\u003c/qiita-embed-ogp\u003e\u003c/p\u003e\n\n\u003cp\u003eこちらのコードを使わない場合、Quick startに沿って進めれば大体いい感じになります。\u003cbr\u003e\n自分の目的に合わせてやりたいなぁという方は\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?tabs=linux\u0026amp;pivots=programming-language-csharp\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eクイック スタート:オーディオ ファイルから音声を認識する - Speech サービス - Azure Cognitive Services | Microsoft Docs\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eを見て頑張ってみてください。\u003c/p\u003e\n\n\u003cp\u003e今回は自分の用意したサンプルコードと上記のクイックスタートを照らし合わせて解説していきます。\u003cbr\u003e\n上記のクイックスタートでは15秒未満の音声のみを対象としたものですが、15秒以上の音声を対象とすることも考え連続音声認識方式で行っています。\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eSpeechConfigを生成する\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp\u0026amp;tabs=linux#create-a-speech-configuration\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eSpeechConfigを作成する - Speech サービス - Azure Cognitive Services | Microsoft Docs\u003c/a\u003e\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"cs\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003estatic\u003c/span\u003e \u003cspan class=\"n\"\u003eSpeechConfig\u003c/span\u003e \u003cspan class=\"nf\"\u003eInitializeSpeechConfig\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003estring\u003c/span\u003e \u003cspan class=\"n\"\u003eendpoint\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"kt\"\u003estring\u003c/span\u003e \u003cspan class=\"n\"\u003esubscriptionKey\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eSpeechConfig\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eFromEndpoint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eUri\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eendpoint\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003esubscriptionKey\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"nf\"\u003eAlso\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003em\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"n\"\u003em\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSpeechRecognitionLanguage\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"ja-JP\"\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 日本語の音声を認識したいので設定\u003c/span\u003e\n        \u003cspan class=\"n\"\u003em\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eOutputFormat\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eOutputFormat\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDetailed\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 必要はないが、信頼度などのパラメータが欲しい場合はDetailedに設定する\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e});\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e普段見ない\u003ccode\u003eAlso\u003c/code\u003eなどが出ていますが、これは拡張メソッドで見慣れている形に書き直すと\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"cs\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"kt\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003econfig\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eSpeechConfig\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eFromEndpoint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eUri\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eendpoint\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e \u003cspan class=\"n\"\u003esubscriptionKey\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"n\"\u003econfig\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSpeechRecognitionLanguage\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"ja-JP\"\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"n\"\u003econfig\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eOutputFormat\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eOutputFormat\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eDetailed\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003econfig\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eと同等です。\u003cbr\u003e\nいい感じに読み替えて下さい。\u003c/p\u003e\n\n\u003cp\u003eここの\u003ccode\u003eendpoint\u003c/code\u003eと\u003ccode\u003esubscriptionKey\u003c/code\u003eは前節でメモをした\u003ccode\u003eEndpoint\u003c/code\u003eと\u003ccode\u003ekey1\u003c/code\u003eが対応しています。\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003eAudioConfigを作成し、認識結果を取得するコールバックを設定する\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp\u0026amp;tabs=linux#create-an-audio-configuration\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eAudioConfigを作成する - Speech サービス - Azure Cognitive Services | Microsoft Docs\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp\u0026amp;tabs=linux#display-the-recognition-results-or-errors\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003e認識結果 (またはエラー) を表示する - Speech サービス - Azure Cognitive Services | Microsoft Docs\u003c/a\u003e\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"cs\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eusing\u003c/span\u003e \u003cspan class=\"nn\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003eaudioConfig\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eAudioConfig\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eFromWavFileInput\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"k\"\u003eusing\u003c/span\u003e \u003cspan class=\"nn\"\u003evar\u003c/span\u003e \u003cspan class=\"n\"\u003erecognizer\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eSpeechRecognizer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econfig\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eaudioConfig\u003c/span\u003e\u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"nf\"\u003eAlso\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003er\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// e is SpeechRecognitionEventArgs\u003c/span\u003e\n    \u003cspan class=\"c1\"\u003e// refs: https://docs.microsoft.com/ja-jp/dotnet/api/microsoft.cognitiveservices.speech.speechrecognitioneventargs?view=azure-dotnet\u003c/span\u003e\n    \u003cspan class=\"n\"\u003er\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRecognized\u003c/span\u003e \u003cspan class=\"p\"\u003e+=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e_\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eResult\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eAlso\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eReason\u003c/span\u003e \u003cspan class=\"p\"\u003e==\u003c/span\u003e \u003cspan class=\"n\"\u003eResultReason\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eRecognizedSpeech\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eresultSubject\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eOnNext\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresult\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eBest\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"nf\"\u003eFirstOrDefault\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"nf\"\u003eLet\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003er\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nf\"\u003eRecognitionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eFile\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eResult\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003er\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eText\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eConfidence\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003er\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eConfidence\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e}));\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e});\u003c/span\u003e\n\n    \u003cspan class=\"n\"\u003er\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eSessionStopped\u003c/span\u003e \u003cspan class=\"p\"\u003e+=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e_\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003e__\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003erecognitionRunningSubject\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eOnNext\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003etrue\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003cspan class=\"p\"\u003e});\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e今回のコードでは、認識したいファイル一つごとに\u003ccode\u003eAudioConfig\u003c/code\u003eと\u003ccode\u003eSpeechRecognizer\u003c/code\u003eを生成しています。\u003cbr\u003e\n\u003ccode\u003eSpeechRecognizer.Recognized\u003c/code\u003eのコールバックでは認識結果を取得することが出来ます。\u003cbr\u003e\n今回は認識結果と、その認識結果の信頼度を出力しています。\u003c/p\u003e\n\n\u003col\u003e\n\u003cli\u003e語句を認識する\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp\u0026amp;tabs=linux#recognize-a-phrase\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003e語句を認識する - Speech サービス - Azure Cognitive Services | Microsoft Docs\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e上記リンクでは\u003ca href=\"https://docs.microsoft.com/ja-jp/dotnet/api/microsoft.cognitiveservices.speech.speechrecognizer.recognizeonceasync?view=azure-dotnet\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eRecognizeOnceAsync\u003c/a\u003eメソッドを使っています。\u003cbr\u003e\nこちらのメソッドだとドキュメントにあるように\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eStarts speech recognition, and returns after a single utterance is recognized. The end of a single utterance is determined by listening for silence at the end or until a maximum of 15 seconds of audio is processed. \u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e最大15秒の無音を含まないような単一発話をターゲットとしているので、少し長めの音声には適していません。\u003c/p\u003e\n\n\u003cp\u003eそのため、本サンプルでは\u003ca href=\"https://docs.microsoft.com/en-us/dotnet/api/microsoft.cognitiveservices.speech.speechrecognizer.startcontinuousrecognitionasync?view=azure-dotnet\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eStartContinuousRecognitionAsync\u003c/a\u003eを使用しました。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"cs\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eawait\u003c/span\u003e \u003cspan class=\"n\"\u003erecognizer\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eStartContinuousRecognitionAsync\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"nf\"\u003eConfigureAwait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003ewhile\u003c/span\u003e \u003cspan class=\"p\"\u003e(!\u003c/span\u003e\u003cspan class=\"n\"\u003erecognitionRunningSubject\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eValue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eawait\u003c/span\u003e \u003cspan class=\"n\"\u003eTask\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eDelay\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"m\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// 何秒ごとにフラグが変わるかのポーリングの秒数なのでお好きにどうぞ\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003eawait\u003c/span\u003e \u003cspan class=\"n\"\u003erecognizer\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eStopContinuousRecognitionAsync\u003c/span\u003e\u003cspan class=\"p\"\u003e().\u003c/span\u003e\u003cspan class=\"nf\"\u003eConfigureAwait\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003efalse\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e2.の\u003ccode\u003eSessionStopped\u003c/code\u003eで入力した音声ファイルの認識が終了したかが取得できるので、そこのイベントの結果を見て、それが起こるまでwhileループで待っている、みたいな漢字のコードになっています（いい感じに書けなかったので誰かPRお待ちしておりますｗ）。\u003c/p\u003e\n\n\u003cp\u003e以上のコードを使用することで認識をスタートすることが出来ます。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"音声を用意する\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E9%9F%B3%E5%A3%B0%E3%82%92%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e音声を用意する\u003c/h3\u003e\n\n\u003cp\u003e前節でファイルを認識する準備ができました。\u003cbr\u003e\nそれでは実際に音声を認識してみましょう。\u003c/p\u003e\n\n\u003cp\u003e今回は話者数が少なく、BGMも無い音声を認識してみます。\u003cbr\u003e\n題材としたのはよく聞いている\u003ca href=\"https://ajito.fm/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eajitofm\u003c/a\u003eの\u003ca href=\"https://ajito.fm/54/\" rel=\"nofollow noopener\" target=\"_blank\"\u003evol.54\u003c/a\u003eを使用してみました。\u003c/p\u003e\n\n\u003cp\u003e本実験に関して音声の使用を快諾してくださった権利者の方々に感謝いたします。\u003c/p\u003e\n\n\u003cp\u003eAzure Cognitive Services Speech Services Speech to Textでは16bitの8or16kHzのwavファイルが入力としてサポートされています。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/quickstarts/speech-to-text-from-file?pivots=programming-language-csharp\u0026amp;tabs=linux#supported-audio-input-format\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eサポートされるオーディオ入力の形式 - Speech サービス - Azure Cognitive Services | Microsoft Docs\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e今回の対象音声はmp3でサポートされているフォーマットと合致しません。\u003cbr\u003e\n今回は\u003ca href=\"http://sox.sourceforge.net/\" rel=\"nofollow noopener\" target=\"_blank\"\u003eSoX（Sound eXchange）\u003c/a\u003eを使って対象の音声に変換します。\u003c/p\u003e\n\n\u003cp\u003eMacであればbrewで入れることが出来ます。\u003c/p\u003e\n\n\u003cp\u003e使い方はhelpなどを見て欲しいのですが、\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"sh\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003esox target.mp3 \u003cspan class=\"nt\"\u003e-r\u003c/span\u003e 16000 target.wav\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eみたいな感じで、target.mp3をtarget.wavに16kHzにダウンサンプルして変換することが出来ます。\u003cbr\u003e\nSoX以外でも同様の処理は可能なのでお好きなアプリケーションをお使い下さい。\u003c/p\u003e\n\n\u003cp\u003eさて、これでフォーマットに合致した音声が生成することが出来ました。\u003c/p\u003e\n\n\u003cp\u003eこれでもうCognitive Servicesを使って音声認識をすることは出来るのですが、オプショナルとして無音区間で区切った音声を以上のファイルから作ってみたいと思います。\u003c/p\u003e\n\n\u003cp\u003e無音区間で区切ることで、音声と書き起こしの対応が付けやすいのと、今後別のサービスを使用する時に便利になったりします（後述）。\u003c/p\u003e\n\n\u003cp\u003eこの無音区間での分割には\u003ca href=\"https://github.com/julius-speech/julius/blob/master/adintool/README.ja.md\" rel=\"nofollow noopener\" target=\"_blank\"\u003eJuliusのadintool\u003c/a\u003eを使用しました。\u003cbr\u003e\nJuliusも音声認識を行うためのToolkitなので、興味のある方はぜひ試してみて下さい。\u003c/p\u003e\n\n\u003cp\u003eadintoolはWindowsの人であれば\u003ca href=\"https://github.com/julius-speech/julius/releases\" rel=\"nofollow noopener\" target=\"_blank\"\u003eGitHub Releaseページ\u003c/a\u003eからダウンロードすることが出来ます。\u003cbr\u003e\nMacやLinuxユーザの方はリポジトリをクローンしてビルドして手に入れましょう。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://julius.osdn.jp/juliusbook/ja/adintool.html\" rel=\"nofollow noopener\" target=\"_blank\"\u003eadintoolのドキュメント\u003c/a\u003eを読んで分割していきます。\u003cbr\u003e\nファイル入力の場合はファイル名を標準入力で取得するので、例えば以下のようなコマンドで分割してみます。\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"sh\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003e\u003cspan class=\"nb\"\u003eecho \u003c/span\u003etarget.wav| adintool \u003cspan class=\"nt\"\u003e-in\u003c/span\u003e file \u003cspan class=\"nt\"\u003e-out\u003c/span\u003e file \u003cspan class=\"nt\"\u003e-filename\u003c/span\u003e target_separated\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e同一ディレクトリのtarget.wavを入力に使用して、target_separated.{ここに連番}.wavと言うファイルで出力するのが上記のコマンドです。\u003cbr\u003e\n私は出力されたファイルが、オリジナルのファイルの何サンプル目か何サンプル目であるかをメモっておきたかったので、\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"sh\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003e\u003cspan class=\"nb\"\u003eecho \u003c/span\u003etarget.wav| adintool \u003cspan class=\"nt\"\u003e-in\u003c/span\u003e file \u003cspan class=\"nt\"\u003e-out\u003c/span\u003e file \u003cspan class=\"nt\"\u003e-filename\u003c/span\u003e target_separated \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e\u0026amp; /dev/null| \u003cspan class=\"nb\"\u003egrep\u003c/span\u003e \u003cspan class=\"nt\"\u003e-E\u003c/span\u003e \u003cspan class=\"s2\"\u003e\"^target_separated.*\"\u003c/span\u003e| \u003cspan class=\"nb\"\u003esed\u003c/span\u003e \u003cspan class=\"nt\"\u003e-E\u003c/span\u003e \u003cspan class=\"s2\"\u003e\"s;(.*\u003c/span\u003e\u003cspan class=\"se\"\u003e\\.\u003c/span\u003e\u003cspan class=\"s2\"\u003ewav):.*\u003c/span\u003e\u003cspan class=\"se\"\u003e\\[\u003c/span\u003e\u003cspan class=\"s2\"\u003e *([0-9]+).*- ([0-9]+).*;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\1\u003c/span\u003e\u003cspan class=\"s2\"\u003e \u003c/span\u003e\u003cspan class=\"se\"\u003e\\2\u003c/span\u003e\u003cspan class=\"s2\"\u003e \u003c/span\u003e\u003cspan class=\"se\"\u003e\\3\u003c/span\u003e\u003cspan class=\"s2\"\u003e;g\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eこんな感じにしてみました。\u003c/p\u003e\n\n\u003ch3\u003e\n\u003cspan id=\"実際に走らせる\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E5%AE%9F%E9%9A%9B%E3%81%AB%E8%B5%B0%E3%82%89%E3%81%9B%E3%82%8B\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e実際に走らせる\u003c/h3\u003e\n\n\u003cp\u003e実際に実行するのは非常に簡単です。\u003c/p\u003e\n\n\u003cp\u003e\u003cqiita-embed-ogp src=\"https://github.com/yamachu/SpeechRecogSample\"\u003e\u003c/qiita-embed-ogp\u003e\u003c/p\u003e\n\n\u003cp\u003eを使用した方はクローンしたディレクトリで\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"sh\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e\u003cspan class=\"nv\"\u003e$ \u003c/span\u003edotnet run \u003cspan class=\"nt\"\u003e--source-dir\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"k\"\u003e${\u003c/span\u003e\u003cspan class=\"p\"\u003e認識したいwavファイルがあるディレクトリ\u003c/span\u003e\u003cspan class=\"k\"\u003e}\u003c/span\u003e \u003cspan class=\"nt\"\u003e--endpoint\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"k\"\u003e${\u003c/span\u003e\u003cspan class=\"p\"\u003eメモったEndpoint\u003c/span\u003e\u003cspan class=\"k\"\u003e}\u003c/span\u003e \u003cspan class=\"nt\"\u003e--subscription-key\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"k\"\u003e${\u003c/span\u003e\u003cspan class=\"p\"\u003eメモったKey1\u003c/span\u003e\u003cspan class=\"k\"\u003e}\u003c/span\u003e \u003cspan class=\"nt\"\u003e--result\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"k\"\u003e${\u003c/span\u003e\u003cspan class=\"nv\"\u003eCSV\u003c/span\u003e\u003cspan class=\"p\"\u003eで認識結果を保存したい場合はここにファイル名\u003c/span\u003e\u003cspan class=\"k\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eみたいな感じで走らせます。\u003cbr\u003e\n100ファイル合計10分程度のファイルの認識で約5分でした。\u003c/p\u003e\n\n\u003cp\u003e認識結果の一部を見てみましょう\u003c/p\u003e\n\n\u003cp\u003eajitofm54.0094.wavの11714236~11897036サンプル目\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"text\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e結果: なんか？アメリカ滞在中に面白かった事とか、あります。ええ、クライミングシューズが安かった。全然仕事じゃなかったみたいな。\n正:\nS: なんか、アメリカ滞在中に面白かった事とか、あります？\nK: ええ、クライミングシューズが安かった。\nS: 全然仕事じゃなかったみたいな。\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e見事に認識できています。\u003cbr\u003e\nクライミングシューズっていう普段でなそうなワードも認識出来ていて素晴らしいですね。\u003c/p\u003e\n\n\u003cp\u003eしかし複数話者の発話が混じっているので大変です…これに関しては\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speaker-recognition/home\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eSpeaker Recognition API\u003c/a\u003eが日本語対応すれば、どこの部分を誰が話しているのか認識出来そうなので、期待して待ちましょう。\u003c/p\u003e\n\n\u003cp\u003eまた\u003c/p\u003e\n\n\u003cp\u003eajitofm54.0079.wavの9774236~9844036サンプル目\u003c/p\u003e\n\n\u003cdiv class=\"code-frame\" data-lang=\"text\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"with-code\"\u003e\u003ccode\u003e結果: ソースコード読みたいなと思いながら、まあまだ読んでないけど。\n正:\nK: ソースコード読みたいなと思いながら\nS: ああー（相槌）\nK: まだ読んでないけど。\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003e相槌が混じってしまっていますが、Domain Specificな単語も認識しています。\u003cbr\u003e\nバッチリですね……\u003c/p\u003e\n\n\u003ch2\u003e\n\u003cspan id=\"終わりに\" class=\"fragment\"\u003e\u003c/span\u003e\u003ca href=\"#%E7%B5%82%E3%82%8F%E3%82%8A%E3%81%AB\"\u003e\u003ci class=\"fa fa-link\"\u003e\u003c/i\u003e\u003c/a\u003e終わりに\u003c/h2\u003e\n\n\u003cp\u003eSpeech to Text APIを使うためにプログラムを書いて、実際に認識するための一連の流れを紹介しました。\u003c/p\u003e\n\n\u003cp\u003e一回認識するためのプログラムを用意してしまえば、あとは音声を用意するだけで簡単に書き起こしが出来ちゃいます。\u003c/p\u003e\n\n\u003cp\u003e今回紹介できませんでしたが（日本語対応とかしていないというのもあるけど）、認識精度を上げるために\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/how-to-custom-speech-train-model\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003e話者モデル\u003c/a\u003eを作ったり、前述した\u003ca href=\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/speaker-recognition/home\u0026amp;WT.mc_id=AI-MVP-5002987\" rel=\"nofollow noopener\" target=\"_blank\"\u003eSpeaker Recognition API\u003c/a\u003eを使用することにより、更に書き起こし業務が簡単になりそうです。\u003c/p\u003e\n\n\u003cp\u003eこれらをするにはある程度ファイルを分割しておいたほうが楽なので、音声準備の段階で無音区間でファイルを分割みたいなことを推奨していました。\u003c/p\u003e\n\n\u003cp\u003eまたSpeech to Textサービスはリアルタイムのマイク入力も対応しているので、後々書き起こしがしたい音声の録音時にそのまま書き起こしさせたりすることが出来ます。\u003cbr\u003e\nまた話者毎の認識精度を上げるためにマイクを別々に用意して、各話者毎に録音するなどの工夫次第でどんどん使いやすくなるのでぜひチャレンジしてみて下さい。\u003c/p\u003e\n\n\u003chr\u003e\n\n\u003cp\u003eさて\u003ca href=\"https://qiita.com/advent-calendar/2019/azure-ai\"\u003eAzure AI Advent Calendar 2019\u003c/a\u003e完走です！\u003c/p\u003e\n\n\u003cp\u003e面白い記事を投稿してくださった皆様、本当にありがとうございました。\u003cbr\u003e\nAzureのAI技術面白いものがまだまだたくさんあります。\u003c/p\u003e\n\n\u003cp\u003eぜひ多くのサービスを試して、こういうことが出来そう、出来たなどの例や、ここで詰まったーこうすると良いよ、みたいな知見を投稿して良いコミュニティが生まれたらいいなと覆います。\u003c/p\u003e\n\n\u003cp\u003e来年もAzure AIをよろしくお願いいたします！（誰）\u003c/p\u003e\n","createdAt":"2019-12-27T11:45:57Z","elapsedYearsFromLastModifiedAt":0,"encryptedId":"XQl0CHnnCh9giBcGzCkaBHF9xttus7jcMA==--Q2/mRaqjpK6dzQ9M--Hgf5+wRhhib6eqsLug2kxg==","isBanned":false,"isDeprecated":false,"isDestroyableByViewer":false,"isEditRequestReadableByViewer":true,"isEditRequestSendableByViewer":true,"isLikableByViewer":true,"isLikedByViewer":false,"isPublic":true,"isSlide":false,"isStockableByViewer":true,"isStockedByViewer":false,"isSubscribableByViewer":false,"isSubscribedByViewer":false,"isUpdatableByViewer":false,"isUpdated":true,"lastModifiedAt":"2020-11-13T10:39:49Z","likesCount":15,"linkUrl":"https://qiita.com/yamachu/items/dda2624abbfe4364328a","organization":null,"originalId":1124445,"stockedCount":11,"title":"Azure Cognitive ServicesのSpeech to Textで書き起こしをしてみよう","toc":"\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B%E3%82%82%E3%81%AE\"\u003e用意するもの\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%A7%8B%E3%82%81%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86\"\u003e始めてみよう\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#cognitive-services%E3%81%AE%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%82%92%E4%BD%9C%E3%82%8B\"\u003eCognitive Servicesのプロジェクトを作る\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E4%BD%9C%E3%82%8B\"\u003eアプリケーションを作る\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E9%9F%B3%E5%A3%B0%E3%82%92%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B\"\u003e音声を用意する\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E5%AE%9F%E9%9A%9B%E3%81%AB%E8%B5%B0%E3%82%89%E3%81%9B%E3%82%8B\"\u003e実際に走らせる\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#%E7%B5%82%E3%82%8F%E3%82%8A%E3%81%AB\"\u003e終わりに\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","totalPv":7503,"uuid":"dda2624abbfe4364328a","banReason":null,"adventCalendarItem":{"day":25,"calendar":{"name":"Azure AI","urlName":"azure-ai","year":2019,"organization":null}},"author":{"encryptedId":"0Db9awDVjncdHDtw0YFu6ux+57qa--K4TYoMLm312mABBx--x+QDg4qIBfwDKHse+GQyaw==","originalId":104085,"description":"","facebookUrl":null,"githubUrl":"https://github.com/yamachu","isBlockingViewer":false,"isFollowableByViewer":true,"isFollowedByViewer":false,"isTweetWebNotificationReceivable":true,"linkedinUrl":null,"name":"","profileImageUrl":"https://qiita-image-store.s3.amazonaws.com/0/104085/profile-images/1504185427","profileImageUrlW48":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F104085%2Fprofile-images%2F1504185427?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=48\u0026s=7ecad0ea454b504f33f3556cfcbbbf3b","profileImageUrlW75":"https://qiita-user-profile-images.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F104085%2Fprofile-images%2F1504185427?ixlib=rb-4.0.0\u0026auto=compress%2Cformat\u0026lossless=0\u0026w=75\u0026s=cb074881c1f31aff91534ee5280be305","urlName":"yamachu","websiteUrl":"http://teitoku-window.hatenablog.com/","twitterUrl":"https://twitter.com/y_chu5","twitterUrlName":"y_chu5","revealedOrganizations":{"edges":[]}},"tags":[{"name":"C#","urlName":"csharp"},{"name":"Azure","urlName":"azure"},{"name":"CognitiveServices","urlName":"cognitiveservices"},{"name":"SpeechToText","urlName":"speechtotext"}],"followingLikers":{"edges":[]},"comments":{"totalCount":0}},"comments":[],"client":null,"ads_event_emitter":null}}</script>
