More than 3 years have passed since last update.前回のStream Analytics で 凝った集計処理を実装するで書いた通り、Stream Analytics でテストデータから、Portal 上で想定通りデータがサマリされるところまで確認した。次に、EventHub -&gt; Stream Analytics -&gt; CosmosDB の構成なので、それがちゃんと動作するかのE2Eのスモークテストを簡単に書いておこうと思った。ところが、これが早速うまくいかなかった。出てきた問題点を次にはまらないように整理しておく。課題は前回の記事のSQL を作成して、ポータル上でテストも完成したので、まったく同じデータを使って、EventHubs のライブラリからポストすると CosmosDBに全くストアされない。なんでやねん。この問題を解決したいと思った。結構解決に時間がかかったが、様々な要因が絡み合っていたので、それを忘れないようにメモしておきたい。EventHubs のクライアントライブラリを使ったコードは、Event Hubs のプログラミング ガイドというページがあるのだが、少なくとも .NetCore を使っている人はこの書き方はバージョンが古い上に、WindowsAzure.ServiceBus をインストールする必要がある。.NETCore 使いの人はこちら。nuget パッケージも Microsoft.Azure.EventHubs のみでよい。かなりすっきりする。私はAzure Functions で使うので、‘Microsoft.Azure.WebJobs.Extensions.EventHubs (v3.0.0-beta7-11351)` のパッケージを使っている。このバージョンでいくと、古いバージョンだとNameSpaceManager 等が必要だったのがもっとすっきり書ける。ぐらいの感じでかけて相当すっきりとかけていい感じ。現在の制限事項らしい。泣く泣く出力先のクラスの属性を小文字にした。(属性をつけてもよかったけど）これは、まず疑うべきところ。実際わすれていた。次のページが参考になった。結局クエリを実行したが、０件だからデータが吐かれていなかったということが原因だった。現在のクエリはこれでモロ該当するこれはクエリを SELECT * INTO cosmosdb FROM downtime みたいな単純な全件検索にして気づいた。この場合問題なく全件がCosmosDB に書かれたということは、設定は間違っていない。 特に、Timestamp By を使用する場合は、イベントのタイムスタンプがジョブの開始時刻より後であることが必要です。また、Window 関数を使っているときに、 Window が終わっていなかったらデータが来ません。これはたぶん Timestamp By と思われるが、Stream Analytics 開始後であっても、タイムスタンプがデータが送られた時間と大幅にかけ離れていてもうまくクエリーできないみたいだ。例えば、クエリー開始時間後の　5分、10分 15分　ぐらいのデータを一気に送信すると、5 分のデータは出力されたが、そのあとのは出力されなかった。このあたりの仕様はよくわからないし、ドキュメントでも見つけられないのでメーリングリストで聞くか、友人に聞いてみたい。(TODO) つまり ほぼリアルタイムにデータを送信する必要がある。最初は E2E テストを書いているときに、最初にアウトプットをするコレクションをクリアしたかったので、一旦コレクションを消して、作成するというオペレーションをしていた。すると、アクティビティログ で次のようなエラーに会う。おそらく、アウトプットの設定時に、コネクションを始めているのかもしれない。だから、Stream Analytics の開始時点のコレクションがなくなったら書き込みができなくなるので、そういったことをしないのがポイント。コレクションを削除する代わりに、Document を全件削除するとよい。しかしこれが面倒だ。そいうったメソッドはないし、やろうとしたら、全件クエリーして、１件づつ削除なのだが、PartitionKey があるテーブルだと、それを設定しないといけない。Generic なメソッドを作ろうと思ったが、面倒になって、べたべたのコードを書いた。ここ以外で使うタイミングがないので、抽象化が割に合わない。大変面倒だが、テストデータは、一気に投入できない。時間を必要とするパターンがある場合、該当の時間にデータを投入する必要がある。作戦としては、データパターンを作っておいて、そのデータパターンに現在時を入れて、その相対時間でテストデータを作るとよい。厳密にいうとタイミングによっては Fail して freaky なテストになるかもしれないが、発生するまではこれで。発生したら、もっとロジックで正しさを証明するように直すとよい。（例えば、Stream Analytics に期待するロジックをテストで書いておいて、インプットデータと、予想されるアウトプットを計算するロジックを書く。みなさんどうしているのだろう。もしもっといい方法があれば是非ご教授ください。デバッグに関しては、クライアントは、VS のデバッグ機能でステップ実行するのが王道。また、Stream Analytics の場合、Metrics を見ると、Input はあるのに、Output がない（ということは、クエリーの結果０件）とかがわかる。他には アクティビティログはcosmosdbの接続問題を診断するのに役立った。、診断ログが設定できるので設定しておいたが、ストレージにイベントが吐かれているのがわかった。小さな Tips だけど、上記にあるように、DateTime の演算をしたいときに、TimeSpan を渡せば演算できるこれで無事E2Eテストが実行されて動作が確認できた。次は Change Feed + CosmosDB Trigger を使って、最終的な集計を実施してそれも、E2Eテストに組み込んでみたい。あと、これいい記事だった。Pluralsight は２時間半なので、ちゃんと見てみよう。


